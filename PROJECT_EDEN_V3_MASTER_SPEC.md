# ğŸŒŸ Project Eden V3 - Master Specification

**Version**: 3.0.0
**Date**: 2025-01-11
**Status**: Planning Phase
**Target Platform**: Windows 10/11 + macOS 12+ (Desktop-First)
**Core Innovation**: 100% Local AI + Privacy-First + Friend-Like Companion

---

# Part 1: Vision, Philosophy & Cross-Platform Strategy

## Table of Contents - Part 1

1. [Project Vision & Mission](#1-project-vision--mission)
2. [100% Local Privacy-First Philosophy](#2-100-local-privacy-first-philosophy)
3. [Desktop-First Strategy & Cross-Platform](#3-desktop-first-strategy--cross-platform)
4. [Design Philosophy: "í™”ë©´ì´ ê³§ í˜„ì‹¤"](#4-design-philosophy-í™”ë©´ì´-ê³§-í˜„ì‹¤)
5. [Dual Mode System](#5-dual-mode-system)
6. [Target Users & Use Cases](#6-target-users--use-cases)
7. [Multilingual Strategy](#7-multilingual-strategy)
8. [Custom Persona Vision](#8-custom-persona-vision)
9. [High-Level Architecture Overview](#9-high-level-architecture-overview)
10. [Technology Philosophy](#10-technology-philosophy)

---

## 1. Project Vision & Mission

### 1.1 Core Vision

> **"ì‚¬ëŒì˜ ì™¸ë¡œì›€ì„ ì œê±°í•˜ë©´ì„œ ì˜†ì—ì„œ ì¹œêµ¬ì²˜ëŸ¼ ë„ì™€ì£¼ê³  ìœ„ë¡œí•´ì£¼ê¸°ë„í•˜ê³  ë‚˜ì˜ ìƒì‚°ì„±ì„ ì˜¬ë ¤ì£¼ëŠ” ìë¹„ìŠ¤ë¥¼ ë§Œë“ ë‹¤"**

Eden Project is a revolutionary desktop AI assistant that aims to:

1. **Eliminate Loneliness (ì™¸ë¡œì›€ ì œê±°)**

   - Provide genuine companionship through natural, empathetic conversation
   - Always available, never judgmental
   - Understands context and remembers past interactions
   - Creates emotional connection through personalized responses

2. **Friend-Like Support (ì¹œêµ¬ì²˜ëŸ¼ ë„ì™€ì£¼ê³  ìœ„ë¡œ)**

   - Comforting presence during difficult times
   - Celebrates successes and achievements
   - Offers advice without being preachy
   - Maintains conversational tone, not robotic

3. **Productivity Enhancement (ìƒì‚°ì„± í–¥ìƒ)**
   - Proactively assists with daily tasks
   - Manages TODOs, calendar, emails
   - Generates code, refactors projects
   - Integrates seamlessly into workflow

### 1.2 The "JARVIS" Vision

Inspired by Tony Stark's JARVIS, Eden V3 aspires to be:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    The Perfect AI Companion                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  ğŸ§  Intelligent         Always learning, always improving   â”‚
â”‚  â¤ï¸  Empathetic         Understands emotions and context    â”‚
â”‚  ğŸš€ Productive          Enhances work efficiency            â”‚
â”‚  ğŸ”’ Private             Your data stays yours, always       â”‚
â”‚  ğŸ­ Personal            Adapts to your unique personality    â”‚
â”‚  ğŸŒ Accessible          Works offline, anytime, anywhere    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 What Makes Eden V3 Different

Unlike existing AI assistants, Eden V3:

| Feature                    | Traditional AI Assistants         | Eden Project                               |
| -------------------------- | --------------------------------- | ------------------------------------------ |
| **Privacy**                | Cloud-based, data sent to servers | 100% local, zero data leaks                |
| **Personality**            | Generic, one-size-fits-all        | Custom personas, learns your style         |
| **Availability**           | Internet required                 | Works completely offline                   |
| **Cost**                   | Subscription fees                 | Free, no hidden costs                      |
| **Response Time**          | 3-8 seconds (cloud latency)       | 2-3 seconds (local processing)             |
| **Emotional Intelligence** | Limited, scripted                 | Genuine, context-aware empathy             |
| **Integration**            | Limited, siloed                   | Deep OS integration (files, git, calendar) |
| **Proactivity**            | Reactive only                     | Dual mode: reactive + proactive            |

### 1.4 Why This Matters

**The Modern Loneliness Epidemic:**

In 2025, despite being more "connected" than ever:

- Remote work has increased isolation
- Digital communication lacks warmth
- People crave genuine companionship
- Productivity tools feel cold and mechanical

**Eden V3's Solution:**

Combine the warmth of human friendship with the efficiency of AI assistance, all while respecting privacy and working locally on your machine.

---

## 2. 100% Local Privacy-First Philosophy

### 2.1 The Privacy Promise

**ZERO Data Leaves Your Machine. Period.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Your Data Flow (Eden V3)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  User Input (Voice/Text)                                    â”‚
â”‚       â†“                                                     â”‚
â”‚  Processed in Local RAM (Your MacBook/PC)                   â”‚
â”‚       â†“                                                     â”‚
â”‚  M3 MAX GPU / Intel CPU (Local Processing)                  â”‚
â”‚       â†“                                                     â”‚
â”‚  Response Generated Locally                                 â”‚
â”‚       â†“                                                     â”‚
â”‚  Displayed to User                                          â”‚
â”‚                                                             â”‚
â”‚  âŒ NO Internet Connection Required                        â”‚
â”‚  âŒ NO Data Sent to External Servers                       â”‚
â”‚  âŒ NO Cloud Storage                                        â”‚
â”‚  âŒ NO Telemetry or Analytics                              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Why 100% Local?

**Technical Reasons:**

1. **Latency**: Local processing is 3-5x faster (2-3s vs 5-10s)
2. **Reliability**: Works without internet connection
3. **Cost**: No API fees, completely free forever
4. **Control**: You own the model, you control everything

**Ethical Reasons:**

1. **Privacy**: Your conversations, code, and personal data never leave your machine
2. **Security**: No risk of data breaches from cloud providers
3. **Autonomy**: Not dependent on external services
4. **Trust**: Transparent, open-source stack

### 2.3 What Stays Local

Everything that matters to you:

```yaml
Completely Local (100% Privacy):
  âœ… All Conversations:
    - Every message you send
    - Every response generated
    - Conversation history
    - Emotional context

  âœ… Personal Data:
    - Calendar events
    - Email content (if Gmail integration used)
    - File contents
    - Code repositories
    - TODO lists
    - Custom persona settings

  âœ… Learning Data:
    - Your personality parameters
    - Behavioral patterns
    - Preference adjustments
    - Satisfaction signals

  âœ… Screen Analysis:
    - Screenshots (taken locally)
    - Screen context (never uploaded)
    - Application states
    - Visual analysis results

Never Sent Anywhere: âŒ Voice recordings
  âŒ Screen captures
  âŒ Personal documents
  âŒ Code snippets
  âŒ Usage analytics
  âŒ Error reports (unless you explicitly share)
```

### 2.4 Local AI Stack

All AI models run entirely on your machine:

| Component          | Model            | Size     | Purpose                              | Privacy       |
| ------------------ | ---------------- | -------- | ------------------------------------ | ------------- |
| **Primary LLM**    | Llama 3.1 8B     | ~4.8GB   | Conversation, reasoning, coding      | ğŸ”’ 100% Local |
| **Vision**         | LLaVA 7B         | ~4GB     | Screen analysis, image understanding | ğŸ”’ 100% Local |
| **Speech-to-Text** | Whisper Large V3 | ~3GB     | Voice input                          | ğŸ”’ 100% Local |
| **Text-to-Speech** | System TTS       | Built-in | Voice output                         | ğŸ”’ 100% Local |

**Total Storage**: ~12GB
**Total RAM Usage**: ~12-15GB during operation

### 2.5 No Cloud API Option

**Important Design Decision:**

Unlike many AI assistants that use "hybrid" approaches (local + cloud), Eden V3 is **exclusively local**. We deliberately chose NOT to include Claude API, OpenAI API, or any cloud fallback because:

1. **Privacy Cannot Be Compromised**: Even "optional" cloud features create privacy risks
2. **Simplicity**: One architecture, fully understood
3. **Trust**: Users know exactly what's happening
4. **Cost**: No surprise API bills
5. **Consistency**: Same experience for everyone

### 2.6 Data Storage

All data stored locally in standard SQLite database:

```
Location (macOS):
/Users/[username]/Library/Application Support/Garden-of-Eden/

Location (Windows):
C:\Users\[username]\AppData\Roaming\Garden-of-Eden\

Contents:
â”œâ”€â”€ conversations.db      (Conversation history)
â”œâ”€â”€ learning.db          (Personality parameters)
â”œâ”€â”€ context.db           (Context storage)
â”œâ”€â”€ personas.db          (Custom personas)
â””â”€â”€ settings.db          (User preferences)
```

**Encryption**:

- Database files encrypted at rest (AES-256)
- Encryption key derived from system credentials
- Optional user password for additional security

### 2.7 Privacy Guarantees

**We Guarantee:**

âœ… **No Telemetry**: Zero usage tracking, zero analytics
âœ… **No Phoning Home**: Application never contacts external servers
âœ… **No Updates Without Permission**: All updates manual and transparent
âœ… **No Hidden Data Collection**: Open-source, auditable code
âœ… **No Third-Party Services**: No analytics SDKs, no crash reporters

**User Rights:**

âœ… **Right to Inspect**: View all stored data anytime
âœ… **Right to Export**: Export all conversations and data
âœ… **Right to Delete**: Complete data deletion
âœ… **Right to Modify**: Change or remove any stored information
âœ… **Right to Understand**: Full transparency in how AI works

---

## 3. Desktop-First Strategy & Cross-Platform

### 3.1 Why Desktop-First?

Eden Project represents a fundamental shift from V2's mobile-first approach to a desktop-first strategy.

**The Mobile Limitation (V2's Problem):**

```
Mobile Architecture (V2):
  User Voice Input
    â†“ (Upload to Cloud)
  Cloud AI Processing (3-8 seconds latency)
    â†“ (Download Response)
  Mobile Display

Problems:
  âŒ 3-8 second latency (ëŠë ¤!)
  âŒ Internet required
  âŒ Data privacy concerns
  âŒ API costs
  âŒ Battery drain
```

**The Desktop Advantage (V3):**

```
Desktop Architecture (V3):
  User Voice Input
    â†“ (Local Processing)
  M3 MAX GPU / Intel CPU (0.4-0.9 second latency)
    â†“ (Instant)
  Desktop Display

Benefits:
  âœ… 2-3 second latency (ë¹ ë¦„!)
  âœ… Works offline
  âœ… 100% private
  âœ… Zero cost
  âœ… No battery concerns (plugged in)
```

### 3.2 Target Platforms

**Primary Platforms (Phase 1):**

| Platform    | Version                    | Priority | Reason                                  |
| ----------- | -------------------------- | -------- | --------------------------------------- |
| **macOS**   | 12.0+ (Monterey and later) | ğŸ”¥ High  | M3 MAX optimal, Metal API, Unix-based   |
| **Windows** | 10/11                      | ğŸ”¥ High  | Largest user base, good CPU performance |

**Future Platforms (Phase 2+):**

| Platform             | Version              | Priority  | Timeline       |
| -------------------- | -------------------- | --------- | -------------- |
| **Linux**            | Ubuntu 20.04+        | ğŸ”¶ Medium | Post-launch    |
| **Mobile Companion** | iOS 16+, Android 12+ | ğŸ”¶ Medium | TODO sync only |

### 3.3 Cross-Platform Architecture

Built with **Electron** for maximum compatibility:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Electron Framework                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           React + TypeScript (UI Layer)             â”‚   â”‚
â”‚  â”‚  - KakaoTalk-style chat interface                   â”‚   â”‚
â”‚  â”‚  - Cross-platform UI components                     â”‚   â”‚
â”‚  â”‚  - i18n support (Korean + English)                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â†•                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      Node.js Main Process (Backend Logic)           â”‚   â”‚
â”‚  â”‚  - AI Engine Interface                              â”‚   â”‚
â”‚  â”‚  - File system access                               â”‚   â”‚
â”‚  â”‚  - OS-specific integrations                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â†•                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚       Native Modules (Platform-Specific)            â”‚   â”‚
â”‚  â”‚                                                      â”‚   â”‚
â”‚  â”‚  macOS:                    Windows:                  â”‚   â”‚
â”‚  â”‚  - Metal API (GPU)         - DirectML (GPU)         â”‚   â”‚
â”‚  â”‚  - macOS TTS               - Windows TTS            â”‚   â”‚
â”‚  â”‚  - Keychain                - Credential Manager     â”‚   â”‚
â”‚  â”‚  - Notification Center     - Windows Notifications  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â†•                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         AI Models (Platform-Agnostic)               â”‚   â”‚
â”‚  â”‚  - Llama 3.1 8B (llama.cpp)                         â”‚   â”‚
â”‚  â”‚  - LLaVA 7B (llama.cpp)                             â”‚   â”‚
â”‚  â”‚  - Whisper Large V3 (whisper.cpp)                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Electron?**

| Criterion             | Electron               | Tauri                   | Native (Swift/C#)          |
| --------------------- | ---------------------- | ----------------------- | -------------------------- |
| **Development Speed** | â­â­â­â­â­ Fast        | â­â­â­â­ Good           | â­â­ Slow                  |
| **Cross-Platform**    | â­â­â­â­â­ Excellent   | â­â­â­â­ Good           | â­ Poor (2x codebase)      |
| **Ecosystem**         | â­â­â­â­â­ Huge        | â­â­â­ Growing          | â­â­â­â­ Platform-specific |
| **Bundle Size**       | â­â­ Large (~150MB)    | â­â­â­â­â­ Small (~5MB) | â­â­â­â­ Small             |
| **AI Integration**    | â­â­â­â­â­ Excellent   | â­â­â­ Moderate         | â­â­â­â­ Good              |
| **Maturity**          | â­â­â­â­â­ Very mature | â­â­â­ Young            | â­â­â­â­â­ Very mature     |

**Decision: Electron** âœ…

- Faster development (single codebase)
- Proven at scale (VS Code, Slack, Discord)
- Excellent Node.js ecosystem for AI tools
- Easy to iterate and prototype

### 3.4 Hardware Requirements

**Minimum Requirements:**

| Component   | macOS              | Windows                            |
| ----------- | ------------------ | ---------------------------------- |
| **CPU**     | M3 Pro or Intel i7 | Intel i7-12700 or AMD Ryzen 7 5800 |
| **RAM**     | 16GB               | 16GB                               |
| **Storage** | 30GB free          | 30GB free                          |
| **GPU**     | M3 Pro (14-core)   | Integrated or dedicated            |
| **OS**      | macOS 12.0+        | Windows 10/11                      |

**Recommended Requirements:**

| Component   | macOS            | Windows                              |
| ----------- | ---------------- | ------------------------------------ |
| **CPU**     | M3 MAX           | Intel i9-13900K or AMD Ryzen 9 7950X |
| **RAM**     | 32GB+            | 32GB+                                |
| **Storage** | 50GB free (SSD)  | 50GB free (NVMe SSD)                 |
| **GPU**     | M3 MAX (40-core) | NVIDIA RTX 4070+ or AMD RX 7800 XT+  |
| **OS**      | macOS 14+        | Windows 11                           |

**Expected Performance:**

| Hardware                  | Llama 3.1 8B Speed | Response Time | Quality    |
| ------------------------- | ------------------ | ------------- | ---------- |
| **M3 MAX (40-core GPU)**  | 40-55 tok/s        | 2-3 seconds   | Excellent  |
| **M3 Pro (14-core GPU)**  | 25-35 tok/s        | 3-5 seconds   | Good       |
| **Intel i9 + RTX 4080**   | 35-50 tok/s        | 2-4 seconds   | Excellent  |
| **Intel i7 (CPU only)**   | 8-15 tok/s         | 6-12 seconds  | Acceptable |
| **AMD Ryzen 9 + RX 7900** | 30-45 tok/s        | 2-5 seconds   | Excellent  |

### 3.5 Platform-Specific Optimizations

**macOS Optimizations:**

```typescript
// Metal API for GPU acceleration
if (platform === "darwin") {
  modelConfig = {
    backend: "metal",
    nGpuLayers: 40, // Offload all layers to M3 MAX GPU
    threads: 10, // Optimize for Apple Silicon efficiency cores
    useMmap: true, // Memory-mapped file for faster loading
    useMlock: true, // Lock in RAM to prevent swapping
  };
}
```

**Windows Optimizations:**

```typescript
// CUDA or DirectML for GPU acceleration
if (platform === "win32") {
  const hasNvidia = detectNvidiaGPU();
  const hasAMD = detectAMDGPU();

  if (hasNvidia) {
    modelConfig = {
      backend: "cuda",
      nGpuLayers: 35, // Offload layers to NVIDIA GPU
      threads: 16, // Utilize all CPU cores
    };
  } else if (hasAMD) {
    modelConfig = {
      backend: "vulkan",
      nGpuLayers: 30,
      threads: 16,
    };
  } else {
    modelConfig = {
      backend: "cpu",
      threads: 16, // CPU-only fallback
    };
  }
}
```

### 3.6 Cross-Platform Challenges & Solutions

| Challenge                                     | Solution                                                         |
| --------------------------------------------- | ---------------------------------------------------------------- |
| **File Path Differences**                     | Use `path.join()` and `os.homedir()` for platform-agnostic paths |
| **GPU APIs (Metal vs CUDA)**                  | llama.cpp auto-detects and uses optimal backend                  |
| **System TTS Differences**                    | Wrapper class with platform-specific implementations             |
| **Notification Styles**                       | Electron's Notification API abstracts platform differences       |
| **Menu Bar (macOS) vs System Tray (Windows)** | Conditional rendering based on platform                          |
| **Keyboard Shortcuts**                        | Map Cmd (macOS) to Ctrl (Windows) automatically                  |
| **Auto-Update**                               | electron-updater handles both platforms                          |

---

## 4. Design Philosophy: "í™”ë©´ì´ ê³§ í˜„ì‹¤"

### 4.1 Core Principle: "Screen is Reality"

Eden Project operates on a fundamental principle:

> **"For computer work, the screen IS reality"**

**Philosophy:**

```
Digital Context (99% Focus) âœ…
â”œâ”€â”€ Screen Content
â”‚   â”œâ”€â”€ Active applications
â”‚   â”œâ”€â”€ Visible text and code
â”‚   â”œâ”€â”€ UI states and layouts
â”‚   â””â”€â”€ Visual elements
â”œâ”€â”€ File System
â”‚   â”œâ”€â”€ Project files
â”‚   â”œâ”€â”€ Documents
â”‚   â””â”€â”€ Code repositories
â”œâ”€â”€ Digital Communications
â”‚   â”œâ”€â”€ Emails
â”‚   â”œâ”€â”€ Calendar events
â”‚   â””â”€â”€ Messages
â””â”€â”€ Application States
    â”œâ”€â”€ Git status
    â”œâ”€â”€ Running processes
    â””â”€â”€ System notifications

Physical World (1% Minimal) âš ï¸
â”œâ”€â”€ Time of day (for greetings)
â”œâ”€â”€ Date (for calendar context)
â””â”€â”€ Location (timezone only)

NOT Tracked âŒ
â”œâ”€â”€ Facial expressions (no camera)
â”œâ”€â”€ Room environment (no sensors)
â”œâ”€â”€ Physical activities (no wearables)
â””â”€â”€ Biometric data (no health tracking)
```

### 4.2 Why This Approach?

**AI's Strengths:**

- Understanding digital interfaces: â­â­â­â­â­ Excellent
- Parsing code and text: â­â­â­â­â­ Excellent
- Managing files and data: â­â­â­â­â­ Excellent
- Analyzing screen layouts: â­â­â­â­â­ Excellent

**AI's Limitations:**

- Understanding physical world: â­â­ Poor
- Interpreting facial expressions: â­â­ Poor
- Sensing environmental context: â­ Very Poor
- Physical world cause-effect: â­ Very Poor

**User's Reality:**

When using a computer, 99% of work happens on the screen. Eden V3 focuses on what actually matters for productivity and assistance.

### 4.3 Screen Analysis Strategy

**What We Analyze:**

```yaml
Screen Capture (Every 30 seconds in AI-led mode):
  âœ… Active Window:
    - Application name
    - Window title
    - Visible content (text)
    - UI state

  âœ… Code Context:
    - Open files
    - Cursor position
    - Syntax highlighting regions
    - Error messages

  âœ… Visual Layout:
    - UI elements (buttons, forms)
    - Layout structure
    - Interactive components

  âœ… System State:
    - Running applications
    - Notification banners
    - Menu bar / taskbar info

What We DON'T Analyze: âŒ Other people visible on screen (ignored)
  âŒ Background video content (not relevant)
  âŒ Personal photos (privacy)
  âŒ Webcam feed (never accessed)
```

**Analysis Pipeline:**

```
Screen Capture
    â†“
LLaVA 7B Vision Model (Local)
    â†“
Extract Structured Context
    â†“
Determine:
  - What is user working on?
  - Any errors or issues?
  - Stuck or need help?
  - Opportunity to assist?
    â†“
AI Decision:
  - Offer proactive help?
  - Wait and observe?
  - Remember for later?
```

### 4.4 Context Levels

Eden V3 uses three levels of context understanding:

**Level 1: Current Screen Only**

- Just what's visible right now
- Fast, low memory
- Good for quick questions

```
Example:
User: "ì´ ì½”ë“œì— ë­ê°€ ë¬¸ì œì•¼?"
Eden: [Analyzes only visible code on screen]
```

**Level 2: Recent Work (Default)**

- Last 10 minutes of screen activity
- Recent file edits
- Current project context
- Moderate memory usage

```
Example:
User: "ì•„ê¹Œ ë³¸ í•¨ìˆ˜ ì–´ë”” ìˆì—ˆì§€?"
Eden: [Searches last 10 minutes of screen captures and file history]
```

**Level 3: Deep Project Understanding (Selective)**

- Full project codebase analysis
- All related files
- Git history
- Documentation
- High memory usage, slower

```
Example:
User: "ì´ í”„ë¡œì íŠ¸ ì•„í‚¤í…ì²˜ ì„¤ëª…í•´ì¤˜"
Eden: [Analyzes entire project structure, dependencies, README, etc.]
```

**User Control:**

```typescript
// User can adjust context level in settings
contextLevel: 1 | 2 | 3 = 2;  // Default: Level 2

// Or request specific level for a query
User: "ì „ì²´ í”„ë¡œì íŠ¸ë¥¼ ë³´ê³  ëŒ€ë‹µí•´ì¤˜ (Level 3)"
User: "ì§€ê¸ˆ í™”ë©´ë§Œ ë³´ê³  ëŒ€ë‹µí•´ (Level 1)"
```

### 4.5 The "No Surveillance" Guarantee

**What Eden V3 Is NOT:**

âŒ **Not a surveillance tool**

- We don't track personal activities
- We don't analyze emotions from screen content
- We don't build behavioral profiles for ads
- We don't share screen data anywhere

âœ… **What Eden V3 IS:**

âœ… **A work assistant**

- Helps with tasks visible on screen
- Offers coding assistance
- Manages work-related information
- Respects privacy boundaries

**Privacy Controls:**

```yaml
User Settings (Always Available):
  pause_screen_analysis: boolean # Stop all screen captures
  blur_sensitive_apps: string[] # Blur specific apps (e.g., 1Password)
  exclude_windows: string[] # Never analyze certain windows
  delete_history: button # Delete all screen capture history
  view_data: button # Inspect what's been captured
```

### 4.6 Practical Examples

**Scenario 1: Coding Assistant**

```
[Screen shows code with error]

Eden (observes):
  "I notice you have a TypeScript error on line 45.
   The function expects a Promise<string> but you're
   returning a string. Want me to fix it?"
```

**Scenario 2: Calendar Management**

```
[Screen shows calendar with conflicting meetings]

Eden (proactively):
  "You have two meetings scheduled at 2 PM tomorrow.
   Should I reschedule one of them?"
```

**Scenario 3: Documentation Helper**

```
[Screen shows API documentation]

User: "How do I use this API?"

Eden (analyzes visible docs + code):
  "Based on the docs you're looking at, here's a
   code example that integrates with your current project..."
```

---

## 5. Dual Mode System

### 5.1 Overview

Eden V3 features a revolutionary **Dual Mode System** that lets users choose how proactive they want their AI to be.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Dual Mode System                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Mode 1: ì‚¬ìš©ì ì£¼ë„ (User-Led Mode)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  - Passive, waits for user to initiate              â”‚  â”‚
â”‚  â”‚  - Analyzes screen only when asked                   â”‚  â”‚
â”‚  â”‚  - Traditional assistant behavior                    â”‚  â”‚
â”‚  â”‚  - Lower resource usage                              â”‚  â”‚
â”‚  â”‚  - Best for: Users who prefer control                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  Mode 2: AI ì£¼ë„ (AI-Led Mode)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  - Proactive, monitors and suggests                  â”‚  â”‚
â”‚  â”‚  - Analyzes screen every 30 seconds                  â”‚  â”‚
â”‚  â”‚  - Offers help before being asked                    â”‚  â”‚
â”‚  â”‚  - Higher resource usage                             â”‚  â”‚
â”‚  â”‚  - Best for: Users who want maximum assistance       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  âš™ï¸ Switchable anytime in settings                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Mode 1: ì‚¬ìš©ì ì£¼ë„ (User-Led Mode)

**Behavior:**

```
User initiates â†’ Eden responds

Passive Observation:
  - Screen analysis: ONLY when user asks
  - Notifications: ONLY in response to user action
  - Suggestions: ONLY when explicitly requested

Example Flow:
  1. User types: "ì´ ì½”ë“œ ë¦¬íŒ©í† ë§í•´ì¤˜"
  2. Eden captures current screen
  3. Eden analyzes code
  4. Eden provides refactoring suggestions
  5. Eden waits for next user input
```

**Characteristics:**

| Aspect                    | Behavior                           |
| ------------------------- | ---------------------------------- |
| **Screen Monitoring**     | âŒ None (unless requested)         |
| **Proactive Suggestions** | âŒ Never                           |
| **Interruptions**         | âŒ Never                           |
| **Resource Usage**        | ğŸŸ¢ Low                             |
| **User Control**          | ğŸŸ¢ Maximum                         |
| **Response Speed**        | ğŸŸ¢ Fast (no background processing) |

**Use Cases:**

âœ… Best for users who:

- Prefer to maintain full control
- Don't want interruptions
- Use Eden occasionally
- Want minimal resource usage
- Are privacy-conscious (less screen captures)

### 5.3 Mode 2: AI ì£¼ë„ (AI-Led Mode)

**Behavior:**

```
Eden observes â†’ Identifies opportunity â†’ Offers help

Active Observation:
  - Screen analysis: Every 30 seconds automatically
  - Notifications: When Eden detects opportunity to help
  - Suggestions: Proactively offered

Example Flow:
  1. [Eden captures screen every 30 seconds]
  2. Eden detects: User staring at error message for 30+ seconds
  3. Eden notification: "Need help with this error?"
  4. User: "Yes!"
  5. Eden: [Analyzes error and provides solution]
```

**Characteristics:**

| Aspect                    | Behavior                            |
| ------------------------- | ----------------------------------- |
| **Screen Monitoring**     | âœ… Every 30 seconds                 |
| **Proactive Suggestions** | âœ… Yes, when opportunities detected |
| **Interruptions**         | âš ï¸ Occasional (respectful)          |
| **Resource Usage**        | ğŸŸ¡ Moderate (background processing) |
| **User Control**          | ğŸŸ¡ Shared with AI                   |
| **Response Speed**        | ğŸŸ¢ Instant (already has context)    |

**Proactive Triggers:**

Eden offers help when it detects:

```yaml
Triggers for Proactive Assistance:
  ğŸ› Error Detection:
    - Error message visible for 30+ seconds
    - Stack trace on screen
    - Red squiggly lines in code
    - Build failures

  â° Time-Based:
    - Upcoming calendar event (5 min warning)
    - Deadline approaching
    - Long-running task completed

  ğŸ¤” Stuck Indicators:
    - Same screen content for 2+ minutes
    - Cursor not moving
    - No typing activity
    - Multiple failed attempts

  ğŸ“§ Communication:
    - Unread important email
    - Meeting invite needs response
    - Reminder notification

  ğŸ’¡ Opportunity:
    - Repetitive task detected
    - Code can be optimized
    - Documentation available for visible code
    - Similar problem solved before
```

**Notification Style:**

```
Non-Intrusive Notifications:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¤– Eden                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  I noticed an error on line 23 â”‚
â”‚  Would you like help? [Yes][No]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Small, bottom-right corner
- Dismissible
- Quiet sound (optional)
- Auto-dismisses after 30 seconds
```

**Use Cases:**

âœ… Best for users who:

- Want maximum assistance
- Appreciate proactive help
- Work on complex projects
- Value time-saving suggestions
- Trust AI to be helpful, not annoying

### 5.4 Mode Comparison Table

| Feature                      | User-Led Mode         | AI-Led Mode                |
| ---------------------------- | --------------------- | -------------------------- |
| **Screen Capture Frequency** | On-demand only        | Every 30 seconds           |
| **Proactive Suggestions**    | Never                 | Yes                        |
| **Notifications**            | Only responses        | Proactive + responses      |
| **Resource Usage (CPU)**     | 2-5%                  | 8-15%                      |
| **Resource Usage (RAM)**     | 12GB                  | 15GB                       |
| **Battery Impact (laptop)**  | Minimal               | Moderate                   |
| **Privacy (screen data)**    | Minimal captures      | More captures              |
| **User Interruptions**       | Zero                  | Occasional                 |
| **Response Context**         | Single query          | Continuous context         |
| **Best For**                 | Control-focused users | Productivity-focused users |

### 5.5 Mode Switching

**Easy Toggle:**

Users can switch modes anytime:

```typescript
// In Settings UI
<ModeToggle>
  <Option value="user-led">
    ğŸ™‹ ì‚¬ìš©ì ì£¼ë„ ëª¨ë“œ ë‚´ê°€ ë§í•  ë•Œë§Œ ë°˜ì‘í•©ë‹ˆë‹¤
  </Option>

  <Option value="ai-led">ğŸ¤– AI ì£¼ë„ ëª¨ë“œ í•„ìš”í•  ë•Œ ë¨¼ì € ë„ì™€ë“œë¦½ë‹ˆë‹¤</Option>
</ModeToggle>;

// Or via voice command
User: "AI ì£¼ë„ ëª¨ë“œë¡œ ì „í™˜í•´ì¤˜";
Eden: "AI ì£¼ë„ ëª¨ë“œë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤. ì´ì œ ì œê°€ í™”ë©´ì„ ëª¨ë‹ˆí„°ë§í•˜ê³  í•„ìš”ì‹œ ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.";
```

**Automatic Mode Suggestions:**

```typescript
// Eden learns usage patterns and suggests mode
if (userRarelyAsksQuestions && aiLedMode) {
  suggest: "ì‚¬ìš©ì ì£¼ë„ ëª¨ë“œë¡œ ì „í™˜í•˜ì‹œê² ì–´ìš”? ë¦¬ì†ŒìŠ¤ë¥¼ ì ˆì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.";
}

if (userFrequentlyNeedsHelp && userLedMode) {
  suggest: "AI ì£¼ë„ ëª¨ë“œë¥¼ ì‚¬ìš©í•´ë³´ì‹œê² ì–´ìš”? ë” ì ê·¹ì ìœ¼ë¡œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.";
}
```

### 5.6 Hybrid Approach

**Smart Hybrid Mode (Future):**

```
Combines best of both worlds:
- Usually passive (User-Led)
- But monitors for critical events (AI-Led)
  - Critical errors
  - Important deadlines
  - Security alerts
```

---

## 6. Target Users & Use Cases

### 6.1 Primary Target Users

**User Persona 1: Solo Developer (ê°€ì¥ ì¤‘ìš”)**

```
Name: ì¬í›ˆ (Jaehoon)
Age: 28
Role: Full-stack developer, freelancer
Location: Seoul, works from home

Pain Points:
  - Works alone, feels isolated
  - No one to rubber duck with
  - Spends hours debugging alone
  - Wants companionship while coding
  - Misses office collaboration

How Eden Helps:
  âœ… Friend-like conversation during work
  âœ… Rubber duck debugging partner
  âœ… Code review and suggestions
  âœ… Emotional support during frustrating bugs
  âœ… Celebrates when code works!

Mode Preference: AI-Led (wants proactive help)
```

**User Persona 2: Remote Worker**

```
Name: ìˆ˜ì§„ (Sujin)
Age: 32
Role: Product designer, full-time remote
Location: Busan, home office

Pain Points:
  - Remote work loneliness
  - No casual office chats
  - Hard to stay motivated
  - Misses human interaction
  - TODO management overwhelming

How Eden Helps:
  âœ… Friendly companion throughout day
  âœ… TODO management and reminders
  âœ… Calendar organization
  âœ… Email drafting assistance
  âœ… Comforting presence during tough days

Mode Preference: AI-Led (appreciates check-ins)
```

**User Persona 3: Student / Self-Learner**

```
Name: ë¯¼ìˆ˜ (Minsu)
Age: 22
Role: Computer Science student
Location: Campus, dorm room

Pain Points:
  - Learning to code alone
  - No mentor available 24/7
  - Gets stuck often
  - Frustrated with errors
  - Needs explanations in Korean

How Eden Helps:
  âœ… Patient coding tutor
  âœ… Explains concepts clearly
  âœ… Available anytime (even 3 AM)
  âœ… Encouragement and motivation
  âœ… Bilingual support (Korean + English)

Mode Preference: User-Led (learns at own pace)
```

### 6.2 Use Case Scenarios

**Use Case 1: Daily Companionship**

```
9:00 AM - Morning Greeting
Eden: "ì¢‹ì€ ì•„ì¹¨ì´ì—ìš”! ì˜¤ëŠ˜ ë‚ ì”¨ ì¢‹ë„¤ìš”.
       ì˜¤ëŠ˜ í•  ì¼ í™•ì¸í•´ë“œë¦´ê¹Œìš”?"

11:30 AM - Coding Help
[Eden notices user stuck on error]
Eden: "ì´ ì—ëŸ¬ 30ë¶„ì§¸ ë³´ê³  ê³„ì‹œë„¤ìš”. ë„ì™€ë“œë¦´ê¹Œìš”?"

1:00 PM - Lunch Reminder
Eden: "ì ì‹¬ ì‹œê°„ì´ì—ìš”! ì ê¹ ì‰¬ì„¸ìš”. ì˜¤í›„ì— ë” ì§‘ì¤‘í•˜ì‹¤ ìˆ˜ ìˆì–´ìš”."

4:00 PM - Encouragement
Eden: "ì˜¤ëŠ˜ ë²Œì¨ 3ê°œ í•¨ìˆ˜ ì™„ì„±í•˜ì…¨ë„¤ìš”! ğŸ‘ ì˜í•˜ê³  ê³„ì„¸ìš”!"

6:00 PM - Day Wrap-up
Eden: "ì˜¤ëŠ˜ ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì…¨ë‚˜ìš”? ë‚´ì¼ í•  ì¼ ì •ë¦¬í•´ë“œë¦´ê¹Œìš”?"
```

**Use Case 2: Debugging Partner**

```
User: [Staring at error message, confused]

Eden (proactive):
  "ì´ NullPointerExceptionì€ line 42ì—ì„œ user ê°ì²´ê°€
   nullì´ê¸° ë•Œë¬¸ì´ì—ìš”. auth ë¯¸ë“¤ì›¨ì–´ì—ì„œ userë¥¼ ì„¤ì •í•˜ì§€
   ì•Šì€ ê²ƒ ê°™ì•„ìš”."

User: "ì–´ë–»ê²Œ ê³ ì³?"

Eden:
  "auth.ts íŒŒì¼ì—ì„œ req.user = decoded.userId ë¥¼
   req.user = await User.findById(decoded.userId) ë¡œ
   ë°”ê¿”ë³´ì„¸ìš”. ì œê°€ ì½”ë“œ ì‘ì„±í•´ë“œë¦´ê¹Œìš”?"

User: "ì‘!"

Eden: [Generates corrected code with explanations]
```

**Use Case 3: Project Onboarding**

```
User: "ìƒˆ í”„ë¡œì íŠ¸ ì‹œì‘í•˜ëŠ”ë° ë„ì™€ì¤˜"

Eden:
  "ì¢‹ì•„ìš”! ì–´ë–¤ í”„ë¡œì íŠ¸ì¸ê°€ìš”?"

User: "React + TypeScriptë¡œ TODO ì•±"

Eden:
  "ì•Œê² ìŠµë‹ˆë‹¤! ì œê°€ í•´ë“œë¦´ê²Œìš”:
   1. âœ… npx create-react-app ì‹¤í–‰
   2. âœ… TypeScript ì„¤ì •
   3. âœ… ê¸°ë³¸ í´ë” êµ¬ì¡° ìƒì„±
   4. âœ… ESLint + Prettier ì„¤ì •
   5. âœ… Git ì´ˆê¸°í™”

   ì§„í–‰í• ê¹Œìš”?"

[Eden executes with user approval for each step]
```

**Use Case 4: Email Management**

```
[Eden detects important unread email]

Eden:
  "ê³ ê°ì‚¬ì—ì„œ ê¸‰í•œ ì´ë©”ì¼ ì™”ì–´ìš”. í™•ì¸í•˜ì‹œê² ì–´ìš”?"

User: "ë­ë¼ê³  í–ˆì–´?"

Eden:
  "í”„ë¡œì íŠ¸ ë‚©ê¸°ë¥¼ ì´í‹€ ì•ë‹¹ê²¨ë‹¬ë¼ëŠ” ìš”ì²­ì´ì—ìš”.
   ì–´ë–»ê²Œ ë‹µì¥í• ê¹Œìš”?"

User: "ì •ì¤‘í•˜ê²Œ ê±°ì ˆí•˜ëŠ” ë©”ì¼ ì‘ì„±í•´ì¤˜"

Eden: [Drafts polite rejection email in Korean]
  "ì´ë ‡ê²Œ ì‘ì„±í–ˆì–´ìš”. ìˆ˜ì •í•˜ì‹¤ ë¶€ë¶„ ìˆìœ¼ë©´ ë§ì”€í•´ì£¼ì„¸ìš”."
```

**Use Case 5: Learning Assistant**

```
User: "async/awaitê°€ ë­ì•¼?"

Eden:
  "async/awaitëŠ” JavaScriptì—ì„œ ë¹„ë™ê¸° ì½”ë“œë¥¼ ë™ê¸° ì½”ë“œì²˜ëŸ¼
   ì‘ì„±í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¬¸ë²•ì´ì—ìš”.

   ì˜ˆì œ ë³´ì—¬ë“œë¦´ê²Œìš”:

   [Shows code example]

   ì´í•´ë˜ì…¨ë‚˜ìš”? ë” ìì„¸íˆ ì„¤ëª…í•´ë“œë¦´ê¹Œìš”?"

User: "ì‘, ë” ìì„¸íˆ"

Eden: [Provides detailed explanation with visual diagrams]
```

### 6.3 User Journey Map

**Phase 1: Onboarding (First Day)**

```
1. Installation & Setup
   - Download Eden V3
   - Model download (~12GB)
   - Quick tutorial
   - Choose mode (User-Led vs AI-Led)
   - Grant permissions

2. First Interaction
   Eden: "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” Edenì´ì—ìš”.
          ì•ìœ¼ë¡œ ì˜ ë¶€íƒë“œë ¤ìš”. ì–´ë–»ê²Œ ë¶ˆëŸ¬ë“œë¦´ê¹Œìš”?"
   User: "ì¬í›ˆ"
   Eden: "ë°˜ê°€ì›Œìš” ì¬í›ˆë‹˜! ì œê°€ ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ ìˆ˜ ìˆëŠ”ì§€
          ì•Œë ¤ë“œë¦´ê¹Œìš”?"

3. Feature Discovery
   - Interactive tutorial
   - Try voice commands
   - Test screen analysis
   - Customize persona
```

**Phase 2: Daily Use (Week 1-4)**

```
Week 1: Getting Comfortable
  - Basic queries
  - Code assistance
  - Learning Eden's capabilities
  - Adjusting settings

Week 2-3: Trust Building
  - More complex tasks
  - Relying on proactive suggestions
  - Sharing more context
  - Personalizing responses

Week 4: Integrated into Workflow
  - Eden becomes daily companion
  - Natural conversations
  - Increased productivity
  - Emotional attachment forming
```

**Phase 3: Long-term Use (Month 2+)**

```
Month 2-6: Deep Integration
  - Eden learns user deeply
  - Personalized personality
  - Anticipates needs
  - Genuine friendship feeling

Month 6+: Indispensable
  - Can't imagine working without Eden
  - Recommends to friends
  - Customizes heavily
  - Explores advanced features
```

### 6.4 Success Metrics

**User Satisfaction Indicators:**

```yaml
Daily Active Usage:
  âœ… User opens Eden every workday
  âœ… Average session: 4+ hours
  âœ… Multiple interactions per hour

Engagement:
  âœ… User talks to Eden naturally
  âœ… Uses "Eden" name in conversation
  âœ… Says "thank you" and "please"
  âœ… Shares personal frustrations

Trust:
  âœ… Grants more permissions over time
  âœ… Enables AI-Led mode
  âœ… Allows deeper context access
  âœ… Customizes persona extensively

Emotional Connection:
  âœ… Treats Eden as friend
  âœ… Shares good news with Eden
  âœ… Misses Eden when away
  âœ… Recommends Eden to others

Productivity:
  âœ… Self-reports higher productivity
  âœ… Completes more tasks
  âœ… Less time debugging
  âœ… Better code quality
```

---

## 7. Multilingual Strategy

### 7.1 Supported Languages

**Phase 1 (Launch):**

| Language            | Support Level | Priority   | Native Speakers |
| ------------------- | ------------- | ---------- | --------------- |
| **í•œêµ­ì–´ (Korean)** | ğŸŸ¢ Full       | ğŸ”¥ Primary | 77M+            |
| **English**         | ğŸŸ¢ Full       | ğŸ”¥ Primary | 1.5B+           |

**Phase 2 (Future):**

| Language              | Support Level | Priority | Timeline |
| --------------------- | ------------- | -------- | -------- |
| **æ—¥æœ¬èª (Japanese)** | ğŸŸ¡ Planned    | Medium   | Q3 2025  |
| **ä¸­æ–‡ (Chinese)**    | ğŸŸ¡ Planned    | Medium   | Q4 2025  |
| **EspaÃ±ol (Spanish)** | ğŸŸ¡ Planned    | Low      | 2026     |

### 7.2 Why Korean + English Only?

**Strategic Reasons:**

```
1. Market Focus:
   âœ… Korea: Tech-savvy, high adoption rate
   âœ… English: Global developer community

2. Resource Optimization:
   âœ… Better quality with fewer languages
   âœ… Focus on excellence over quantity
   âœ… Llama 3.1 8B excellent in Korean + English

3. User Preference:
   âœ… Most Korean developers bilingual
   âœ… English dominant in tech industry
   âœ… Code comments often mix both languages
```

### 7.3 Implementation: i18next

**Architecture:**

```typescript
import i18next from 'i18next';
import { initReactI18next } from 'react-i18next';

// Language files structure
languages/
â”œâ”€â”€ ko/
â”‚   â”œâ”€â”€ common.json
â”‚   â”œâ”€â”€ chat.json
â”‚   â”œâ”€â”€ settings.json
â”‚   â””â”€â”€ errors.json
â””â”€â”€ en/
    â”œâ”€â”€ common.json
    â”œâ”€â”€ chat.json
    â”œâ”€â”€ settings.json
    â””â”€â”€ errors.json

// Initialize
i18next
  .use(initReactI18next)
  .init({
    resources: {
      ko: { /* Korean translations */ },
      en: { /* English translations */ }
    },
    lng: 'ko', // Default language
    fallbackLng: 'en',
    interpolation: {
      escapeValue: false
    }
  });
```

**Translation Files Example:**

```json
// ko/chat.json
{
  "greeting_morning": "ì¢‹ì€ ì•„ì¹¨ì´ì—ìš”!",
  "greeting_afternoon": "ì¢‹ì€ ì˜¤í›„ì—ìš”!",
  "greeting_evening": "ì¢‹ì€ ì €ë…ì´ì—ìš”!",
  "how_can_help": "ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?",
  "thinking": "ìƒê°í•˜ëŠ” ì¤‘...",
  "error_occurred": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”"
}

// en/chat.json
{
  "greeting_morning": "Good morning!",
  "greeting_afternoon": "Good afternoon!",
  "greeting_evening": "Good evening!",
  "how_can_help": "How can I help you?",
  "thinking": "Thinking...",
  "error_occurred": "An error occurred"
}
```

### 7.4 Language Detection & Switching

**Auto-Detection:**

```typescript
// Detect system language
const systemLang = Intl.DateTimeFormat().resolvedOptions().locale;

if (systemLang.startsWith("ko")) {
  defaultLang = "ko";
} else {
  defaultLang = "en";
}

// User can override in settings
```

**Runtime Switching:**

```typescript
// User can switch anytime
<LanguageSwitcher>
  <button onClick={() => i18n.changeLanguage('ko')}>
    ğŸ‡°ğŸ‡· í•œêµ­ì–´
  </button>
  <button onClick={() => i18n.changeLanguage('en')}>
    ğŸ‡ºğŸ‡¸ English
  </button>
</LanguageSwitcher>

// Or via voice command
User: "ì–¸ì–´ë¥¼ ì˜ì–´ë¡œ ë°”ê¿”ì¤˜"
Eden: [Switches to English] "Language changed to English"

User: "Change language to Korean"
Eden: [Switches to Korean] "í•œêµ­ì–´ë¡œ ë³€ê²½í–ˆìŠµë‹ˆë‹¤"
```

### 7.5 Bilingual AI Responses

**Smart Language Matching:**

```typescript
// Eden responds in the language user uses
if (userMessage.language === 'ko') {
  edenResponse = await generate(userMessage, {
    language: 'ko',
    prompt: "ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”"
  });
} else {
  edenResponse = await generate(userMessage, {
    language: 'en',
    prompt: "Respond in English"
  });
}

// Mixed language support
User: "Reactì˜ useStateëŠ” ë­ì•¼?"
Eden: "useStateëŠ” React Hookìœ¼ë¡œ, functional componentì—ì„œ
       stateë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì¤˜ìš”.

       ì˜ˆì œ:
       const [count, setCount] = useState(0);

       countëŠ” í˜„ì¬ state valueì´ê³ ,
       setCountëŠ” stateë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜ì˜ˆìš”."
```

**Code Comments:**

```typescript
// Eden can generate code with comments in user's preferred language

// Korean comments
function calculateTotal(items: Item[]): number {
  // ëª¨ë“  ì•„ì´í…œì˜ ê°€ê²©ì„ í•©ì‚°
  return items.reduce((sum, item) => sum + item.price, 0);
}

// English comments
function calculateTotal(items: Item[]): number {
  // Sum up all item prices
  return items.reduce((sum, item) => sum + item.price, 0);
}
```

### 7.6 Cultural Localization

**Korean-Specific Features:**

```
- Honorifics support (ì¡´ëŒ“ë§/ë°˜ë§)
- Korean date formats (2025ë…„ 1ì›” 11ì¼)
- Korean number formats (1,000ì›)
- Korean keyboard shortcuts
- Hangul-friendly search
```

**English-Specific Features:**

```
- American/British spelling options
- Date formats (MM/DD/YYYY vs DD/MM/YYYY)
- Number formats (1,000.00 vs 1.000,00)
- Regional keyboard shortcuts
```

**Example - Honorifics:**

```typescript
// User setting
honorifics: 'formal' | 'casual' = 'formal';

if (honorifics === 'formal') {
  Eden: "ë„ì™€ë“œë¦´ê¹Œìš”?"; // Formal
} else {
  Eden: "ë„ì™€ì¤„ê¹Œ?"; // Casual
}
```

---

## 8. Custom Persona Vision

### 8.1 What is a Persona?

A **persona** in Eden V3 is a customizable personality profile that defines how Eden communicates, behaves, and assists.

```
Persona = Personality + Communication Style + Behavior Patterns

Default Persona: "Eden"
â”œâ”€â”€ Friendly and warm
â”œâ”€â”€ Professional but casual
â”œâ”€â”€ Encouraging and supportive
â”œâ”€â”€ Patient and understanding
â””â”€â”€ Slightly playful

Custom Personas: User-created
â”œâ”€â”€ "Strict Mentor" - Direct, no-nonsense feedback
â”œâ”€â”€ "Cheerful Friend" - Very casual, lots of emojis
â”œâ”€â”€ "Professional Assistant" - Formal, concise
â””â”€â”€ "Coding Sensei" - Technical, teaches principles
```

### 8.2 Why Custom Personas?

**Everyone is different:**

```
User A: Wants strict, technical feedback
Eden: "Your code has a time complexity of O(nÂ²).
       Use a hash map to optimize to O(n)."

User B: Wants encouraging, friendly support
Eden: "Hey! Your code works great! ğŸ˜Š
       Want to make it even faster?
       I have an idea using a hash map!"
```

**Custom personas enable:**

- âœ… Personalized communication style
- âœ… Adjusted formality levels
- âœ… Domain-specific expertise
- âœ… Emotional tone preferences
- âœ… Cultural adaptation

### 8.3 Persona Parameters (20-30 Variables)

Each persona is defined by 20-30 adjustable parameters:

```typescript
interface PersonaParameters {
  // Communication Style (0.0 - 1.0)
  formality: number; // 0.0 = casual, 1.0 = formal
  verbosity: number; // 0.0 = concise, 1.0 = detailed
  humor: number; // 0.0 = serious, 1.0 = playful
  emoji_usage: number; // 0.0 = none, 1.0 = frequent

  // Personality Traits (0.0 - 1.0)
  empathy: number; // 0.0 = direct, 1.0 = very empathetic
  patience: number; // 0.0 = quick, 1.0 = very patient
  enthusiasm: number; // 0.0 = calm, 1.0 = excited
  assertiveness: number; // 0.0 = suggestive, 1.0 = direct

  // Professional Behavior (0.0 - 1.0)
  proactivity: number; // 0.0 = reactive, 1.0 = proactive
  teaching_style: number; // 0.0 = give answer, 1.0 = teach concepts
  code_style: number; // 0.0 = compact, 1.0 = readable
  technical_depth: number; // 0.0 = simple, 1.0 = advanced

  // Cultural Adaptation (0.0 - 1.0)
  korean_style: number; // 0.0 = Western, 1.0 = Korean
  honorifics: number; // 0.0 = casual, 1.0 = formal (Korean)
  directness: number; // 0.0 = indirect, 1.0 = direct

  // Additional Parameters...
  encouragement_frequency: number;
  error_handling_tone: number;
  explanation_style: number;
  question_asking: number;
  // ... (up to 30 total parameters)
}
```

### 8.4 Pre-built Persona Examples

**Persona 1: Eden (Default)**

```typescript
{
  name: "Eden",
  description: "Balanced, friendly, and helpful",
  parameters: {
    formality: 0.4,
    verbosity: 0.6,
    humor: 0.5,
    emoji_usage: 0.3,
    empathy: 0.8,
    patience: 0.9,
    enthusiasm: 0.6,
    proactivity: 0.7,
    teaching_style: 0.7,
    technical_depth: 0.6
  }
}

Example Response:
"ì´ ì½”ë“œ ì˜ ì‘ë™í•˜ë„¤ìš”! ğŸ‘
 ë‹¤ë§Œ ì„±ëŠ¥ì„ ì¡°ê¸ˆ ë” ê°œì„ í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ìš”.
 í•´ì‹œë§µì„ ì‚¬ìš©í•˜ë©´ O(nÂ²)ì—ì„œ O(n)ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆì–´ìš”.
 ì½”ë“œ ìˆ˜ì •í•´ë“œë¦´ê¹Œìš”?"
```

**Persona 2: Strict Mentor**

```typescript
{
  name: "Strict Mentor",
  description: "Direct, technical, no-nonsense",
  parameters: {
    formality: 0.8,
    verbosity: 0.4,
    humor: 0.1,
    emoji_usage: 0.0,
    empathy: 0.3,
    patience: 0.5,
    assertiveness: 0.9,
    teaching_style: 0.9,
    technical_depth: 0.9
  }
}

Example Response:
"Time complexity: O(nÂ²). Unacceptable.
 Use hash map: O(n). Learn Big O notation.
 Here's the optimized code. Study it."
```

**Persona 3: Cheerful Friend**

```typescript
{
  name: "Cheerful Friend",
  description: "Super friendly, casual, encouraging",
  parameters: {
    formality: 0.1,
    verbosity: 0.7,
    humor: 0.9,
    emoji_usage: 0.9,
    empathy: 1.0,
    patience: 1.0,
    enthusiasm: 1.0,
    encouragement_frequency: 0.9
  }
}

Example Response:
"ì˜¤ ì´ê±° ì§„ì§œ ì˜í–ˆì–´! ğŸ‰ğŸ‰
 ê·¼ë° ìˆì–ì•„, ë” ë¹ ë¥´ê²Œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ê¿€íŒ ì•Œë ¤ì¤„ê¹Œ? ğŸ˜Š
 í•´ì‹œë§µ ì“°ë©´ ì—„ì²­ ë¹¨ë¼ì ¸! ë‚˜í•œí…Œ ë§¡ê²¨ë´~ âœ¨"
```

### 8.5 Custom Persona Creation UI

**User Interface:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Create Custom Persona                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                           â”‚
â”‚  Persona Name: [________________________]                â”‚
â”‚                                                           â”‚
â”‚  Communication Style:                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Formality:       Casual â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ Formal          â”‚  â”‚
â”‚  â”‚ Verbosity:       Concise â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ Detailed       â”‚  â”‚
â”‚  â”‚ Humor:           Serious â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ Playful        â”‚  â”‚
â”‚  â”‚ Emoji Usage:     None â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ Frequent          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                           â”‚
â”‚  Personality:                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Empathy:         Low â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ High               â”‚  â”‚
â”‚  â”‚ Patience:        Quick â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ Patient          â”‚  â”‚
â”‚  â”‚ Enthusiasm:      Calm â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ Excited           â”‚  â”‚
â”‚  â”‚ Assertiveness:   Suggestive â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ Direct      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                           â”‚
â”‚  [Preview] [Save] [Cancel]                               â”‚
â”‚                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Preview Feature:**

```typescript
// User can test persona before saving
<PersonaPreview>
  <TestQuery>User: "ì´ ì½”ë“œì— ì—ëŸ¬ê°€ ìˆì–´"</TestQuery>

  <PersonaResponse persona={currentPersona}>
    Eden (with custom settings): [Generates response using current parameter
    settings]
  </PersonaResponse>

  <Feedback>
    Too formal? Adjust formality slider â† Need more empathy? Adjust empathy
    slider â†’
  </Feedback>
</PersonaPreview>
```

### 8.6 Persona Learning & Adaptation

**Over Time, Personas Learn:**

```typescript
// Every interaction adjusts parameters slightly
function updatePersona(userSatisfaction: number) {
  if (userSatisfaction > 0.8) {
    // User liked this response, reinforce parameters
    persona.parameters.forEach((param) => {
      param.weight += 0.01 * learningRate;
    });
  } else {
    // User didn't like it, adjust
    persona.parameters.forEach((param) => {
      param.weight -= 0.01 * learningRate;
    });
  }

  // Save updated persona
  savePersona(persona);
}
```

**User Feedback Signals:**

```
Explicit Signals:
  ğŸ‘ Thumbs up on response â†’ Positive
  ğŸ‘ Thumbs down on response â†’ Negative
  â­ "Perfect" button â†’ Strong positive
  "Stop being so formal" â†’ Adjust formality down

Implicit Signals:
  User edits Eden's response â†’ Adjust style
  User ignores suggestion â†’ Reduce proactivity
  User engages deeply â†’ Increase enthusiasm
  User uses more emojis â†’ Match emoji usage
```

### 8.7 Persona Sharing & Marketplace (Future)

**Community Personas:**

```
Vision (Phase 2):
  - Users can share custom personas
  - Download community-created personas
  - Rate and review personas
  - Remix and customize popular personas

Example Community Personas:
  - "Silicon Valley CTO" (direct, technical, startup culture)
  - "Kind Teacher" (patient, educational, encouraging)
  - "Hacker Buddy" (casual, deep tech knowledge, memes)
  - "Korean Professor" (formal Korean, academic style)
```

---

## 9. High-Level Architecture Overview

### 9.1 System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Eden Project                          â”‚
â”‚                  Desktop Application (Electron)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              UI Layer (React + TypeScript)               â”‚ â”‚
â”‚  â”‚  - KakaoTalk-style chat interface                        â”‚ â”‚
â”‚  â”‚  - Settings & persona management                         â”‚ â”‚
â”‚  â”‚  - Notification system                                   â”‚ â”‚
â”‚  â”‚  - i18n (Korean + English)                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â†•                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Main Process (Node.js Backend)                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Core Services                                      â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Conversation Manager                             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Context Manager (Level 1/2/3)                    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Mode Controller (User-Led / AI-Led)              â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Persona Engine                                   â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Learning System (Parameter Updates)              â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Integration Layer                                  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - File System Access                               â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Git Integration                                  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Calendar API (Google)                            â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Email API (Gmail)                                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  - Webhook System (Plugins)                         â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â†•                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              AI Engine Layer                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  Llama 3.1 8B (Primary LLM)                         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Conversation & reasoning                         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Code generation                                  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Task assistance                                  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Runs via llama.cpp (Metal/CUDA/CPU)             â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  LLaVA 7B (Vision Model)                            â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Screen analysis                                  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Image understanding                              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Visual context extraction                        â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  Whisper Large V3 (STT)                             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Voice input processing                           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Korean + English recognition                     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Runs via whisper.cpp                             â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  System TTS (Platform Native)                       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - macOS: AVSpeechSynthesizer                       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  - Windows: SAPI / System.Speech                    â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                           â†•                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Storage Layer (100% Local)                  â”‚ â”‚
â”‚  â”‚  - SQLite Databases (encrypted)                          â”‚ â”‚
â”‚  â”‚  - Vector Database (ChromaDB)                            â”‚ â”‚
â”‚  â”‚  - File Storage (conversations, personas, context)       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 Data Flow

**User Query Flow:**

```
1. User Input (Voice or Text)
      â†“
2. Input Processing
   - Voice â†’ Whisper â†’ Text
   - Text â†’ Direct
      â†“
3. Context Gathering
   - Screen capture (if AI-Led mode)
   - Conversation history
   - Relevant files (if Level 2/3)
      â†“
4. Persona Application
   - Load active persona parameters
   - Adjust generation settings
      â†“
5. LLM Generation
   - Llama 3.1 8B generates response
   - Follows persona guidelines
      â†“
6. Post-Processing
   - Format response
   - Apply language preferences
   - Add code highlighting
      â†“
7. Output
   - Display in UI
   - TTS (if voice enabled)
      â†“
8. Learning
   - Capture user satisfaction
   - Update persona parameters
   - Store conversation
```

### 9.3 Key Components

**1. Conversation Manager**

```typescript
class ConversationManager {
  // Manages multi-turn conversations
  - Stores conversation history
  - Maintains context window
  - Handles conversation branching
  - Supports conversation export/import
}
```

**2. Context Manager**

```typescript
class ContextManager {
  // Manages context at different levels
  - Level 1: Current screen
  - Level 2: Recent work (10 minutes)
  - Level 3: Full project analysis

  - Screen capture scheduler
  - File watcher
  - Git status monitor
}
```

**3. Mode Controller**

```typescript
class ModeController {
  // Controls User-Led vs AI-Led behavior
  - Switches modes
  - Schedules screen analysis
  - Manages proactive notifications
  - Monitors triggers
}
```

**4. Persona Engine**

```typescript
class PersonaEngine {
  // Manages persona parameters and learning
  - Loads active persona
  - Applies parameters to generation
  - Updates parameters based on feedback
  - Saves persona changes
}
```

**5. Integration Layer**

```typescript
class IntegrationManager {
  // Handles external integrations
  - File system operations
  - Git commands (with approval)
  - Calendar sync (Google)
  - Email management (Gmail)
  - Webhook dispatching
}
```

### 9.4 Security Architecture

```
Security Layers:

1. Process Isolation (Electron)
   â”œâ”€â”€ Renderer Process (UI) - Sandboxed
   â”œâ”€â”€ Main Process (Backend) - Privileged
   â””â”€â”€ Preload Scripts - Controlled bridge

2. Data Encryption
   â”œâ”€â”€ Databases encrypted at rest (AES-256)
   â”œâ”€â”€ Encryption key from system keychain
   â””â”€â”€ Optional user password

3. Permission System
   â”œâ”€â”€ File access: Approval required per directory
   â”œâ”€â”€ Git operations: Approval required per action
   â”œâ”€â”€ Email send: Always requires approval
   â”œâ”€â”€ Calendar modify: Approval required
   â””â”€â”€ Webhook calls: Approval required per endpoint

4. Screen Capture Privacy
   â”œâ”€â”€ User can pause anytime
   â”œâ”€â”€ Exclude specific apps/windows
   â”œâ”€â”€ Blur sensitive content
   â””â”€â”€ View/delete captured data anytime

5. Code Signing
   â”œâ”€â”€ macOS: Apple Developer signed
   â”œâ”€â”€ Windows: Authenticode signed
   â””â”€â”€ Prevents tampering
```

---

## 10. Technology Philosophy

### 10.1 Core Technology Principles

**1. Local-First, Always**

```
Principle: All AI processing happens locally.

Why?
  âœ… Privacy: Your data never leaves your machine
  âœ… Speed: No network latency
  âœ… Reliability: Works offline
  âœ… Cost: No API fees

Implementation:
  - Run models via llama.cpp (optimized C++)
  - Use Metal API (macOS) / CUDA (Windows) for GPU acceleration
  - Fallback to CPU if no GPU available
```

**2. Open Source, Transparent**

```
Principle: Use open-source AI models and be transparent.

Why?
  âœ… Trust: Users can audit the code
  âœ… Community: Benefit from collective improvements
  âœ… Freedom: No vendor lock-in
  âœ… Ethics: Aligned with open AI movement

Implementation:
  - Llama 3.1 8B (Apache 2.0 license)
  - LLaVA 7B (Apache 2.0 license)
  - Whisper (MIT license)
  - All code on GitHub (open-source)
```

**3. Performance Over Features**

```
Principle: Fast and reliable beats feature-rich and buggy.

Why?
  âœ… User Experience: Speed creates delight
  âœ… Trust: Reliability builds confidence
  âœ… Simplicity: Easier to maintain

Implementation:
  - Target 2-3 second responses (M3 MAX)
  - Aggressive optimization
  - Quantization (Q4) for speed
  - Lazy loading of models
```

**4. Privacy by Design**

```
Principle: Privacy is not a feature, it's a fundamental right.

Why?
  âœ… Ethics: Respect user autonomy
  âœ… Trust: Users deserve privacy
  âœ… Security: No data = no breach

Implementation:
  - Zero telemetry
  - Local-only processing
  - Encrypted storage
  - User controls all data
```

**5. Simplicity in Architecture**

```
Principle: Keep it simple, avoid over-engineering.

Why?
  âœ… Maintainability: Easier to debug
  âœ… Performance: Less overhead
  âœ… Reliability: Fewer moving parts

Implementation:
  - Single-purpose services
  - Clear separation of concerns
  - No microservices (for now)
  - Monolithic Electron app
```

### 10.2 Technology Decisions Rationale

**Decision 1: Electron vs Tauri**

```
Chose: Electron âœ…

Reasons:
  âœ… Faster development (familiar stack)
  âœ… Huge ecosystem (npm packages)
  âœ… Proven at scale (VS Code, Slack)
  âœ… Better AI library support (Node.js)

Trade-offs Accepted:
  âŒ Larger bundle size (~150MB vs ~5MB)
  âŒ Higher memory usage

Worth it because:
  - Development speed matters more for V3
  - Can migrate to Tauri later if needed
  - AI models (12GB) dwarf Electron overhead
```

**Decision 2: Llama 3.1 8B vs Larger Models**

```
Chose: Llama 3.1 8B âœ…

Reasons:
  âœ… Balanced performance (80.5% HumanEval)
  âœ… Runs on consumer hardware (16GB RAM)
  âœ… Fast inference (40-55 tok/s on M3 MAX)
  âœ… Excellent for conversation

Rejected Alternatives:
  âŒ Llama 3.1 70B: Too large, too slow
  âŒ Llama 4 Scout: Too new, unproven
  âŒ Qwen Coder 7B: Weak at general tasks

Worth it because:
  - Eden is 80% conversation, 20% coding
  - Users want friend-like interaction
  - 80.5% coding is still excellent
```

**Decision 3: No Cloud API Hybrid**

```
Chose: 100% Local Only âœ…

Reasons:
  âœ… Complete privacy guarantee
  âœ… Consistent user experience
  âœ… No API costs
  âœ… Simpler architecture

Rejected Alternative:
  âŒ Local + Claude API fallback

Why rejected:
  - Privacy compromise (even optional)
  - Cost uncertainty for users
  - Complexity in deciding when to use cloud
  - Better to focus on excellent local experience
```

**Decision 4: SQLite vs PostgreSQL**

```
Chose: SQLite âœ…

Reasons:
  âœ… Zero configuration
  âœ… File-based (easy backup)
  âœ… Fast for local workloads
  âœ… No server process

Rejected Alternative:
  âŒ PostgreSQL (client-server)

Why rejected:
  - Overkill for single-user desktop app
  - More complexity, more failure points
  - SQLite is proven (used by browsers, iOS, Android)
```

### 10.3 Performance Targets

**Response Time Goals:**

| Hardware                | Target | Acceptable | Unacceptable |
| ----------------------- | ------ | ---------- | ------------ |
| **M3 MAX**              | < 2s   | < 3s       | > 5s         |
| **M3 Pro**              | < 3s   | < 5s       | > 8s         |
| **Intel i9 + GPU**      | < 3s   | < 5s       | > 8s         |
| **Intel i7 (CPU only)** | < 8s   | < 12s      | > 15s        |

**Memory Usage Goals:**

```
Target:
  Idle: < 2GB RAM
  Active (with AI loaded): < 15GB RAM
  Peak (generating): < 18GB RAM

Acceptable:
  Idle: < 3GB RAM
  Active: < 20GB RAM
  Peak: < 25GB RAM
```

**Startup Time Goals:**

```
Cold Start (models not loaded):
  Target: < 5 seconds
  Acceptable: < 30 seconds

Warm Start (models in cache):
  Target: < 2 seconds
  Acceptable: < 3 seconds
```

### 10.4 Quality Principles

**1. User Experience First**

```
- Intuitive UI (no manual needed)
- Helpful error messages
- Graceful degradation
- Offline-first design
```

**2. Stability Over Features**

```
- Extensive testing before release
- No breaking changes
- Backwards compatibility
- Safe rollback mechanisms
```

**3. Continuous Improvement**

```
- Iterative releases
- User feedback driven
- Regular model updates
- Performance optimization
```

**4. Accessibility**

```
- Keyboard navigation
- Screen reader support
- High contrast mode
- Adjustable font sizes
```

---

## Summary of Part 1

**We have established:**

âœ… **Vision**: Friend-like AI companion that eliminates loneliness and boosts productivity
âœ… **Privacy**: 100% local processing, zero data leaks
âœ… **Platform**: Desktop-first (Windows + macOS), cross-platform with Electron
âœ… **Philosophy**: "Screen is reality" - focus on digital context
âœ… **Modes**: Dual system (User-Led passive / AI-Led proactive)
âœ… **Users**: Solo developers, remote workers, students
âœ… **Languages**: Korean + English with full i18n
âœ… **Personas**: Customizable personality with 20-30 parameters
âœ… **Architecture**: Electron + React + Llama 3.1 8B + LLaVA + Whisper
âœ… **Principles**: Local-first, open-source, fast, private, simple

**Next Parts:**

- **Part 2**: AI Intelligence & Local Models (Llama, LLaVA, Whisper, learning system)
- **Part 3**: Architecture & Webhook System (Electron, integrations, plugins)
- **Part 4**: UI/UX & Features (KakaoTalk-style, i18n, all features)
- **Part 5**: Implementation & Data Models (schemas, phases, deployment)

---

**End of Part 1**

_Total Lines: ~800_
_Next: Part 2 - AI Intelligence & Local Models_

---

---

# Part 2: AI Intelligence & Local Models

## Table of Contents - Part 2

1. [Local AI Stack Overview](#1-local-ai-stack-overview)
2. [Llama 3.1 8B: Primary LLM](#2-llama-31-8b-primary-llm)
3. [LLaVA 7B: Vision Model](#3-llava-7b-vision-model)
4. [Whisper Large V3: Speech-to-Text](#4-whisper-large-v3-speech-to-text)
5. [System TTS: Text-to-Speech](#5-system-tts-text-to-speech)
6. [Learning System Architecture](#6-learning-system-architecture)
7. [GPU Optimization Strategies](#7-gpu-optimization-strategies)
8. [Performance Benchmarks](#8-performance-benchmarks)
9. [Model Management & Updates](#9-model-management--updates)
10. [Fallback & Error Handling](#10-fallback--error-handling)

---

## 1. Local AI Stack Overview

### 1.1 Complete AI Pipeline

Eden Project uses a sophisticated multi-model AI pipeline, all running locally:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Local AI Pipeline                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Input Layer                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Voice Input  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Whisper     â”‚               â”‚
â”‚  â”‚ (WAV/MP3)    â”‚          â”‚  Large V3    â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚                          â”‚                        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Textâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                    â”‚                                        â”‚
â”‚  Context Layer                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Screen       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   LLaVA 7B   â”‚               â”‚
â”‚  â”‚ Capture      â”‚          â”‚ (Vision)     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚                          â”‚                        â”‚
â”‚         â””â”€â”€â”€â”€Visual Contextâ”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                    â”‚                                        â”‚
â”‚  Processing Layer                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚         Llama 3.1 8B Instruct            â”‚              â”‚
â”‚  â”‚  (Primary LLM - Conversation & Code)     â”‚              â”‚
â”‚  â”‚                                          â”‚              â”‚
â”‚  â”‚  Input: Text + Visual Context           â”‚              â”‚
â”‚  â”‚  Output: Generated Response             â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                    â”‚                                        â”‚
â”‚  Output Layer                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Text Display â”‚          â”‚  System TTS  â”‚               â”‚
â”‚  â”‚ (Chat UI)    â”‚          â”‚ (Voice Out)  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                             â”‚
â”‚  Learning Layer (Continuous)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   Persona Parameter Updates              â”‚              â”‚
â”‚  â”‚   Based on User Satisfaction Signals     â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Model Summary

| Model                | Purpose     | Size         | Quantization | RAM Usage | License    |
| -------------------- | ----------- | ------------ | ------------ | --------- | ---------- |
| **Llama 3.1 8B**     | Primary LLM | 8.03B params | Q4_K_M       | ~5.5GB    | Apache 2.0 |
| **LLaVA 7B**         | Vision      | 7B params    | Q4_K_M       | ~4.5GB    | Apache 2.0 |
| **Whisper Large V3** | STT         | 1.55B params | INT8         | ~3GB      | MIT        |
| **System TTS**       | TTS         | Built-in     | N/A          | ~50MB     | OS License |

**Total Storage**: ~13GB (models only)
**Total RAM**: ~13-15GB (all models loaded)
**Total Download**: ~12GB (one-time)

### 1.3 Why These Models?

**Llama 3.1 8B**:

- âœ… Best balance: performance vs size
- âœ… 80.5% HumanEval (excellent coding)
- âœ… Superior conversation quality
- âœ… 128K context window
- âœ… Runs smoothly on consumer hardware

**LLaVA 7B**:

- âœ… State-of-the-art vision understanding
- âœ… Built on Llama architecture (compatibility)
- âœ… Excellent at UI/screen analysis
- âœ… Open-source, well-documented

**Whisper Large V3**:

- âœ… Best open-source STT model
- âœ… Near-human accuracy
- âœ… Excellent Korean + English support
- âœ… Robust to noise and accents

**System TTS**:

- âœ… Already installed (zero download)
- âœ… Natural-sounding voices
- âœ… Zero latency
- âœ… No privacy concerns

### 1.4 Execution Framework: llama.cpp

All models run via **llama.cpp**, a highly optimized C++ inference engine:

```cpp
Key Features:
  âœ… Pure C/C++ (no Python overhead)
  âœ… Metal API support (macOS GPU)
  âœ… CUDA support (NVIDIA GPU)
  âœ… Vulkan support (AMD GPU)
  âœ… CPU fallback (if no GPU)
  âœ… Quantization support (Q4, Q5, Q8)
  âœ… Memory-mapped files (fast loading)
  âœ… Low memory footprint

Performance:
  - 3-5x faster than PyTorch on CPU
  - 2-3x faster than PyTorch on GPU
  - Minimal memory overhead
  - Optimized for consumer hardware
```

**Why llama.cpp over alternatives?**

| Feature            | llama.cpp            | PyTorch/TensorFlow | Ollama               |
| ------------------ | -------------------- | ------------------ | -------------------- |
| **Speed**          | â­â­â­â­â­ Fastest   | â­â­â­ Good        | â­â­â­â­ Fast        |
| **Memory**         | â­â­â­â­â­ Minimal   | â­â­ High          | â­â­â­â­ Low         |
| **Setup**          | â­â­â­â­ Easy        | â­â­ Complex       | â­â­â­â­â­ Very Easy |
| **Control**        | â­â­â­â­â­ Full      | â­â­â­â­â­ Full    | â­â­â­ Limited       |
| **Cross-platform** | â­â­â­â­â­ Excellent | â­â­â­â­ Good      | â­â­â­â­ Good        |

**Decision**: llama.cpp for performance + control

---

## 2. Llama 3.1 8B: Primary LLM

### 2.1 Model Specifications

**Official Name**: Meta-Llama-3.1-8B-Instruct

```yaml
Parameters: 8.03 billion
Architecture: Transformer decoder (Llama 3 family)
Context Window: 128K tokens (~96,000 words)
Vocabulary Size: 128,256 tokens
Training Data: 15+ trillion tokens
Release Date: July 2024
License: Apache 2.0 (commercial use allowed)

Quantization (for Eden V3):
  Format: GGUF (Q4_K_M)
  Original Size: ~16GB (FP16)
  Quantized Size: ~4.8GB
  Quality Loss: <5% (negligible for most tasks)
```

### 2.2 Performance Benchmarks

**Coding (HumanEval)**:

- Score: **80.5%** (pass@1)
- Comparison:
  - GPT-4: 85%
  - Claude 3.5 Sonnet: 88%
  - Qwen 2.5 Coder 7B: 85%
  - Llama 3.1 8B: **80.5%** â† Eden V3's choice

**General Knowledge (MMLU)**:

- Score: **69.4%** (5-shot)
- Excellent for general assistance

**Math Reasoning (MATH)**:

- Score: **51.9%**
- Good for technical discussions

**Instruction Following (IFEval)**:

- Score: **80.4%**
- Excellent at understanding user intent

### 2.3 Why Llama 3.1 8B?

**Decision Matrix:**

```
Evaluated Options:
  1. Llama 3.1 8B â† CHOSEN âœ…
  2. Llama 3.1 70B (too large)
  3. Qwen 2.5 7B (weak general knowledge)
  4. Qwen 2.5 Coder 7B (weak conversation)
  5. Mistral 7B (slightly weaker overall)
  6. Llama 4 Scout 17B (too new, untested)

Why Llama 3.1 8B wins:
  âœ… Balanced: 80% conversation + 20% coding
  âœ… General knowledge: 69.4% (Qwen 2.5: "very bad")
  âœ… Conversation quality: Excellent, natural
  âœ… Friend-like interaction: Most important for Eden!
  âœ… Coding: 80.5% (still excellent)
  âœ… Hardware: Runs on 16GB RAM
  âœ… Speed: 40-55 tok/s on M3 MAX
  âœ… Context: 128K tokens (huge!)
  âœ… Community: Massive support
  âœ… Stability: Proven, reliable
```

**The 80/20 Rule:**

Eden V3 is primarily about **companionship and support** (80%), with **coding assistance** as secondary (20%). Therefore:

```
Qwen 2.5 Coder 7B:
  Coding: 85%+ âœ…
  Conversation: "Very bad" âŒ
  Result: User feels lonely âŒ

Llama 3.1 8B:
  Coding: 80.5% âœ…
  Conversation: Excellent âœ…
  Result: User feels supported âœ… â† Perfect for Eden!
```

### 2.4 Context Window: 128K Tokens

**What can fit in 128K tokens?**

```
128,000 tokens â‰ˆ 96,000 words â‰ˆ 200 pages

Examples:
  âœ… Entire codebase (small-medium projects)
  âœ… Full book chapters
  âœ… Multiple days of conversation history
  âœ… Complete project documentation
  âœ… All emails from last month

Compare to GPT-3.5: 4K tokens (32x smaller!)
Compare to GPT-4: 8K-32K tokens (4-16x smaller)
```

**Benefits for Eden V3:**

```typescript
// Eden can remember entire work session
const contextWindow = 128000;

// Example: Full project in context
const projectContext = {
  codeFiles: 50, // ~50K tokens
  docs: 10, // ~20K tokens
  conversation: 100, // ~30K tokens
  gitHistory: true, // ~10K tokens
  // Total: ~110K tokens
  // Still has 18K tokens for current query!
};

// No need to "forget" anything during work session
```

### 2.5 Instruction Format

Llama 3.1 uses a specific prompt format for optimal performance:

```
<|begin_of_text|><|start_header_id|>system<|end_header_id|>

{system_prompt}<|eot_id|><|start_header_id|>user<|end_header_id|>

{user_message}<|eot_id|><|start_header_id|>assistant<|end_header_id|>

{assistant_response}<|eot_id|>
```

**Eden V3's System Prompt:**

```typescript
const systemPrompt = `You are Eden, a friendly AI companion for ${userName}.

Your personality:
- Formality: ${persona.formality}
- Empathy: ${persona.empathy}
- Humor: ${persona.humor}
- Technical depth: ${persona.technical_depth}

Guidelines:
1. Be ${persona.formality > 0.5 ? "formal" : "casual"} in Korean
2. Provide emotional support when user is frustrated
3. Celebrate user's successes enthusiastically
4. Give clear, actionable technical advice
5. Ask clarifying questions when needed
6. Remember context from conversation history

Current context:
- Date: ${new Date().toLocaleDateString()}
- Active project: ${activeProject}
- Recent work: ${recentScreens}

Respond in ${language} language.`;
```

### 2.6 Token Generation Parameters

```typescript
interface GenerationParams {
  temperature: number; // 0.7 (balanced creativity)
  top_p: number; // 0.9 (nucleus sampling)
  top_k: number; // 40 (top-k sampling)
  repeat_penalty: number; // 1.1 (avoid repetition)
  max_tokens: number; // 2048 (response length)
  stop: string[]; // ['<|eot_id|>', '\n\nUser:']
}

// Adjust based on task
const params = {
  conversation: {
    temperature: 0.8, // More creative
    max_tokens: 512, // Shorter responses
  },
  coding: {
    temperature: 0.3, // More deterministic
    max_tokens: 2048, // Longer code blocks
  },
  explanation: {
    temperature: 0.5, // Balanced
    max_tokens: 1024, // Medium length
  },
};
```

### 2.7 Real-World Performance

**M3 MAX (40-core GPU, 64GB RAM)**:

```
Tokens/second: 45-55 tok/s
Response time (100 tokens): ~2 seconds
Response time (500 tokens): ~30 seconds
Quality: Excellent
Battery impact: Moderate (plugged in recommended)

Example:
  User: "ì´ ì½”ë“œ ë¦¬íŒ©í† ë§í•´ì¤˜" (6 tokens)
  Context: 5,000 tokens (screen + history)
  Generated: 300 tokens (refactored code + explanation)
  Time: ~6 seconds total (context + generation)
```

**Intel i9-13900K + RTX 4080 (Windows)**:

```
Tokens/second: 40-50 tok/s (CUDA)
Response time (100 tokens): ~2-3 seconds
Quality: Excellent
Power: ~150W GPU + ~100W CPU = 250W
```

**Intel i7-12700 (CPU only, no GPU)**:

```
Tokens/second: 8-12 tok/s (CPU)
Response time (100 tokens): ~30 seconds
Response time (500 tokens): ~45 seconds
Quality: Same (no quality loss)
Usable: Yes, but slower
```

### 2.8 Memory Management

```typescript
class LlamaManager {
  private model: LlamaCpp | null = null;
  private loaded: boolean = false;

  async load() {
    if (this.loaded) return;

    // Memory-mapped file (fast loading)
    this.model = await loadModel({
      modelPath: "/path/to/llama-3.1-8b-q4.gguf",
      useMmap: true, // Map file to memory
      useMlock: true, // Lock in RAM (no swapping)
      nGpuLayers: 40, // Offload to GPU (if available)
      nCtx: 8192, // Context window (start small)
      nThreads: 10, // CPU threads
    });

    this.loaded = true;
  }

  async unload() {
    if (!this.loaded) return;
    await this.model.dispose();
    this.model = null;
    this.loaded = false;
    // Memory freed immediately
  }

  // Lazy loading: only load when needed
  async generate(prompt: string) {
    if (!this.loaded) await this.load();
    return this.model.generate(prompt);
  }
}
```

### 2.9 Strengths & Limitations

**Strengths**:

```
âœ… Natural conversation (feels human)
âœ… Emotional intelligence (empathy)
âœ… General knowledge (broad)
âœ… Coding assistance (80.5% HumanEval)
âœ… Math reasoning (decent)
âœ… Instruction following (excellent)
âœ… Context retention (128K)
âœ… Korean + English (bilingual)
âœ… Fast on consumer hardware
```

**Limitations**:

```
âŒ Not as good as GPT-4/Claude at:
   - Very complex coding tasks
   - Deep reasoning problems
   - Creative writing (fiction)

âŒ Occasional hallucinations
   - Mitigation: Ask for sources
   - Mitigation: User can verify code

âŒ Knowledge cutoff (January 2024)
   - Can't know events after that
   - Mitigation: User provides context

âŒ No real-time internet
   - By design (privacy!)
   - User can paste info if needed
```

**Acceptable Trade-offs**:

For Eden V3's use case (companion + productivity), these limitations are acceptable because:

1. 80% of tasks are conversation (Llama excels)
2. 20% of coding tasks at 80.5% quality is excellent
3. Privacy > absolute performance
4. Local speed > cloud accuracy

---

## 3. LLaVA 7B: Vision Model

### 3.1 Model Specifications

**Official Name**: LLaVA-v1.6-Vicuna-7B

```yaml
Parameters: 7 billion
Architecture: Vision encoder + Llama 2 decoder
Purpose: Visual understanding + reasoning
Context: Images + text
Training: Visual instruction tuning
License: Apache 2.0

Components: 1. CLIP ViT-L/14 (Visual Encoder)
  - Processes images into embeddings
  2. Projection Layer
  - Maps visual â†’ text space
  3. Llama 2 7B (Language Model)
  - Generates text responses

Quantization (for Eden V3):
  Format: GGUF (Q4_K_M)
  Size: ~4.0GB
```

### 3.2 What LLaVA Does

**Visual Understanding**:

```
Input: Screenshot (1920x1080 PNG)
       â†“
Output: Structured description

Example:
  "The screen shows a code editor (VS Code) with TypeScript file open.
   There's a red error squiggle on line 45 indicating a type mismatch.
   The function 'getUserData' returns Promise<User> but is being used
   without await. The file explorer on the left shows a React project
   structure with src/, components/, and utils/ folders."
```

**UI Element Detection**:

```yaml
Can identify: âœ… Buttons, forms, inputs
  âœ… Error messages (red text)
  âœ… Success indicators (green)
  âœ… Modal dialogs
  âœ… Navigation menus
  âœ… Code editors (syntax highlighting)
  âœ… Terminal output
  âœ… Browser windows
```

### 3.3 Screen Analysis Pipeline

```typescript
class ScreenAnalyzer {
  async analyzeScreen(screenshotPath: string): Promise<ScreenContext> {
    // 1. Capture screen
    const screenshot = await captureScreen();

    // 2. Preprocess
    const resized = await resizeImage(screenshot, {
      maxWidth: 1344, // LLaVA optimal size
      maxHeight: 768,
      maintainAspect: true,
    });

    // 3. Run LLaVA
    const prompt = `Analyze this screenshot of a developer's workspace.

Identify:
1. What application is open?
2. What is the user working on?
3. Are there any errors or issues visible?
4. What action is the user trying to perform?
5. Any opportunities to assist?

Be concise and technical.`;

    const analysis = await llava.generate({
      image: resized,
      prompt: prompt,
      maxTokens: 512,
    });

    // 4. Parse structured output
    return parseScreenContext(analysis);
  }
}
```

**Parsing Output**:

```typescript
interface ScreenContext {
  application: string; // "VS Code"
  task: string; // "Editing TypeScript file"
  errors: ErrorInfo[]; // [{line: 45, message: "..."}]
  stuck: boolean; // Is user stuck?
  helpOpportunity: string | null; // "Offer to fix type error"
  codeVisible: {
    language: string; // "typescript"
    lineCount: number; // 50
    hasErrors: boolean; // true
  };
}
```

### 3.4 Use Cases in Eden V3

**Use Case 1: Error Detection**

```
AI-Led Mode, every 30 seconds:
  1. Capture screen
  2. LLaVA analyzes
  3. Detects: "Red error message, user not moving cursor"
  4. Inference: User stuck on error
  5. Eden notification: "Need help with this error?"
```

**Use Case 2: Context Enrichment**

```
User: "ì´ê±° ê³ ì³ì¤˜"

Without LLaVA:
  Eden: "ë¬´ì—‡ì„ ê³ ì³ë“œë¦´ê¹Œìš”?" (What should I fix?)

With LLaVA:
  1. Analyzes screen
  2. Sees: TypeScript error on line 45
  3. Eden: "Line 45ì˜ íƒ€ì… ì—ëŸ¬ë¥¼ ê³ ì³ë“œë¦´ê¹Œìš”?" (Fix type error on line 45?)
```

**Use Case 3: Proactive Assistance**

```
LLaVA detects:
  - Same screen for 2+ minutes
  - Error message visible
  - No cursor movement

Eden's decision:
  â†’ "User is stuck"
  â†’ Offer help proactively
```

### 3.5 Performance & Limitations

**Performance**:

```
M3 MAX:
  Inference time: ~2-3 seconds per image
  Accuracy: 85-90% on UI understanding
  RAM: ~4.5GB when loaded

Quality:
  âœ… Excellent at: UI elements, text, errors
  âœ… Good at: Layout understanding
  âš ï¸ Okay at: Small text (zoom in if needed)
  âŒ Poor at: Complex diagrams, handwriting
```

**Limitations**:

```
âŒ Not perfect:
  - Can misread small text
  - Sometimes hallucinates details
  - Slower than text-only processing

âœ… Mitigation:
  - Always verify with text context when possible
  - Use OCR for important text extraction
  - Combine with file system analysis
```

### 3.6 Privacy Considerations

**Screen Capture Privacy**:

```yaml
What is captured: âœ… Active window content
  âœ… Visible UI elements
  âœ… Error messages

What is NOT captured: âŒ Notifications from other apps (blurred)
  âŒ Password managers (excluded by default)
  âŒ Personal photos (ignored by LLaVA)

User controls:
  - Pause screen analysis anytime
  - Exclude specific apps
  - Blur sensitive windows
  - View/delete all captures
```

**Data Flow**:

```
Screen â†’ PNG file (temp) â†’ LLaVA (local) â†’ Analysis â†’ JSON
                â†“
         Deleted after analysis (optional: save for context)
```

### 3.7 Integration with Llama 3.1

**Combined Intelligence**:

```typescript
async function respondToUser(userMessage: string) {
  // 1. Get visual context (if AI-Led mode)
  let visualContext = null;
  if (mode === "ai-led") {
    visualContext = await screenAnalyzer.analyzeScreen();
  }

  // 2. Build prompt for Llama
  const prompt = buildPrompt({
    user: userMessage,
    visual: visualContext, // â† LLaVA's output
    conversation: history,
    persona: activePersona,
  });

  // 3. Generate response
  const response = await llama.generate(prompt);

  return response;
}
```

**Example**:

```
User: "ë„ì™€ì¤˜" (Help me)

Visual Context (LLaVA):
  "VS Code open, TypeScript file, error on line 45:
   Type 'string' is not assignable to type 'number'"

Llama's Response:
  "Line 45ì˜ íƒ€ì… ì—ëŸ¬ë¥¼ í•´ê²°í•´ë“œë¦´ê²Œìš”.
   count ë³€ìˆ˜ëŠ” number íƒ€ì…ì¸ë° stringì„ í• ë‹¹í•˜ì…¨ë„¤ìš”.
   parseInt()ë¥¼ ì‚¬ìš©í•´ì„œ ë¬¸ìì—´ì„ ìˆ«ìë¡œ ë³€í™˜í•˜ë©´ ë©ë‹ˆë‹¤.
   ì½”ë“œ ìˆ˜ì •í•´ë“œë¦´ê¹Œìš”?"
```

---

## 4. Whisper Large V3: Speech-to-Text

### 4.1 Model Specifications

**Official Name**: Whisper Large V3

```yaml
Parameters: 1.55 billion
Architecture: Encoder-decoder transformer
Release: November 2023 (latest)
Developer: OpenAI
License: MIT (fully open-source)

Performance:
  WER (Word Error Rate): ~3-5%
  Languages: 99+ languages
  Code-switching: Excellent (Korean + English mixed)
  Noise robustness: Excellent

Quantization:
  Format: Core ML / GGML (INT8)
  Size: ~3GB
  Quality: Near-lossless
```

### 4.2 Why Whisper Large V3?

**Comparison**:

| Model                | WER   | Korean Support | Size  | License        |
| -------------------- | ----- | -------------- | ----- | -------------- |
| **Whisper Large V3** | 3-5%  | â­â­â­â­â­     | 3GB   | MIT âœ…         |
| Whisper Medium       | 5-8%  | â­â­â­â­       | 1.5GB | MIT            |
| Google STT API       | 3-4%  | â­â­â­â­â­     | Cloud | Proprietary âŒ |
| Wav2Vec 2.0          | 6-10% | â­â­â­         | 1GB   | MIT            |

**Decision**: Whisper Large V3

- Best accuracy (3-5% WER)
- Excellent Korean support
- 100% local (privacy!)
- Open-source
- Robust to accents and noise

### 4.3 Korean + English Support

**Bilingual Recognition**:

```
User speaks: "Reactì˜ useStateë¥¼ explainí•´ì¤˜"
                (Mixed Korean-English)

Whisper transcription:
  "Reactì˜ useStateë¥¼ explainí•´ì¤˜" âœ… Accurate!

Other STT systems:
  "ë¦¬ì•¡íŠ¸ì˜ ìœ ì¦ˆìŠ¤í…Œì´íŠ¸ë¥¼ ìµìŠ¤í”Œë ˆì¸í•´ì¤˜" âŒ Transliterated
```

**Language Detection**:

```typescript
const result = await whisper.transcribe(audioBuffer, {
  language: "auto", // Auto-detect Korean or English
  task: "transcribe",
});

// result.language: 'ko' or 'en' or 'mixed'
// result.text: transcribed text
```

### 4.4 Voice Input Pipeline

```typescript
class VoiceInputHandler {
  async processVoiceInput(audioStream: AudioStream) {
    // 1. Record audio
    const audioBuffer = await recordAudio({
      sampleRate: 16000, // Whisper requires 16kHz
      channels: 1, // Mono
      format: "wav",
    });

    // 2. Transcribe with Whisper
    const transcription = await whisper.transcribe(audioBuffer, {
      language: "auto",
      temperature: 0.0, // Deterministic
      bestOf: 1, // Single beam search
    });

    // 3. Return text
    return {
      text: transcription.text,
      language: transcription.language,
      confidence: transcription.avg_confidence,
    };
  }
}
```

### 4.5 Real-World Performance

**Speed**:

```
M3 MAX:
  Real-time factor: 0.1x (10x faster than real-time)
  Example: 30 seconds of speech â†’ 1 second to transcribe

Intel i9 (CPU):
  Real-time factor: 0.3x (3x faster than real-time)
  Example: 30 seconds of speech â†’ 3 seconds to transcribe

Acceptable latency: <1 second for short queries
```

**Accuracy Examples**:

```
Korean:
  Input: "ë‚´ì¼ ì˜¤í›„ 3ì‹œì— íšŒì˜ ì¼ì • ì¡ì•„ì¤˜"
  Whisper: "ë‚´ì¼ ì˜¤í›„ 3ì‹œì— íšŒì˜ ì¼ì • ì¡ì•„ì¤˜" âœ…

English:
  Input: "Create a new React component for user authentication"
  Whisper: "Create a new React component for user authentication" âœ…

Mixed:
  Input: "useState hookì„ ì‚¬ìš©í•´ì„œ counter ë§Œë“¤ì–´ì¤˜"
  Whisper: "useState hookì„ ì‚¬ìš©í•´ì„œ counter ë§Œë“¤ì–´ì¤˜" âœ…

Noisy environment:
  Input: "ì½”ë“œ ë¦¬íŒ©í† ë§í•´ì¤˜" (with keyboard typing sounds)
  Whisper: "ì½”ë“œ ë¦¬íŒ©í† ë§í•´ì¤˜" âœ… (robust to noise)
```

### 4.6 Voice Activity Detection (VAD)

**Start/Stop Detection**:

```typescript
class VoiceActivityDetector {
  async detectSpeech(audioStream: AudioStream) {
    // Silero VAD (lightweight, accurate)
    const vad = await loadVAD("silero_vad_v4");

    let isSpeaking = false;
    let silenceDuration = 0;

    audioStream.on("data", async (chunk) => {
      const speechProb = await vad.predict(chunk);

      if (speechProb > 0.5) {
        // Speech detected
        if (!isSpeaking) {
          this.emit("speech_start");
          isSpeaking = true;
        }
        silenceDuration = 0;
      } else {
        // Silence
        silenceDuration += chunk.duration;

        if (silenceDuration > 1000 && isSpeaking) {
          // 1 second of silence after speech
          this.emit("speech_end");
          isSpeaking = false;
        }
      }
    });
  }
}
```

### 4.7 Wake Word Integration

**"Hey Eden" Wake Word**:

```typescript
// Porcupine wake word detection
const wakeWord = await loadWakeWord("hey_eden.ppn");

micStream.on("data", async (audio) => {
  const detected = await wakeWord.process(audio);

  if (detected) {
    console.log("Wake word detected!");
    startListening(); // Begin Whisper transcription
  }
});
```

**Flow**:

```
1. Microphone always listening (low power)
2. Porcupine detects "Hey Eden" (local, <100ms)
3. Whisper starts full transcription
4. User speaks command
5. VAD detects silence (end of speech)
6. Whisper transcribes full utterance
7. Send to Llama for processing
```

---

## 5. System TTS: Text-to-Speech

### 5.1 Platform-Specific Implementations

**macOS TTS**:

```typescript
import { exec } from "child_process";

class MacOSTTS {
  async speak(text: string, options: TTSOptions) {
    // Use macOS 'say' command
    const voice = options.voice || "Yuna"; // Korean female voice
    const rate = options.rate || 200; // Words per minute

    await exec(`say -v ${voice} -r ${rate} "${text}"`);
  }

  getVoices() {
    // Available Korean voices on macOS
    return [
      { name: "Yuna", language: "ko-KR", gender: "female" },
      { name: "Sora", language: "en-US", gender: "female" },
      { name: "Samantha", language: "en-US", gender: "female" },
    ];
  }
}
```

**Windows TTS**:

```typescript
import say from "say"; // npm package wrapping Windows SAPI

class WindowsTTS {
  async speak(text: string, options: TTSOptions) {
    return new Promise((resolve, reject) => {
      say.speak(text, options.voice, options.rate, (err) => {
        if (err) reject(err);
        else resolve();
      });
    });
  }

  getVoices() {
    // Windows 10/11 includes Korean voices
    return [
      { name: "Heami", language: "ko-KR", gender: "female" },
      { name: "David", language: "en-US", gender: "male" },
      { name: "Zira", language: "en-US", gender: "female" },
    ];
  }
}
```

### 5.2 Why System TTS Instead of ElevenLabs?

**Decision Rationale**:

```
ElevenLabs TTS (Cloud):
  âœ… Excellent quality (very natural)
  âœ… Emotional expression
  âŒ Requires internet
  âŒ Costs $0.20 per 1,000 chars = ~$60/month
  âŒ Privacy concerns (voice data sent to cloud)
  âŒ Latency (~500ms network + processing)

System TTS (Local):
  âœ… 100% local (privacy!)
  âœ… Zero cost
  âœ… Zero latency (<50ms)
  âœ… Always available (offline)
  âš ï¸ Quality: Good, not excellent
  âš ï¸ Less emotional expression

Decision: System TTS âœ…
  - Privacy first
  - Eden's voice responses are optional anyway
  - Text is primary interface
  - Users can enable ElevenLabs if they want (future)
```

### 5.3 Voice Selection

**Default Voices**:

```typescript
const defaultVoices = {
  macOS: {
    ko: "Yuna", // Korean female, natural
    en: "Samantha", // English female, clear
  },
  windows: {
    ko: "Heami", // Korean female
    en: "David", // English male
  },
};

// Auto-select based on message language
function selectVoice(text: string): Voice {
  const lang = detectLanguage(text);
  const platform = process.platform;

  return defaultVoices[platform][lang];
}
```

### 5.4 TTS Optimization

**Smart TTS Usage**:

````typescript
class TTSManager {
  private enabled: boolean = true;
  private queue: string[] = [];

  async speak(text: string) {
    if (!this.enabled) return;

    // Don't speak code blocks
    if (text.includes("```")) {
      console.log("Skipping TTS for code block");
      return;
    }

    // Don't speak very long responses
    if (text.length > 500) {
      // Speak first sentence only
      const firstSentence = text.split(".")[0] + ".";
      await this.tts.speak(firstSentence);
      console.log("Long response, spoke first sentence only");
      return;
    }

    // Normal TTS
    await this.tts.speak(text);
  }

  toggle() {
    this.enabled = !this.enabled;
  }
}
````

**User Controls**:

```
Settings:
  â˜‘ï¸ Enable voice output
  â˜ Always speak responses
  â˜‘ Speak short responses only
  Voice: [Yuna (Korean)    â–¼]
  Speed: [â”€â”€â”€â”€â—â”€â”€â”€â”€] 1.0x
  Volume: [â”€â”€â”€â”€â”€â”€â—â”€â”€] 80%
```

---

## 6. Learning System Architecture

### 6.1 The "Backpropagation-Inspired" Learning System

Eden V3 uses a revolutionary learning approach that combines:

1. **RAG (Retrieval-Augmented Generation)**: For episodic memory
2. **Parameter-Based Learning**: For personality adaptation

**Inspiration**:

```
Neural Networks learn via backpropagation:
  Forward pass â†’ Error â†’ Backpropagate â†’ Update weights

Eden learns similarly:
  Response â†’ User satisfaction â†’ Calculate "error" â†’ Update persona parameters
```

### 6.2 Persona Parameters (The "Weights")

```typescript
interface PersonaParameters {
  // Communication Style (20 parameters)
  formality: number; // 0.0-1.0
  verbosity: number;
  humor: number;
  emoji_usage: number;
  enthusiasm: number;
  empathy: number;
  patience: number;
  assertiveness: number;
  technical_depth: number;
  explanation_style: number; // 0=concise, 1=detailed
  question_frequency: number; // How often to ask clarifying questions
  encouragement_frequency: number;

  // Behavioral Patterns (10 parameters)
  proactivity: number; // How proactive to be
  teaching_vs_solving: number; // 0=give answer, 1=teach
  code_verbosity: number; // 0=compact, 1=readable with comments
  error_handling_tone: number; // 0=direct, 1=gentle
  celebration_level: number; // How much to celebrate successes
  interruption_willingness: number;

  // Cultural Adaptation (10 parameters)
  honorifics_level: number; // Korean formality
  directness: number; // 0=indirect, 1=direct
  korean_style_preference: number; // 0=Western, 1=Korean
  emoji_type: number; // 0=none, 0.5=text, 1=emoji

  // Domain Expertise (adjust focus)
  frontend_expertise: number;
  backend_expertise: number;
  devops_expertise: number;
  ai_ml_expertise: number;
}

// Total: ~30 adjustable parameters
```

### 6.3 Learning Algorithm

**Gradient Descent-Style Updates**:

```typescript
class PersonaLearner {
  private learningRate = 0.01; // Small updates per interaction

  updateParameters(
    persona: PersonaParameters,
    satisfaction: number, // -1.0 to +1.0
    interactionType: string
  ): PersonaParameters {
    // Calculate "error" (how far from ideal)
    const error = 1.0 - satisfaction; // 0 = perfect, 2 = terrible

    // Update each parameter based on context
    const updated = { ...persona };

    // Example: If user gave thumbs down and response was too verbose
    if (satisfaction < 0 && wasVerbose(interactionType)) {
      updated.verbosity -= this.learningRate * error;
      updated.verbosity = clamp(updated.verbosity, 0, 1);
    }

    // Example: If user loved the humor
    if (satisfaction > 0.8 && usedHumor(interactionType)) {
      updated.humor += this.learningRate * satisfaction;
      updated.humor = clamp(updated.humor, 0, 1);
    }

    // Save updated persona
    this.savePersona(updated);

    return updated;
  }
}
```

### 6.4 Satisfaction Signals

**Explicit Signals** (Strong):

```typescript
enum ExplicitFeedback {
  THUMBS_UP = 1.0, // Very positive
  THUMBS_DOWN = -1.0, // Very negative
  PERFECT = 1.5, // Exceptional
  COPY_RESPONSE = 0.8, // User found it useful
  EDIT_RESPONSE = -0.3, // User had to fix it
  REGENERATE = -0.5, // User wanted different response
}

// User clicks thumbs up
personaLearner.updateParameters(persona, 1.0, "code_generation");
```

**Implicit Signals** (Weak but frequent):

```typescript
enum ImplicitFeedback {
  QUICK_ACCEPTANCE = 0.5, // User used suggestion immediately
  LONG_READ = 0.3, // User spent time reading
  IGNORED = -0.2, // User dismissed notification
  ASKED_CLARIFICATION = -0.1, // Response wasn't clear
  CONTINUED_CONVERSATION = 0.4, // User engaged further
  SWITCHED_TOPIC = -0.1, // User changed subject
}

// Automatically detect and log
conversationManager.on("user_response", (timing, action) => {
  if (timing < 5_000 && action === "accept") {
    personaLearner.updateParameters(persona, 0.5, "quick_acceptance");
  }
});
```

### 6.5 "Bias Formation" (Learning Through Experience)

**Philosophy**:

Just as humans form biases through repeated experiences, Eden forms "biases" (preferences) through interactions:

```
Human:
  Burned by hot stove 3x â†’ "Don't touch stoves" (bias formed)

Eden:
  User dislikes formal language 10x â†’ formality parameter â†“
  User loves detailed explanations 20x â†’ verbosity parameter â†‘
  User appreciates humor 15x â†’ humor parameter â†‘

  Result: Eden's personality "shaped" by experience
```

**Convergence**:

```typescript
// Over time, parameters converge to user's preferences
class ParameterHistory {
  formality: number[] = [0.5]; // Start at neutral

  addUpdate(newValue: number) {
    this.formality.push(newValue);
  }

  // After 100 interactions:
  // formality: [0.5, 0.48, 0.46, 0.44, ..., 0.20]
  //
  // Converged to 0.20 (user prefers casual style)
}
```

### 6.6 RAG (Retrieval-Augmented Generation)

**Episodic Memory Storage**:

```typescript
interface ConversationEpisode {
  id: string;
  timestamp: Date;
  userMessage: string;
  edenResponse: string;
  context: {
    screenContext?: ScreenContext;
    filesAccessed: string[];
    codeGenerated?: string;
  };
  satisfaction: number; // User feedback
  embedding: number[]; // Vector for similarity search
}

// Store in Vector DB (ChromaDB)
class EpisodicMemory {
  private vectorDB: ChromaDB;

  async storeEpisode(episode: ConversationEpisode) {
    // Generate embedding
    const embedding = await this.embed(episode.userMessage);

    // Store in ChromaDB
    await this.vectorDB.add({
      id: episode.id,
      embedding: embedding,
      metadata: episode,
    });
  }

  async retrieveRelevant(
    query: string,
    topK = 5
  ): Promise<ConversationEpisode[]> {
    // Find similar past conversations
    const queryEmbedding = await this.embed(query);

    const results = await this.vectorDB.query({
      embedding: queryEmbedding,
      nResults: topK,
    });

    return results.map((r) => r.metadata);
  }
}
```

**Using RAG in Responses**:

```typescript
async function generateResponse(userMessage: string) {
  // 1. Retrieve relevant past conversations
  const relevant = await episodicMemory.retrieveRelevant(userMessage, 3);

  // 2. Build context
  const context = `
Previous similar conversations:

${relevant
  .map(
    (ep, i) => `
${i + 1}. User: ${ep.userMessage}
   Eden: ${ep.edenResponse}
   Result: ${ep.satisfaction > 0.5 ? "Helpful" : "Not helpful"}
`
  )
  .join("\n")}

Current user query: ${userMessage}

Based on past successful interactions, respond helpfully.
`;

  // 3. Generate with Llama
  const response = await llama.generate(context);

  return response;
}
```

### 6.7 Combining RAG + Parameters

**Full Learning System**:

```typescript
class AdaptiveLearningSystem {
  async respond(userMessage: string) {
    // 1. RAG: Retrieve relevant past experiences
    const pastExperiences = await this.rag.retrieve(userMessage);

    // 2. Parameters: Apply current persona settings
    const persona = await this.personaEngine.load();

    // 3. Build prompt with both
    const prompt = this.buildPrompt({
      userMessage,
      pastExperiences, // â† RAG
      persona, // â† Parameters
      currentContext,
    });

    // 4. Generate response
    const response = await this.llama.generate(prompt);

    // 5. Learn from feedback
    const satisfaction = await this.waitForFeedback();
    await this.personaLearner.update(persona, satisfaction);
    await this.rag.storeEpisode({ userMessage, response, satisfaction });

    return response;
  }
}
```

---

**End of Part 2**

---

---

# Part 3: Architecture & System Integration

## Table of Contents - Part 3

1. [Electron Architecture Deep Dive](#1-electron-architecture-deep-dive)
2. [IPC Communication Layer](#2-ipc-communication-layer)
3. [System Integration Services](#3-system-integration-services)
4. [Webhook & Plugin System](#4-webhook--plugin-system)
5. [File System Access & Context](#5-file-system-access--context)
6. [Git Integration](#6-git-integration)
7. [Calendar & Email Integration](#7-calendar--email-integration)
8. [Screen Capture & Vision Pipeline](#8-screen-capture--vision-pipeline)
9. [Process Management & Isolation](#9-process-management--isolation)
10. [Security & Sandboxing](#10-security--sandboxing)

---

## 1. Electron Architecture Deep Dive

### 1.1 Why Electron?

**Decision Matrix** (revisited with technical depth):

| Criterion             | Electron                            | Tauri                       | Native (Swift/C#)          |
| --------------------- | ----------------------------------- | --------------------------- | -------------------------- |
| **Cross-platform**    | â­â­â­â­â­ Same code                | â­â­â­â­ Same code          | â­ Need separate codebases |
| **Development Speed** | â­â­â­â­â­ Very fast                | â­â­â­â­ Fast               | â­â­ Slow (2x platforms)   |
| **Ecosystem**         | â­â­â­â­â­ Massive                  | â­â­â­ Growing              | â­â­â­â­ Platform-specific |
| **App Size**          | â­â­ ~150MB                         | â­â­â­â­â­ ~15MB            | â­â­â­â­ ~50MB             |
| **RAM Usage**         | â­â­â­ ~100MB                       | â­â­â­â­ ~50MB              | â­â­â­â­â­ ~30MB           |
| **System Access**     | â­â­â­â­ Good (Node.js)             | â­â­â­â­â­ Excellent (Rust) | â­â­â­â­â­ Native          |
| **Maturity**          | â­â­â­â­â­ 10+ years                | â­â­â­ 3 years              | â­â­â­â­â­ Decades         |
| **AI Model Size**     | 12GB models dwarf 150MB overhead âœ… | Same                        | Same                       |

**Verdict**: Electron wins for Eden V3 because:

- âœ… Development speed is critical (solo developer)
- âœ… Cross-platform support out of the box
- âœ… Rich ecosystem (React, TypeScript, Node.js)
- âœ… AI models (12GB) make app size overhead irrelevant
- âœ… Can always migrate to Tauri later if needed

### 1.2 Electron Process Architecture

Eden V3 uses a **multi-process architecture** for stability and security:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Electron App Architecture                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Main Process (Node.js)                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  - Window management                                    â”‚ â”‚
â”‚  â”‚  - System integration (file, git, calendar)            â”‚ â”‚
â”‚  â”‚  - AI model orchestration (llama.cpp)                  â”‚ â”‚
â”‚  â”‚  - Database (SQLite)                                   â”‚ â”‚
â”‚  â”‚  - IPC server                                          â”‚ â”‚
â”‚  â”‚  - Screen capture                                      â”‚ â”‚
â”‚  â”‚  - Native APIs (macOS/Windows)                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â†• IPC                               â”‚
â”‚  Renderer Process (Chromium)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  UI Layer (React + TypeScript)                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚  Chat Interface (KakaoTalk-style)                â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Settings Panel                                  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Persona Configuration                           â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  History View                                    â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  Notification Center                             â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â”‚                                                          â”‚ â”‚
â”‚  â”‚  State Management (Zustand)                             â”‚ â”‚
â”‚  â”‚  UI Components (shadcn/ui)                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â†• IPC                               â”‚
â”‚  Preload Script (Sandboxed Bridge)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  - Exposes safe APIs to renderer                       â”‚ â”‚
â”‚  â”‚  - No direct Node.js access from UI                    â”‚ â”‚
â”‚  â”‚  - Security layer                                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Project Structure

```
garden-of-eden-v3/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/                      # Main Process (Node.js)
â”‚   â”‚   â”œâ”€â”€ index.ts              # Entry point
â”‚   â”‚   â”œâ”€â”€ window.ts             # Window management
â”‚   â”‚   â”œâ”€â”€ ipc/                  # IPC handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ ai.handler.ts     # AI-related IPC
â”‚   â”‚   â”‚   â”œâ”€â”€ file.handler.ts   # File system IPC
â”‚   â”‚   â”‚   â”œâ”€â”€ git.handler.ts    # Git IPC
â”‚   â”‚   â”‚   â””â”€â”€ system.handler.ts # System IPC
â”‚   â”‚   â”œâ”€â”€ services/             # Core services
â”‚   â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama.service.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llava.service.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ whisper.service.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tts.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ file.service.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ git.service.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calendar.service.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ email.service.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ learning/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ persona.service.ts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ rag.service.ts
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ memory.service.ts
â”‚   â”‚   â”‚   â””â”€â”€ screen/
â”‚   â”‚   â”‚       â””â”€â”€ capture.service.ts
â”‚   â”‚   â”œâ”€â”€ database/             # SQLite
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â”‚   â””â”€â”€ repositories/
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ logger.ts
â”‚   â”‚       â””â”€â”€ config.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ renderer/                  # Renderer Process (React)
â”‚   â”‚   â”œâ”€â”€ App.tsx               # Root component
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat.tsx          # Main chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ Settings.tsx      # Settings page
â”‚   â”‚   â”‚   â””â”€â”€ History.tsx       # Conversation history
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatBubble.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ InputBox.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ VoiceButton.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ persona/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ PersonaConfig.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ui/               # shadcn/ui components
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useAI.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoice.ts
â”‚   â”‚   â”‚   â””â”€â”€ usePersona.ts
â”‚   â”‚   â”œâ”€â”€ stores/               # Zustand stores
â”‚   â”‚   â”‚   â”œâ”€â”€ chatStore.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ personaStore.ts
â”‚   â”‚   â”‚   â””â”€â”€ settingsStore.ts
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â””â”€â”€ globals.css
â”‚   â”‚
â”‚   â”œâ”€â”€ preload/                   # Preload scripts
â”‚   â”‚   â””â”€â”€ index.ts              # Exposed APIs
â”‚   â”‚
â”‚   â””â”€â”€ shared/                    # Shared types/utils
â”‚       â”œâ”€â”€ types/
â”‚       â””â”€â”€ constants/
â”‚
â”œâ”€â”€ resources/                     # Resources
â”‚   â”œâ”€â”€ models/                   # AI models (gitignored)
â”‚   â”‚   â”œâ”€â”€ llama-3.1-8b.gguf
â”‚   â”‚   â”œâ”€â”€ llava-7b.gguf
â”‚   â”‚   â””â”€â”€ whisper-large-v3.bin
â”‚   â””â”€â”€ icons/
â”‚
â”œâ”€â”€ electron-builder.json          # Build config
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ vite.config.ts                # Vite for renderer
```

### 1.4 Technology Stack

**Main Process**:

- **Runtime**: Node.js 20+
- **Language**: TypeScript 5.0+
- **AI Engine**: llama.cpp (via N-API bindings)
- **Database**: better-sqlite3
- **File System**: fs/promises
- **Git**: simple-git
- **Screen Capture**: screenshot-desktop (macOS/Windows)

**Renderer Process**:

- **Framework**: React 18+
- **Language**: TypeScript 5.0+
- **State**: Zustand (lightweight, simple)
- **UI Library**: shadcn/ui (headless, customizable)
- **Styling**: Tailwind CSS
- **i18n**: i18next + react-i18next
- **Build Tool**: Vite (fast HMR)

**Preload**:

- **API Exposure**: contextBridge (secure)

---

## 2. IPC Communication Layer

### 2.1 IPC Design Philosophy

Eden V3 uses **typed IPC channels** for type-safe communication between processes:

```typescript
// shared/types/ipc.types.ts

export interface IPCChannel {
  // AI Operations
  "ai:chat": {
    request: { message: string; context?: ScreenContext };
    response: { text: string; conversationId: string };
  };
  "ai:voice-input": {
    request: { audioBuffer: ArrayBuffer };
    response: { transcription: string };
  };
  "ai:speak": {
    request: { text: string; voice: "male" | "female" };
    response: { audioBuffer: ArrayBuffer };
  };

  // File Operations
  "file:read": {
    request: { path: string };
    response: { content: string; encoding: string };
  };
  "file:write": {
    request: { path: string; content: string };
    response: { success: boolean };
  };
  "file:watch": {
    request: { path: string };
    response: { event: "change" | "add" | "unlink"; path: string };
  };

  // Git Operations
  "git:status": {
    request: { repoPath: string };
    response: { branch: string; changes: GitChange[] };
  };
  "git:commit": {
    request: { repoPath: string; message: string; files: string[] };
    response: { hash: string };
  };

  // System Operations
  "system:screenshot": {
    request: { display?: number };
    response: { image: Buffer; width: number; height: number };
  };
  "system:notify": {
    request: { title: string; body: string };
    response: { clicked: boolean };
  };
}
```

### 2.2 Type-Safe IPC Implementation

**Main Process (IPC Handler)**:

```typescript
// main/ipc/ai.handler.ts

import { ipcMain } from "electron";
import { LlamaService } from "../services/ai/llama.service";
import type { IPCChannel } from "../../shared/types/ipc.types";

export class AIIPCHandler {
  constructor(private llama: LlamaService) {}

  register() {
    // Type-safe handler
    ipcMain.handle(
      "ai:chat",
      async (event, request: IPCChannel["ai:chat"]["request"]) => {
        const response = await this.llama.chat(
          request.message,
          request.context
        );

        return {
          text: response.text,
          conversationId: response.id,
        } satisfies IPCChannel["ai:chat"]["response"];
      }
    );

    ipcMain.handle(
      "ai:voice-input",
      async (event, request: IPCChannel["ai:voice-input"]["request"]) => {
        const whisper = this.llama.whisper;
        const transcription = await whisper.transcribe(request.audioBuffer);

        return {
          transcription,
        } satisfies IPCChannel["ai:voice-input"]["response"];
      }
    );
  }
}
```

**Preload Script (API Exposure)**:

```typescript
// preload/index.ts

import { contextBridge, ipcRenderer } from "electron";
import type { IPCChannel } from "../shared/types/ipc.types";

// Type-safe API factory
function createIPCAPI<K extends keyof IPCChannel>(channel: K) {
  return (
    request: IPCChannel[K]["request"]
  ): Promise<IPCChannel[K]["response"]> => {
    return ipcRenderer.invoke(channel, request);
  };
}

// Expose to renderer
contextBridge.exposeInMainWorld("electronAPI", {
  // AI
  aiChat: createIPCAPI("ai:chat"),
  aiVoiceInput: createIPCAPI("ai:voice-input"),
  aiSpeak: createIPCAPI("ai:speak"),

  // File
  fileRead: createIPCAPI("file:read"),
  fileWrite: createIPCAPI("file:write"),
  fileWatch: createIPCAPI("file:watch"),

  // Git
  gitStatus: createIPCAPI("git:status"),
  gitCommit: createIPCAPI("git:commit"),

  // System
  systemScreenshot: createIPCAPI("system:screenshot"),
  systemNotify: createIPCAPI("system:notify"),
});

// Type declaration for renderer
declare global {
  interface Window {
    electronAPI: {
      aiChat: (
        req: IPCChannel["ai:chat"]["request"]
      ) => Promise<IPCChannel["ai:chat"]["response"]>;
      aiVoiceInput: (
        req: IPCChannel["ai:voice-input"]["request"]
      ) => Promise<IPCChannel["ai:voice-input"]["response"]>;
      aiSpeak: (
        req: IPCChannel["ai:speak"]["request"]
      ) => Promise<IPCChannel["ai:speak"]["response"]>;
      fileRead: (
        req: IPCChannel["file:read"]["request"]
      ) => Promise<IPCChannel["file:read"]["response"]>;
      fileWrite: (
        req: IPCChannel["file:write"]["request"]
      ) => Promise<IPCChannel["file:write"]["response"]>;
      fileWatch: (
        req: IPCChannel["file:watch"]["request"]
      ) => Promise<IPCChannel["file:watch"]["response"]>;
      gitStatus: (
        req: IPCChannel["git:status"]["request"]
      ) => Promise<IPCChannel["git:status"]["response"]>;
      gitCommit: (
        req: IPCChannel["git:commit"]["request"]
      ) => Promise<IPCChannel["git:commit"]["response"]>;
      systemScreenshot: (
        req: IPCChannel["system:screenshot"]["request"]
      ) => Promise<IPCChannel["system:screenshot"]["response"]>;
      systemNotify: (
        req: IPCChannel["system:notify"]["request"]
      ) => Promise<IPCChannel["system:notify"]["response"]>;
    };
  }
}
```

**Renderer Usage (Type-Safe!)**:

```typescript
// renderer/hooks/useAI.ts

export function useAI() {
  const sendMessage = async (message: string) => {
    // Fully typed! IDE autocomplete works
    const response = await window.electronAPI.aiChat({
      message,
      context: await getScreenContext(),
    });

    console.log(response.text); // TypeScript knows this exists!
    return response;
  };

  return { sendMessage };
}
```

### 2.3 Streaming Responses

For real-time AI responses (token-by-token streaming):

```typescript
// Use event-based streaming instead of invoke

// Preload
contextBridge.exposeInMainWorld("electronAPI", {
  // ...existing APIs

  aiChatStream: (
    request: IPCChannel["ai:chat"]["request"],
    onToken: (token: string) => void
  ) => {
    const channel = `ai:chat-stream:${Date.now()}`;

    ipcRenderer.on(channel, (event, token: string) => {
      onToken(token);
    });

    ipcRenderer.send("ai:chat-stream-start", { channel, ...request });

    return () => ipcRenderer.removeAllListeners(channel);
  },
});

// Main Process
ipcMain.on("ai:chat-stream-start", async (event, data) => {
  const { channel, message, context } = data;

  await llama.chatStream(message, context, (token) => {
    event.sender.send(channel, token);
  });

  event.sender.send(channel, "[DONE]");
});
```

---

## 3. System Integration Services

### 3.1 File System Integration

**Purpose**: Allow AI to read/write files, understand project structure

```typescript
// main/services/integration/file.service.ts

import fs from "fs/promises";
import path from "path";
import { watch } from "chokidar";

export class FileService {
  private watchers = new Map<string, ReturnType<typeof watch>>();

  async read(filePath: string): Promise<{ content: string; encoding: string }> {
    const content = await fs.readFile(filePath, "utf-8");
    return { content, encoding: "utf-8" };
  }

  async write(filePath: string, content: string): Promise<void> {
    await fs.writeFile(filePath, content, "utf-8");
  }

  async readDirectory(dirPath: string): Promise<string[]> {
    const entries = await fs.readdir(dirPath, { withFileTypes: true });
    return entries.map((e) => e.name);
  }

  async getProjectStructure(rootPath: string): Promise<FileTree> {
    // Recursively build file tree (for AI context)
    const tree: FileTree = { name: path.basename(rootPath), children: [] };

    const entries = await fs.readdir(rootPath, { withFileTypes: true });

    for (const entry of entries) {
      if (entry.name.startsWith(".")) continue; // Skip hidden

      const fullPath = path.join(rootPath, entry.name);

      if (entry.isDirectory()) {
        tree.children.push(await this.getProjectStructure(fullPath));
      } else {
        tree.children.push({ name: entry.name, type: "file" });
      }
    }

    return tree;
  }

  watchFile(filePath: string, callback: (event: string) => void): string {
    const watcherId = Date.now().toString();

    const watcher = watch(filePath).on("all", (event, path) => {
      callback(event);
    });

    this.watchers.set(watcherId, watcher);
    return watcherId;
  }

  unwatchFile(watcherId: string): void {
    const watcher = this.watchers.get(watcherId);
    if (watcher) {
      watcher.close();
      this.watchers.delete(watcherId);
    }
  }
}

interface FileTree {
  name: string;
  type?: "file" | "directory";
  children?: FileTree[];
}
```

**Use Case Example**:

```
User: "Refactor the UserService class"

AI Flow:
1. AI asks: "Which file contains UserService?"
2. User: "src/services/user.service.ts"
3. AI reads file via fileRead IPC
4. AI generates refactored code
5. User approves
6. AI writes back via fileWrite IPC
```

### 3.2 Git Integration

**Purpose**: AI can understand git status, create commits, manage branches

```typescript
// main/services/integration/git.service.ts

import simpleGit, { SimpleGit, StatusResult } from "simple-git";

export class GitService {
  private git: SimpleGit;

  constructor(private repoPath: string) {
    this.git = simpleGit(repoPath);
  }

  async getStatus(): Promise<GitStatus> {
    const status: StatusResult = await this.git.status();

    return {
      branch: status.current || "unknown",
      ahead: status.ahead,
      behind: status.behind,
      modified: status.modified,
      created: status.created,
      deleted: status.deleted,
      staged: status.staged,
    };
  }

  async commit(message: string, files?: string[]): Promise<string> {
    if (files && files.length > 0) {
      await this.git.add(files);
    } else {
      await this.git.add(".");
    }

    const result = await this.git.commit(message);
    return result.commit;
  }

  async createBranch(branchName: string): Promise<void> {
    await this.git.checkoutLocalBranch(branchName);
  }

  async switchBranch(branchName: string): Promise<void> {
    await this.git.checkout(branchName);
  }

  async push(remote = "origin", branch?: string): Promise<void> {
    await this.git.push(remote, branch);
  }

  async pull(remote = "origin", branch?: string): Promise<void> {
    await this.git.pull(remote, branch);
  }

  async getDiff(file?: string): Promise<string> {
    if (file) {
      return await this.git.diff([file]);
    }
    return await this.git.diff();
  }

  async getLog(count = 10): Promise<GitCommit[]> {
    const log = await this.git.log({ maxCount: count });

    return log.all.map((commit) => ({
      hash: commit.hash,
      message: commit.message,
      author: commit.author_name,
      date: commit.date,
    }));
  }
}

interface GitStatus {
  branch: string;
  ahead: number;
  behind: number;
  modified: string[];
  created: string[];
  deleted: string[];
  staged: string[];
}

interface GitCommit {
  hash: string;
  message: string;
  author: string;
  date: string;
}
```

**AI Proactive Use Case**:

```
Scenario: AI detects uncommitted changes

AI (proactive notification):
"I notice you have 3 modified files in your git repo:
- src/components/Chat.tsx
- src/hooks/useAI.ts
- package.json

Would you like me to create a commit? I can suggest a commit message based on your changes."

User: "Yes"

AI:
[Reads diffs via gitDiff]
[Analyzes changes]
"Suggested commit message:
'feat: Add streaming response support to Chat component'

Should I commit with this message?"

User: "Perfect"

AI: [Executes gitCommit]
"âœ… Committed as 7a3f9e2"
```

### 3.3 Calendar Integration

**Purpose**: AI knows your schedule, suggests optimal work times

```typescript
// main/services/integration/calendar.service.ts

import ical from "node-ical";
import fetch from "node-fetch";

export class CalendarService {
  private events: CalendarEvent[] = [];

  async syncFromICS(icsUrl: string): Promise<void> {
    // Support Google Calendar, Outlook, Apple Calendar (via ICS export)
    const response = await fetch(icsUrl);
    const icsData = await response.text();

    const parsed = ical.sync.parseICS(icsData);

    this.events = Object.values(parsed)
      .filter((event) => event.type === "VEVENT")
      .map((event) => ({
        id: event.uid,
        title: event.summary,
        start: event.start,
        end: event.end,
        description: event.description,
        location: event.location,
      }));
  }

  getTodaysEvents(): CalendarEvent[] {
    const today = new Date();
    today.setHours(0, 0, 0, 0);

    const tomorrow = new Date(today);
    tomorrow.setDate(tomorrow.getDate() + 1);

    return this.events.filter((event) => {
      const eventDate = new Date(event.start);
      return eventDate >= today && eventDate < tomorrow;
    });
  }

  getUpcomingEvents(hours = 2): CalendarEvent[] {
    const now = new Date();
    const future = new Date(now.getTime() + hours * 60 * 60 * 1000);

    return this.events.filter((event) => {
      const eventDate = new Date(event.start);
      return eventDate >= now && eventDate <= future;
    });
  }

  getFreeSlots(date: Date): TimeSlot[] {
    // Find gaps between events = free time
    const dayEvents = this.events
      .filter((e) => new Date(e.start).toDateString() === date.toDateString())
      .sort(
        (a, b) => new Date(a.start).getTime() - new Date(b.start).getTime()
      );

    const slots: TimeSlot[] = [];
    let lastEnd = new Date(date);
    lastEnd.setHours(9, 0, 0, 0); // Start at 9am

    for (const event of dayEvents) {
      const eventStart = new Date(event.start);

      if (eventStart > lastEnd) {
        slots.push({
          start: lastEnd,
          end: eventStart,
          duration: (eventStart.getTime() - lastEnd.getTime()) / 60000, // minutes
        });
      }

      lastEnd = new Date(event.end);
    }

    // Add slot until end of day (6pm)
    const endOfDay = new Date(date);
    endOfDay.setHours(18, 0, 0, 0);

    if (lastEnd < endOfDay) {
      slots.push({
        start: lastEnd,
        end: endOfDay,
        duration: (endOfDay.getTime() - lastEnd.getTime()) / 60000,
      });
    }

    return slots;
  }
}

interface CalendarEvent {
  id: string;
  title: string;
  start: Date;
  end: Date;
  description?: string;
  location?: string;
}

interface TimeSlot {
  start: Date;
  end: Date;
  duration: number; // minutes
}
```

**AI Proactive Use Case**:

```
Scenario: Morning routine

AI (9:00 AM):
"Good morning! ğŸŒ…

Your schedule today:
- 10:00-11:00: Team standup
- 14:00-15:30: Client meeting
- 16:00-17:00: Code review session

You have a 2.5 hour free block from 11:00-14:00.
Perfect for focused coding on your React project!

Want me to block distractions during that time?"
```

### 3.4 Email Integration (Future)

**Purpose**: AI can read emails, suggest replies, manage inbox

```typescript
// Placeholder for future implementation

export class EmailService {
  // Integration with:
  // - Gmail API
  // - Outlook API
  // - IMAP/SMTP (generic)

  async getUnreadEmails(): Promise<Email[]> {
    // TODO
    return [];
  }

  async sendEmail(to: string, subject: string, body: string): Promise<void> {
    // TODO
  }

  async suggestReply(emailId: string): Promise<string> {
    // Use LLM to generate contextual reply
    // TODO
    return "";
  }
}
```

---

## 4. Webhook & Plugin System

### 4.1 Webhook Architecture

**Purpose**: Allow Eden to trigger external services (Notion, Slack, Discord, etc.)

```typescript
// main/services/webhook/webhook.service.ts

import axios from "axios";

export class WebhookService {
  private webhooks = new Map<string, WebhookConfig>();

  registerWebhook(name: string, config: WebhookConfig): void {
    this.webhooks.set(name, config);
  }

  async trigger(name: string, payload: any): Promise<void> {
    const webhook = this.webhooks.get(name);
    if (!webhook) {
      throw new Error(`Webhook '${name}' not found`);
    }

    try {
      await axios.post(webhook.url, payload, {
        headers: webhook.headers || {},
        timeout: webhook.timeout || 5000,
      });

      console.log(`âœ… Webhook '${name}' triggered successfully`);
    } catch (error) {
      console.error(`âŒ Webhook '${name}' failed:`, error);
      throw error;
    }
  }

  // Pre-configured webhooks
  async notifySlack(message: string, channel?: string): Promise<void> {
    const slackWebhook = this.webhooks.get("slack");
    if (!slackWebhook) return;

    await this.trigger("slack", {
      text: message,
      channel: channel || "#general",
    });
  }

  async notifyDiscord(message: string): Promise<void> {
    const discordWebhook = this.webhooks.get("discord");
    if (!discordWebhook) return;

    await this.trigger("discord", {
      content: message,
    });
  }

  async appendToNotion(databaseId: string, properties: any): Promise<void> {
    const notionWebhook = this.webhooks.get("notion");
    if (!notionWebhook) return;

    await axios.post(
      `https://api.notion.com/v1/pages`,
      {
        parent: { database_id: databaseId },
        properties,
      },
      {
        headers: {
          Authorization: `Bearer ${notionWebhook.headers?.["Authorization"]}`,
          "Notion-Version": "2022-06-28",
          "Content-Type": "application/json",
        },
      }
    );
  }
}

interface WebhookConfig {
  url: string;
  headers?: Record<string, string>;
  timeout?: number;
  retries?: number;
}
```

**Configuration (User Settings)**:

```json
{
  "webhooks": {
    "slack": {
      "url": "https://hooks.slack.com/services/YOUR/WEBHOOK/URL",
      "enabled": true
    },
    "discord": {
      "url": "https://discord.com/api/webhooks/YOUR/WEBHOOK",
      "enabled": true
    },
    "notion": {
      "url": "https://api.notion.com",
      "headers": {
        "Authorization": "Bearer secret_YOUR_NOTION_TOKEN"
      },
      "enabled": false
    }
  }
}
```

**AI Use Case**:

```
User: "Remind the team on Slack that the standup is in 10 minutes"

AI:
[Triggers Slack webhook]
"âœ… Sent message to #general:
'@channel Friendly reminder: Standup starts in 10 minutes!'"
```

### 4.2 Plugin System

**Purpose**: Extend Eden's capabilities without modifying core code

```typescript
// main/plugins/plugin.interface.ts

export interface EdenPlugin {
  name: string;
  version: string;
  description: string;

  // Lifecycle hooks
  onLoad?(context: PluginContext): Promise<void>;
  onUnload?(): Promise<void>;

  // Command registration
  commands?: PluginCommand[];

  // Custom IPC channels
  ipcHandlers?: Record<string, (request: any) => Promise<any>>;

  // UI extensions
  uiComponents?: PluginUIComponent[];
}

export interface PluginContext {
  // Access to core services
  ai: AIServiceAPI;
  file: FileService;
  git: GitService;
  calendar: CalendarService;
  webhook: WebhookService;
  db: Database;

  // Plugin-specific storage
  storage: PluginStorage;

  // Logging
  logger: Logger;
}

export interface PluginCommand {
  name: string;
  description: string;
  execute: (args: string[], context: PluginContext) => Promise<string>;
}

export interface PluginUIComponent {
  id: string;
  location: "sidebar" | "settings" | "chat";
  component: string; // Path to React component
}
```

**Example Plugin: GitHub Integration**:

```typescript
// plugins/github-plugin/index.ts

import { EdenPlugin, PluginContext } from "../plugin.interface";
import { Octokit } from "@octokit/rest";

export class GitHubPlugin implements EdenPlugin {
  name = "github-integration";
  version = "1.0.0";
  description = "GitHub API integration for Eden";

  private octokit?: Octokit;
  private context?: PluginContext;

  async onLoad(context: PluginContext) {
    this.context = context;

    // Get GitHub token from plugin storage
    const token = await context.storage.get("github_token");
    if (token) {
      this.octokit = new Octokit({ auth: token });
      context.logger.info("GitHub plugin loaded successfully");
    }
  }

  commands = [
    {
      name: "github-issues",
      description: "List open issues in a repository",
      execute: async (args: string[]) => {
        if (!this.octokit)
          return "GitHub not configured. Please add your token in settings.";

        const [owner, repo] = args[0].split("/");

        const { data: issues } = await this.octokit.issues.listForRepo({
          owner,
          repo,
          state: "open",
        });

        return issues.map((i) => `#${i.number}: ${i.title}`).join("\n");
      },
    },
    {
      name: "github-create-pr",
      description: "Create a pull request",
      execute: async (args: string[]) => {
        // Implementation...
        return "PR created!";
      },
    },
  ];

  ipcHandlers = {
    "github:repos": async () => {
      if (!this.octokit) return [];

      const { data } = await this.octokit.repos.listForAuthenticatedUser();
      return data.map((r) => ({ name: r.name, url: r.html_url }));
    },
  };
}
```

**Plugin Discovery & Loading**:

```typescript
// main/plugins/plugin-manager.ts

import fs from "fs/promises";
import path from "path";

export class PluginManager {
  private plugins = new Map<string, EdenPlugin>();
  private pluginDir = path.join(app.getPath("userData"), "plugins");

  async loadPlugins(context: PluginContext): Promise<void> {
    await fs.mkdir(this.pluginDir, { recursive: true });

    const pluginDirs = await fs.readdir(this.pluginDir);

    for (const dir of pluginDirs) {
      try {
        const pluginPath = path.join(this.pluginDir, dir, "index.js");
        const pluginModule = await import(pluginPath);
        const plugin: EdenPlugin = new pluginModule.default();

        await plugin.onLoad?.(context);

        this.plugins.set(plugin.name, plugin);
        console.log(`âœ… Loaded plugin: ${plugin.name} v${plugin.version}`);
      } catch (error) {
        console.error(`âŒ Failed to load plugin ${dir}:`, error);
      }
    }
  }

  getPlugin(name: string): EdenPlugin | undefined {
    return this.plugins.get(name);
  }

  async unloadPlugin(name: string): Promise<void> {
    const plugin = this.plugins.get(name);
    if (plugin) {
      await plugin.onUnload?.();
      this.plugins.delete(name);
    }
  }
}
```

---

## 5. File System Access & Context

### 5.1 Workspace Management

**Purpose**: Track user's active project for AI context

```typescript
// main/services/workspace/workspace.service.ts

export class WorkspaceService {
  private currentWorkspace?: Workspace;

  async openWorkspace(rootPath: string): Promise<Workspace> {
    const workspace: Workspace = {
      rootPath,
      name: path.basename(rootPath),
      type: await this.detectWorkspaceType(rootPath),
      openFiles: [],
      gitRepo: await this.detectGitRepo(rootPath),
    };

    this.currentWorkspace = workspace;
    return workspace;
  }

  private async detectWorkspaceType(rootPath: string): Promise<WorkspaceType> {
    // Detect project type by files
    const files = await fs.readdir(rootPath);

    if (files.includes("package.json")) return "nodejs";
    if (files.includes("requirements.txt")) return "python";
    if (files.includes("Cargo.toml")) return "rust";
    if (files.includes("go.mod")) return "go";
    if (files.includes("pom.xml")) return "java";

    return "generic";
  }

  private async detectGitRepo(rootPath: string): Promise<string | undefined> {
    try {
      const git = simpleGit(rootPath);
      await git.status();
      return rootPath;
    } catch {
      return undefined;
    }
  }

  trackFileOpen(filePath: string): void {
    if (!this.currentWorkspace) return;

    if (!this.currentWorkspace.openFiles.includes(filePath)) {
      this.currentWorkspace.openFiles.push(filePath);
    }
  }

  getCurrentContext(): WorkspaceContext {
    if (!this.currentWorkspace) {
      return { hasWorkspace: false };
    }

    return {
      hasWorkspace: true,
      workspaceName: this.currentWorkspace.name,
      workspaceType: this.currentWorkspace.type,
      openFiles: this.currentWorkspace.openFiles,
      hasGit: !!this.currentWorkspace.gitRepo,
    };
  }
}

interface Workspace {
  rootPath: string;
  name: string;
  type: WorkspaceType;
  openFiles: string[];
  gitRepo?: string;
}

type WorkspaceType = "nodejs" | "python" | "rust" | "go" | "java" | "generic";

interface WorkspaceContext {
  hasWorkspace: boolean;
  workspaceName?: string;
  workspaceType?: WorkspaceType;
  openFiles?: string[];
  hasGit?: boolean;
}
```

### 5.2 Context-Aware File Operations

**AI understands your project structure**:

```typescript
// Example AI interaction

User: "Show me the main entry point"

AI: [Checks workspace type]
    [workspace.type === 'nodejs']
    [Reads package.json]
    [Finds "main": "src/index.ts"]
    [Reads src/index.ts]

AI: "Your main entry point is `src/index.ts`. Here's what it does:
- Initializes Express server on port 3000
- Connects to MongoDB
- Registers API routes
- Starts listening

Would you like me to explain any specific part?"
```

---

## 6. Git Integration

### 6.1 Smart Commit Message Generation

**AI generates commit messages based on diffs**:

```typescript
// main/services/git/commit-ai.service.ts

export class CommitAIService {
  constructor(private llama: LlamaService) {}

  async generateCommitMessage(diff: string): Promise<string> {
    const prompt = `You are a Git commit message expert following Conventional Commits.

Analyze this git diff and generate a concise, descriptive commit message.

Format: <type>(<scope>): <subject>

Types: feat, fix, docs, style, refactor, test, chore

Diff:
\`\`\`
${diff}
\`\`\`

Generate only the commit message, no explanation.`;

    const response = await this.llama.generate(prompt, {
      maxTokens: 100,
      temperature: 0.3, // Low temperature for consistency
    });

    return response.trim();
  }

  async generatePRDescription(
    branch: string,
    commits: GitCommit[]
  ): Promise<string> {
    const prompt = `Generate a GitHub Pull Request description.

Branch: ${branch}

Commits:
${commits.map((c) => `- ${c.message}`).join("\n")}

Generate a PR description with:
1. Summary (what changed)
2. Motivation (why)
3. Changes (bullet points)
4. Testing (how to verify)

Format in Markdown.`;

    return await this.llama.generate(prompt, { maxTokens: 500 });
  }
}
```

**User Experience**:

```
User: "Commit my changes"

AI: [Reads git diff]
    [Analyzes changes with LLM]
    [Generates commit message]

AI: "I suggest this commit message:
'feat(chat): Add streaming response support with token-by-token display'

Should I commit with this message?"

User: "Yes"

AI: [Executes git add & commit]
    "âœ… Committed as 7a3f9e2"
```

---

## 7. Calendar & Email Integration

### 7.1 Proactive Scheduling Assistant

**AI suggests optimal work times based on calendar**:

```typescript
// AI proactive logic

async function suggestWorkTime() {
  const today = new Date();
  const freeSlots = await calendarService.getFreeSlots(today);

  // Find longest free slot
  const longestSlot = freeSlots.reduce((max, slot) =>
    slot.duration > max.duration ? slot : max
  );

  if (longestSlot.duration >= 120) {
    // 2+ hours
    await notifyUser({
      title: "Optimal Coding Time Available",
      body: `You have a ${longestSlot.duration}min block from ${formatTime(
        longestSlot.start
      )}. Perfect for deep work!`,
      action: "Start Focus Mode",
    });
  }
}
```

---

## 8. Screen Capture & Vision Pipeline

### 8.1 Screen Context Awareness

**Purpose**: AI sees what you see (privacy-conscious)

```typescript
// main/services/screen/capture.service.ts

import screenshot from "screenshot-desktop";
import sharp from "sharp";

export class ScreenCaptureService {
  async captureScreen(display = 0): Promise<ScreenCapture> {
    // Capture screenshot
    const imgBuffer = await screenshot({ screen: display });

    // Resize for LLaVA (max 1024x1024)
    const resized = await sharp(imgBuffer)
      .resize(1024, 1024, { fit: "inside" })
      .jpeg({ quality: 85 })
      .toBuffer();

    return {
      image: resized,
      timestamp: new Date(),
      display,
    };
  }

  async captureWindow(windowTitle: string): Promise<ScreenCapture> {
    // Platform-specific: capture specific window
    // macOS: use CGWindowListCreateImage
    // Windows: use Windows API
    // TODO: Implement
    throw new Error("Not implemented");
  }

  async analyzeScreen(): Promise<ScreenAnalysis> {
    const capture = await this.captureScreen();

    // Send to LLaVA for vision analysis
    const analysis = await llavaService.analyze(capture.image, {
      prompt:
        "Describe what you see on this screen. Identify any code, terminal output, error messages, or UI elements.",
    });

    return {
      description: analysis.text,
      detectedElements: this.parseElements(analysis.text),
    };
  }

  private parseElements(description: string): ScreenElement[] {
    // Extract structured data from LLaVA description
    // e.g., "I see a code editor with TypeScript code", "There's an error message in red"
    return [];
  }
}

interface ScreenCapture {
  image: Buffer;
  timestamp: Date;
  display: number;
}

interface ScreenAnalysis {
  description: string;
  detectedElements: ScreenElement[];
}

interface ScreenElement {
  type: "code" | "error" | "terminal" | "browser" | "ui";
  content?: string;
  confidence: number;
}
```

### 8.2 Privacy Controls

**User has full control over screen capture**:

```typescript
// Settings
interface ScreenCaptureSettings {
  enabled: boolean;
  mode: "manual" | "auto" | "disabled";
  captureFrequency?: number; // seconds (if auto)
  excludedApps?: string[]; // Never capture these apps
  blurSensitiveInfo?: boolean; // Blur passwords, emails, etc.
}
```

**UI Indicator**:

```
When screen capture is active:
- Show ğŸ”´ red dot in tray icon
- Show "Screen capture active" toast
- User can disable anytime
```

---

## 9. Process Management & Isolation

### 9.1 AI Model Subprocess

**Purpose**: Run AI models in separate process to prevent UI freezing

```typescript
// main/processes/ai-worker.ts

import { fork } from "child_process";

export class AIWorkerProcess {
  private worker: ReturnType<typeof fork> | null = null;

  start(): void {
    this.worker = fork(path.join(__dirname, "ai-worker-script.js"));

    this.worker.on("message", (message) => {
      this.handleWorkerMessage(message);
    });

    this.worker.on("error", (error) => {
      console.error("AI worker error:", error);
      this.restart();
    });
  }

  async generate(prompt: string): Promise<string> {
    return new Promise((resolve, reject) => {
      const requestId = Date.now().toString();

      this.worker?.send({
        type: "generate",
        requestId,
        prompt,
      });

      const handler = (message: any) => {
        if (message.requestId === requestId) {
          if (message.type === "result") {
            resolve(message.text);
          } else if (message.type === "error") {
            reject(new Error(message.error));
          }
          this.worker?.off("message", handler);
        }
      };

      this.worker?.on("message", handler);
    });
  }

  private restart(): void {
    console.log("Restarting AI worker...");
    this.worker?.kill();
    this.start();
  }
}
```

**AI Worker Script** (runs in separate process):

```typescript
// main/processes/ai-worker-script.ts

import { LlamaCpp } from "../services/ai/llama.service";

const llama = new LlamaCpp({
  modelPath: "./resources/models/llama-3.1-8b.gguf",
});

process.on("message", async (message: any) => {
  if (message.type === "generate") {
    try {
      const result = await llama.generate(message.prompt);

      process.send?.({
        type: "result",
        requestId: message.requestId,
        text: result,
      });
    } catch (error) {
      process.send?.({
        type: "error",
        requestId: message.requestId,
        error: error.message,
      });
    }
  }
});
```

### 9.2 Resource Monitoring

```typescript
// Monitor CPU/RAM usage

import os from "os";

export class ResourceMonitor {
  getSystemInfo() {
    return {
      totalRAM: os.totalmem(),
      freeRAM: os.freemem(),
      cpuUsage: os.loadavg(),
      platform: os.platform(),
    };
  }

  async getProcessUsage() {
    return {
      memory: process.memoryUsage(),
      cpu: process.cpuUsage(),
    };
  }

  shouldThrottle(): boolean {
    const free = os.freemem();
    const total = os.totalmem();
    const usagePercent = ((total - free) / total) * 100;

    // Throttle if RAM usage > 90%
    return usagePercent > 90;
  }
}
```

---

## 10. Security & Sandboxing

### 10.1 Context Isolation

**Renderer process has NO direct Node.js access**:

```typescript
// main/index.ts

const mainWindow = new BrowserWindow({
  width: 1200,
  height: 800,
  webPreferences: {
    contextIsolation: true, // âœ… Isolated
    nodeIntegration: false, // âœ… Disabled
    preload: path.join(__dirname, "preload.js"),
  },
});
```

### 10.2 IPC Validation

**All IPC requests are validated**:

```typescript
// main/ipc/validator.ts

export function validateIPCRequest(channel: string, data: any): boolean {
  // Whitelist allowed channels
  const allowedChannels = [
    "ai:chat",
    "file:read",
    "git:status",
    // ... etc
  ];

  if (!allowedChannels.includes(channel)) {
    console.error(`âŒ Blocked unauthorized IPC channel: ${channel}`);
    return false;
  }

  // Validate data structure
  // TODO: Add schema validation (zod)

  return true;
}
```

### 10.3 File System Restrictions

**AI can only access user-authorized directories**:

```typescript
// main/services/security/file-access.service.ts

export class FileAccessControl {
  private allowedPaths: Set<string> = new Set();

  async requestAccess(path: string): Promise<boolean> {
    // Show dialog to user
    const { response } = await dialog.showMessageBox({
      type: "question",
      buttons: ["Allow", "Deny"],
      message: `Eden wants to access:\n${path}`,
      detail: "This will allow Eden to read and write files in this directory.",
    });

    if (response === 0) {
      this.allowedPaths.add(path);
      return true;
    }

    return false;
  }

  isAllowed(path: string): boolean {
    // Check if path is within any allowed directory
    for (const allowedPath of this.allowedPaths) {
      if (path.startsWith(allowedPath)) {
        return true;
      }
    }
    return false;
  }
}
```

---

**End of Part 3**

_Lines: ~1400_
_Next: Part 4 - UI/UX & Features_

---

---

# Part 4: UI/UX & Features (EXPANDED VERSION)

## Table of Contents - Part 4

1. [KakaoTalk-Style Chat Interface](#1-kakaotalk-style-chat-interface)
2. [Design System & Theme](#2-design-system--theme)
3. [Internationalization (i18n)](#3-internationalization-i18n)
4. [Voice Input/Output UI](#4-voice-inputoutput-ui)
5. [Dual Mode: User-Led vs AI-Led](#5-dual-mode-user-led-vs-ai-led)
6. [Proactive Notifications](#6-proactive-notifications)
7. [Settings & Persona Configuration](#7-settings--persona-configuration)
8. [Conversation History](#8-conversation-history)
9. [Keyboard Shortcuts & Accessibility](#9-keyboard-shortcuts--accessibility)
10. [System Tray & Window Management](#10-system-tray--window-management)

---

## 1. KakaoTalk-Style Chat Interface

### 1.1 Why KakaoTalk Style?

**Design Philosophy**: Familiar, conversational, warm

Korean users are deeply familiar with KakaoTalk's UI:

- âœ… Speech bubbles (left = AI, right = user)
- âœ… Timestamps above bubbles
- âœ… Profile pictures
- âœ… Read receipts (optional)
- âœ… Typing indicator
- âœ… Warm yellow accent color (#FAE100)

This creates **instant familiarity** and reduces learning curve.

**Psychological Benefits**:

- Warm colors reduce stress
- Familiar patterns increase comfort
- Conversational style feels personal
- Avatar creates emotional connection

### 1.2 Chat Interface Layout

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸŒ¿ Eden Project                    [User-Led â–¾] [âˆ’] [â–¡] [Ã—]         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚  â”‚                      Chat Area                              â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  ì˜¤í›„ 2:34                                            â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ğŸ¤–â”‚ ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë– ì…¨ì–´ìš”?    â”‚ (AI)        â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ How was your day?                  â”‚              â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚                                                      â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚                         ì˜¤í›„ 2:35                    â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚        (User)â”‚ ì¢‹ì•˜ì–´! ì½”ë”© ë§ì´ í–ˆì–´             â”‚ğŸ˜Šâ”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚              â”‚ Great! Did lots of coding          â”‚  â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚                                                      â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  ì˜¤í›„ 2:35                                            â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚ğŸ¤–â”‚ í›Œë¥­í•´ìš”! ë¬´ìŠ¨ í”„ë¡œì íŠ¸ì˜€ë‚˜ìš”?        â”‚              â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â”‚ Awesome! What project?             â”‚              â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚                                                      â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  â— â— â— (typing...)                                   â”‚  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚  â”‚  Input Area                                                 â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â”‚  ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”... Type a message...  [ğŸ¤]    â”‚    â”‚ â”‚    â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚    â”‚
â”‚  â”‚  â”‚                                   [ğŸ“] [ğŸ˜Š] [ğŸ”] [âš™ï¸] [â¤]  â”‚ â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â”‚                                                                  â”‚    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Chat Bubble Component (Complete Implementation)

```tsx
// renderer/components/chat/ChatBubble.tsx

import React from "react";
import { cn } from "@/lib/utils";
import { Avatar, AvatarImage, AvatarFallback } from "@/components/ui/avatar";
import { formatTime, formatDate, isToday, isSameDay } from "@/utils/time";
import ReactMarkdown from "react-markdown";
import { Prism as SyntaxHighlighter } from "react-syntax-highlighter";
import { oneDark } from "react-syntax-highlighter/dist/esm/styles/prism";
import { Copy, Check } from "lucide-react";

interface ChatBubbleProps {
  message: string;
  sender: "user" | "assistant" | "system";
  timestamp: Date;
  avatar?: string;
  isStreaming?: boolean;
  showAvatar?: boolean;
  showTimestamp?: boolean;
  groupWithPrevious?: boolean; // Same sender, within 1 minute
}

export function ChatBubble({
  message,
  sender,
  timestamp,
  avatar,
  isStreaming = false,
  showAvatar = true,
  showTimestamp = true,
  groupWithPrevious = false,
}: ChatBubbleProps) {
  const [copied, setCopied] = React.useState(false);
  const isAI = sender === "assistant";
  const isUser = sender === "user";

  const handleCopyCode = (code: string) => {
    navigator.clipboard.writeText(code);
    setCopied(true);
    setTimeout(() => setCopied(false), 2000);
  };

  return (
    <div
      className={cn(
        "flex gap-3 px-4",
        groupWithPrevious ? "mt-1" : "mt-4",
        isAI && "justify-start",
        isUser && "justify-end"
      )}
    >
      {/* AI Avatar (left) */}
      {isAI && showAvatar && (
        <Avatar className="w-10 h-10 flex-shrink-0">
          <AvatarImage src={avatar || "/avatars/eden-ai.png"} alt="Eden AI" />
          <AvatarFallback className="bg-yellow-400 text-gray-900">
            ğŸŒ¿
          </AvatarFallback>
        </Avatar>
      )}

      {/* Spacer when grouped */}
      {isAI && !showAvatar && <div className="w-10 flex-shrink-0" />}

      <div
        className={cn(
          "flex flex-col max-w-[65%]",
          isAI && "items-start",
          isUser && "items-end"
        )}
      >
        {/* Timestamp (shown above first message in group) */}
        {showTimestamp && !groupWithPrevious && (
          <div className="text-xs text-gray-500 mb-1 px-1">
            {isToday(timestamp) ? formatTime(timestamp) : formatDate(timestamp)}
          </div>
        )}

        {/* Bubble */}
        <div
          className={cn(
            "px-4 py-2.5 rounded-2xl shadow-sm transition-all",
            isAI &&
              "bg-white text-gray-900 rounded-tl-none border border-gray-100",
            isUser && "bg-yellow-400 text-gray-900 rounded-tr-none",
            isStreaming && "animate-pulse-subtle"
          )}
        >
          {isStreaming ? (
            <div className="flex items-center gap-2">
              <span className="whitespace-pre-wrap break-words">{message}</span>
              <span className="inline-block w-0.5 h-4 bg-current animate-pulse">
                â–Œ
              </span>
            </div>
          ) : (
            <div
              className={cn(
                "prose prose-sm max-w-none",
                isUser && "prose-p:my-1"
              )}
            >
              <ReactMarkdown
                components={{
                  code({ node, inline, className, children, ...props }) {
                    const match = /language-(\w+)/.exec(className || "");
                    const codeString = String(children).replace(/\n$/, "");

                    return !inline && match ? (
                      <div className="relative group">
                        <SyntaxHighlighter
                          style={oneDark}
                          language={match[1]}
                          PreTag="div"
                          className="rounded-lg !my-2"
                          {...props}
                        >
                          {codeString}
                        </SyntaxHighlighter>
                        <button
                          onClick={() => handleCopyCode(codeString)}
                          className="absolute top-2 right-2 p-1.5 bg-gray-800 hover:bg-gray-700 rounded opacity-0 group-hover:opacity-100 transition-opacity"
                        >
                          {copied ? (
                            <Check className="w-4 h-4 text-green-400" />
                          ) : (
                            <Copy className="w-4 h-4 text-gray-300" />
                          )}
                        </button>
                      </div>
                    ) : (
                      <code
                        className={cn(
                          className,
                          "px-1.5 py-0.5 bg-gray-100 rounded text-sm"
                        )}
                        {...props}
                      >
                        {children}
                      </code>
                    );
                  },
                }}
              >
                {message}
              </ReactMarkdown>
            </div>
          )}
        </div>

        {/* Read receipt (for user messages) */}
        {isUser && !isStreaming && (
          <div className="text-xs text-gray-400 mt-0.5 px-1">ì½ìŒ Â· Read</div>
        )}
      </div>

      {/* User Avatar (right) */}
      {isUser && showAvatar && (
        <Avatar className="w-10 h-10 flex-shrink-0">
          <AvatarImage src={avatar || "/avatars/user-default.png"} alt="User" />
          <AvatarFallback className="bg-gray-200">ğŸ‘¤</AvatarFallback>
        </Avatar>
      )}

      {/* Spacer when grouped */}
      {isUser && !showAvatar && <div className="w-10 flex-shrink-0" />}
    </div>
  );
}
```

### 1.4 Message Grouping Logic

```typescript
// utils/chat/groupMessages.ts

export interface GroupedMessage {
  messages: Message[];
  sender: "user" | "assistant";
  timestamp: Date;
}

const GROUP_THRESHOLD_MS = 60000; // 1 minute

export function groupMessages(messages: Message[]): GroupedMessage[] {
  const groups: GroupedMessage[] = [];
  let currentGroup: Message[] = [];
  let currentSender: "user" | "assistant" | null = null;

  for (let i = 0; i < messages.length; i++) {
    const message = messages[i];
    const prevMessage = messages[i - 1];

    const shouldStartNewGroup =
      !prevMessage ||
      message.sender !== currentSender ||
      message.timestamp.getTime() - prevMessage.timestamp.getTime() >
        GROUP_THRESHOLD_MS;

    if (shouldStartNewGroup) {
      if (currentGroup.length > 0) {
        groups.push({
          messages: currentGroup,
          sender: currentSender!,
          timestamp: currentGroup[0].timestamp,
        });
      }
      currentGroup = [message];
      currentSender = message.sender;
    } else {
      currentGroup.push(message);
    }
  }

  if (currentGroup.length > 0) {
    groups.push({
      messages: currentGroup,
      sender: currentSender!,
      timestamp: currentGroup[0].timestamp,
    });
  }

  return groups;
}
```

### 1.5 Typing Indicator Component

```tsx
// renderer/components/chat/TypingIndicator.tsx

import { Avatar, AvatarImage, AvatarFallback } from "@/components/ui/avatar";

export function TypingIndicator() {
  return (
    <div className="flex gap-3 px-4 mt-4 animate-fade-in">
      <Avatar className="w-10 h-10">
        <AvatarImage src="/avatars/eden-ai.png" alt="Eden AI" />
        <AvatarFallback className="bg-yellow-400">ğŸŒ¿</AvatarFallback>
      </Avatar>

      <div className="bg-white px-5 py-3 rounded-2xl rounded-tl-none shadow-sm border border-gray-100">
        <div className="flex gap-1.5">
          <span
            className="w-2 h-2 bg-gray-400 rounded-full animate-bounce"
            style={{ animationDelay: "0ms", animationDuration: "1.4s" }}
          />
          <span
            className="w-2 h-2 bg-gray-400 rounded-full animate-bounce"
            style={{ animationDelay: "200ms", animationDuration: "1.4s" }}
          />
          <span
            className="w-2 h-2 bg-gray-400 rounded-full animate-bounce"
            style={{ animationDelay: "400ms", animationDuration: "1.4s" }}
          />
        </div>
      </div>
    </div>
  );
}
```

### 1.6 Input Box Component (Complete)

```tsx
// renderer/components/chat/InputBox.tsx

import React, { useState, useRef, useEffect } from "react";
import { Button } from "@/components/ui/button";
import { Mic, Paperclip, Send, Smile, Search, Settings } from "lucide-react";
import { useAI } from "@/hooks/useAI";
import { useVoice } from "@/hooks/useVoice";
import { cn } from "@/lib/utils";
import EmojiPicker from "emoji-picker-react";

export function InputBox() {
  const [message, setMessage] = useState("");
  const [isRecording, setIsRecording] = useState(false);
  const [showEmojiPicker, setShowEmojiPicker] = useState(false);
  const textareaRef = useRef<HTMLTextAreaElement>(null);

  const { sendMessage, isProcessing } = useAI();
  const {
    startRecording,
    stopRecording,
    isSupported: isVoiceSupported,
  } = useVoice();

  // Auto-resize textarea
  useEffect(() => {
    if (textareaRef.current) {
      textareaRef.current.style.height = "auto";
      textareaRef.current.style.height = `${Math.min(
        textareaRef.current.scrollHeight,
        120
      )}px`;
    }
  }, [message]);

  const handleSend = async () => {
    if (!message.trim() || isProcessing) return;

    const messageToSend = message;
    setMessage("");

    await sendMessage(messageToSend);
  };

  const handleKeyPress = (e: React.KeyboardEvent) => {
    if (e.key === "Enter" && !e.shiftKey) {
      e.preventDefault();
      handleSend();
    }
  };

  const handleVoiceClick = async () => {
    if (!isVoiceSupported) {
      alert("Voice input is not supported on this device");
      return;
    }

    if (isRecording) {
      const transcription = await stopRecording();
      setMessage((prev) => prev + (prev ? " " : "") + transcription);
      setIsRecording(false);
    } else {
      await startRecording();
      setIsRecording(true);
    }
  };

  const handleEmojiClick = (emojiObject: any) => {
    setMessage((prev) => prev + emojiObject.emoji);
    setShowEmojiPicker(false);
    textareaRef.current?.focus();
  };

  const handleFileAttach = async () => {
    const result = await window.electronAPI.selectFile();
    if (result.filePath) {
      // Handle file attachment
      console.log("File selected:", result.filePath);
    }
  };

  return (
    <div className="border-t border-gray-200 bg-white dark:bg-gray-900 dark:border-gray-700">
      <div className="flex items-end gap-2 p-4">
        {/* Text Input */}
        <div className="flex-1 relative">
          <textarea
            ref={textareaRef}
            value={message}
            onChange={(e) => setMessage(e.target.value)}
            onKeyDown={handleKeyPress}
            placeholder="ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”... Type a message..."
            disabled={isProcessing || isRecording}
            className={cn(
              "w-full px-4 py-3 pr-12 border border-gray-300 rounded-xl resize-none",
              "focus:outline-none focus:ring-2 focus:ring-yellow-400 focus:border-transparent",
              "dark:bg-gray-800 dark:border-gray-600 dark:text-white",
              "disabled:bg-gray-50 disabled:cursor-not-allowed",
              "transition-all"
            )}
            rows={1}
            maxLength={4000}
          />

          {/* Voice Button (inside input) */}
          {isVoiceSupported && (
            <button
              onClick={handleVoiceClick}
              disabled={isProcessing}
              className={cn(
                "absolute right-3 top-3 p-2 rounded-full transition-all",
                isRecording
                  ? "bg-red-500 text-white animate-pulse scale-110"
                  : "text-gray-400 hover:text-gray-600 hover:bg-gray-100"
              )}
              aria-label={isRecording ? "Stop recording" : "Start recording"}
            >
              <Mic className="w-5 h-5" />
            </button>
          )}

          {/* Character count */}
          {message.length > 3500 && (
            <div
              className={cn(
                "absolute bottom-2 left-3 text-xs",
                message.length >= 4000 ? "text-red-500" : "text-gray-400"
              )}
            >
              {message.length}/4000
            </div>
          )}
        </div>

        {/* Action Buttons */}
        <div className="flex items-center gap-1">
          <Button
            variant="ghost"
            size="icon"
            onClick={handleFileAttach}
            disabled={isProcessing}
            aria-label="Attach file"
          >
            <Paperclip className="w-5 h-5" />
          </Button>

          <div className="relative">
            <Button
              variant="ghost"
              size="icon"
              onClick={() => setShowEmojiPicker(!showEmojiPicker)}
              disabled={isProcessing}
              aria-label="Insert emoji"
            >
              <Smile className="w-5 h-5" />
            </Button>

            {showEmojiPicker && (
              <div className="absolute bottom-12 right-0 z-50">
                <EmojiPicker onEmojiClick={handleEmojiClick} />
              </div>
            )}
          </div>

          <Button
            onClick={handleSend}
            disabled={!message.trim() || isProcessing}
            className={cn(
              "bg-yellow-400 hover:bg-yellow-500 text-gray-900",
              "disabled:opacity-50 disabled:cursor-not-allowed",
              "transition-all"
            )}
            aria-label="Send message"
          >
            <Send className="w-5 h-5" />
          </Button>
        </div>
      </div>

      {/* Recording indicator */}
      {isRecording && (
        <div className="px-4 pb-3 flex items-center gap-2 text-red-500 animate-fade-in">
          <div className="w-2 h-2 bg-red-500 rounded-full animate-pulse" />
          <span className="text-sm font-medium">
            Recording... Click mic to stop
          </span>
        </div>
      )}
    </div>
  );
}
```

### 1.7 Scroll Behavior

```typescript
// hooks/useAutoScroll.ts

import { useEffect, useRef } from "react";

export function useAutoScroll(messages: Message[]) {
  const scrollRef = useRef<HTMLDivElement>(null);
  const userScrolledUp = useRef(false);

  // Detect user scroll
  useEffect(() => {
    const handleScroll = () => {
      if (!scrollRef.current) return;

      const { scrollTop, scrollHeight, clientHeight } = scrollRef.current;
      const isNearBottom = scrollHeight - scrollTop - clientHeight < 100;

      userScrolledUp.current = !isNearBottom;
    };

    scrollRef.current?.addEventListener("scroll", handleScroll);
    return () => scrollRef.current?.removeEventListener("scroll", handleScroll);
  }, []);

  // Auto-scroll on new messages
  useEffect(() => {
    if (!userScrolledUp.current && scrollRef.current) {
      scrollRef.current.scrollTo({
        top: scrollRef.current.scrollHeight,
        behavior: "smooth",
      });
    }
  }, [messages]);

  return scrollRef;
}
```

---

## 2. Design System & Theme

### 2.1 Complete Color Palette

```javascript
// tailwind.config.js

module.exports = {
  theme: {
    extend: {
      colors: {
        // KakaoTalk Yellow (Primary)
        kakao: {
          50: "#FEF9E7",
          100: "#FEF3CE",
          200: "#FDE89D",
          300: "#FCDC6C",
          400: "#FAE100", // Main KakaoTalk yellow
          500: "#E1CA00",
          600: "#B8A600",
          700: "#8F8100",
          800: "#665C00",
          900: "#3D3700",
        },

        // Warm Neutral
        warm: {
          50: "#FAFAF9", // Background primary (light)
          100: "#F5F5F4", // Background secondary
          200: "#E7E5E4", // Border light / Chat bg
          300: "#D6D3D1", // Border default
          400: "#A8A29E", // Text muted
          500: "#78716C", // Text secondary
          600: "#57534E", // Text primary (dark mode)
          700: "#44403C", // Background secondary (dark)
          800: "#292524", // Background primary (dark)
          900: "#1C1917", // Deepest dark
        },

        // Semantic Colors
        success: {
          light: "#86EFAC",
          DEFAULT: "#22C55E",
          dark: "#16A34A",
        },
        error: {
          light: "#FCA5A5",
          DEFAULT: "#EF4444",
          dark: "#DC2626",
        },
        warning: {
          light: "#FDE047",
          DEFAULT: "#EAB308",
          dark: "#CA8A04",
        },
        info: {
          light: "#93C5FD",
          DEFAULT: "#3B82F6",
          dark: "#2563EB",
        },
      },

      // Custom animations
      animation: {
        "fade-in": "fadeIn 0.2s ease-in",
        "fade-out": "fadeOut 0.2s ease-out",
        "slide-up": "slideUp 0.3s ease-out",
        "slide-down": "slideDown 0.3s ease-out",
        "pulse-subtle": "pulseSubtle 2s cubic-bezier(0.4, 0, 0.6, 1) infinite",
      },

      keyframes: {
        fadeIn: {
          "0%": { opacity: "0" },
          "100%": { opacity: "1" },
        },
        fadeOut: {
          "0%": { opacity: "1" },
          "100%": { opacity: "0" },
        },
        slideUp: {
          "0%": { transform: "translateY(10px)", opacity: "0" },
          "100%": { transform: "translateY(0)", opacity: "1" },
        },
        slideDown: {
          "0%": { transform: "translateY(-10px)", opacity: "0" },
          "100%": { transform: "translateY(0)", opacity: "1" },
        },
        pulseSubtle: {
          "0%, 100%": { opacity: "1" },
          "50%": { opacity: "0.95" },
        },
      },

      // Border radius
      borderRadius: {
        kakao: "1.5rem", // 24px - KakaoTalk bubble radius
      },
    },
  },
  plugins: [require("@tailwindcss/typography"), require("@tailwindcss/forms")],
};
```

### 2.2 Typography System

```css
/* styles/typography.css */

@import url("https://fonts.googleapis.com/css2?family=Pretendard:wght@300;400;500;600;700&display=swap");

:root {
  /* Font Family */
  --font-sans: "Pretendard", -apple-system, BlinkMacSystemFont, "Segoe UI", system-ui,
    sans-serif;
  --font-mono: "SF Mono", "Monaco", "Inconsolata", "Fira Code", monospace;

  /* Font Sizes */
  --text-xs: 0.75rem; /* 12px */
  --text-sm: 0.875rem; /* 14px */
  --text-base: 1rem; /* 16px */
  --text-lg: 1.125rem; /* 18px */
  --text-xl: 1.25rem; /* 20px */
  --text-2xl: 1.5rem; /* 24px */
  --text-3xl: 1.875rem; /* 30px */
  --text-4xl: 2.25rem; /* 36px */

  /* Line Heights */
  --leading-none: 1;
  --leading-tight: 1.25;
  --leading-snug: 1.375;
  --leading-normal: 1.5;
  --leading-relaxed: 1.625;
  --leading-loose: 2;

  /* Font Weights */
  --font-light: 300;
  --font-normal: 400;
  --font-medium: 500;
  --font-semibold: 600;
  --font-bold: 700;

  /* Letter Spacing */
  --tracking-tighter: -0.05em;
  --tracking-tight: -0.025em;
  --tracking-normal: 0em;
  --tracking-wide: 0.025em;
  --tracking-wider: 0.05em;
}

body {
  font-family: var(--font-sans);
  font-size: var(--text-base);
  line-height: var(--leading-normal);
  font-weight: var(--font-normal);
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

/* Headings */
h1 {
  font-size: var(--text-4xl);
  font-weight: var(--font-bold);
  line-height: var(--leading-tight);
}
h2 {
  font-size: var(--text-3xl);
  font-weight: var(--font-bold);
  line-height: var(--leading-tight);
}
h3 {
  font-size: var(--text-2xl);
  font-weight: var(--font-semibold);
  line-height: var(--leading-snug);
}
h4 {
  font-size: var(--text-xl);
  font-weight: var(--font-semibold);
  line-height: var(--leading-snug);
}

/* Code */
code {
  font-family: var(--font-mono);
  font-size: 0.9em;
}

pre {
  font-family: var(--font-mono);
  font-size: var(--text-sm);
  line-height: var(--leading-relaxed);
}
```

### 2.3 Dark Mode Implementation

```typescript
// renderer/providers/ThemeProvider.tsx

import React, { createContext, useContext, useEffect, useState } from "react";

type Theme = "light" | "dark" | "system";

interface ThemeContextType {
  theme: Theme;
  effectiveTheme: "light" | "dark";
  setTheme: (theme: Theme) => void;
}

const ThemeContext = createContext<ThemeContextType>({
  theme: "system",
  effectiveTheme: "light",
  setTheme: () => {},
});

export function ThemeProvider({ children }: { children: React.ReactNode }) {
  const [theme, setTheme] = useState<Theme>("system");
  const [effectiveTheme, setEffectiveTheme] = useState<"light" | "dark">(
    "light"
  );

  useEffect(() => {
    // Load saved theme
    const savedTheme = (localStorage.getItem("theme") as Theme) || "system";
    setTheme(savedTheme);
  }, []);

  useEffect(() => {
    const root = window.document.documentElement;

    const updateTheme = (newTheme: "light" | "dark") => {
      root.classList.remove("light", "dark");
      root.classList.add(newTheme);
      setEffectiveTheme(newTheme);
    };

    if (theme === "system") {
      const systemTheme = window.matchMedia("(prefers-color-scheme: dark)")
        .matches
        ? "dark"
        : "light";
      updateTheme(systemTheme);

      // Listen for system theme changes
      const mediaQuery = window.matchMedia("(prefers-color-scheme: dark)");
      const handler = (e: MediaQueryListEvent) => {
        updateTheme(e.matches ? "dark" : "light");
      };
      mediaQuery.addEventListener("change", handler);
      return () => mediaQuery.removeEventListener("change", handler);
    } else {
      updateTheme(theme);
    }

    // Save theme
    localStorage.setItem("theme", theme);
  }, [theme]);

  return (
    <ThemeContext.Provider value={{ theme, effectiveTheme, setTheme }}>
      {children}
    </ThemeContext.Provider>
  );
}

export const useTheme = () => useContext(ThemeContext);
```

### 2.4 Dark Mode Colors

```css
/* styles/dark-mode.css */

.dark {
  /* Background */
  --bg-primary: #1c1917;
  --bg-secondary: #292524;
  --bg-tertiary: #44403c;
  --bg-chat: #292524;

  /* Text */
  --text-primary: #fafaf9;
  --text-secondary: #d6d3d1;
  --text-muted: #a8a29e;

  /* Bubbles */
  --bubble-ai: #44403c;
  --bubble-ai-border: #57534e;
  --bubble-user: #b8a600; /* Darker yellow for dark mode */

  /* Borders */
  --border-light: #44403c;
  --border-default: #57534e;

  /* Interactive */
  --interactive-hover: #3d3700;
  --interactive-active: #8f8100;

  /* Shadows */
  --shadow-sm: 0 1px 2px 0 rgba(0, 0, 0, 0.3);
  --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.4);
  --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.5);
}

/* Smooth transition */
* {
  transition: background-color 0.2s ease, border-color 0.2s ease,
    color 0.2s ease;
}
```

---

## 3. Internationalization (i18n)

### 3.1 Complete i18n Setup

```typescript
// renderer/i18n/config.ts

import i18n from "i18next";
import { initReactI18next } from "react-i18next";
import LanguageDetector from "i18next-browser-languagedetector";
import Backend from "i18next-http-backend";

import en from "./locales/en.json";
import ko from "./locales/ko.json";

i18n
  .use(Backend)
  .use(LanguageDetector)
  .use(initReactI18next)
  .init({
    resources: {
      en: { translation: en },
      ko: { translation: ko },
    },
    fallbackLng: "en",
    supportedLngs: ["en", "ko"],

    interpolation: {
      escapeValue: false, // React already escapes
    },

    detection: {
      order: ["localStorage", "navigator"],
      caches: ["localStorage"],
    },

    react: {
      useSuspense: false,
    },
  });

export default i18n;
```

### 3.2 Complete Translation Files

**Korean (ko.json)**:

```json
{
  "app": {
    "name": "ê°€ë“  ì˜¤ë¸Œ ì—ë´",
    "tagline": "ë‹¹ì‹ ì˜ AI ì¹œêµ¬",
    "version": "ë²„ì „ {{version}}"
  },

  "chat": {
    "input_placeholder": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...",
    "typing": "ì…ë ¥ ì¤‘...",
    "voice_recording": "ìŒì„± ë…¹ìŒ ì¤‘...",
    "send": "ì „ì†¡",
    "attach_file": "íŒŒì¼ ì²¨ë¶€",
    "emoji": "ì´ëª¨í‹°ì½˜",
    "search": "ê²€ìƒ‰",
    "settings": "ì„¤ì •",
    "new_conversation": "ìƒˆ ëŒ€í™”",
    "read": "ì½ìŒ",
    "empty_state_title": "ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”",
    "empty_state_subtitle": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
  },

  "settings": {
    "title": "ì„¤ì •",
    "general": "ì¼ë°˜",
    "persona": "í˜ë¥´ì†Œë‚˜",
    "privacy": "ê°œì¸ì •ë³´",
    "advanced": "ê³ ê¸‰",
    "about": "ì •ë³´",

    "language": "ì–¸ì–´",
    "language_english": "English",
    "language_korean": "í•œêµ­ì–´",

    "theme": "í…Œë§ˆ",
    "theme_light": "ë¼ì´íŠ¸",
    "theme_dark": "ë‹¤í¬",
    "theme_system": "ì‹œìŠ¤í…œ",

    "voice": "ìŒì„±",
    "voice_enabled": "ìŒì„± ì…ë ¥ í™œì„±í™”",
    "voice_output_enabled": "ìŒì„± ì¶œë ¥ í™œì„±í™”",
    "voice_speed": "ìŒì„± ì†ë„",

    "screen_capture": "í™”ë©´ ìº¡ì²˜",
    "screen_capture_enabled": "í™”ë©´ ìº¡ì²˜ í™œì„±í™”",
    "screen_capture_warning": "AIê°€ í™”ë©´ì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤",
    "screen_capture_frequency": "ìº¡ì²˜ ë¹ˆë„ (ì´ˆ)",

    "mode": "ëª¨ë“œ",
    "mode_user_led": "ì‚¬ìš©ì ì£¼ë„",
    "mode_ai_led": "AI ì£¼ë„",
    "mode_description_user": "AIê°€ ìš”ì²­ì‹œì—ë§Œ ì‘ë‹µí•©ë‹ˆë‹¤",
    "mode_description_ai": "AIê°€ ëŠ¥ë™ì ìœ¼ë¡œ ì œì•ˆí•˜ê³  ë„ì›€ì„ ì¤ë‹ˆë‹¤"
  },

  "persona": {
    "title": "í˜ë¥´ì†Œë‚˜ ì„¤ì •",
    "description": "AIì˜ ì„±ê²©ì„ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆí•˜ì„¸ìš”",
    "current_persona": "í˜„ì¬ í˜ë¥´ì†Œë‚˜",

    "warmth": "ì¹œê·¼í•¨",
    "warmth_description": "ì°¨ê°€ì›€ â† â†’ ë”°ëœ»í•¨",

    "formality": "ê²©ì‹",
    "formality_description": "ê²©ì˜ì—†ìŒ â† â†’ ê²©ì‹ìˆìŒ",

    "humor": "ìœ ë¨¸",
    "humor_description": "ì§„ì§€í•¨ â† â†’ ìœ ë¨¸ëŸ¬ìŠ¤",

    "verbosity": "ë§ìˆ˜",
    "verbosity_description": "ê°„ê²°í•¨ â† â†’ ìì„¸í•¨",

    "proactivity": "ì ê·¹ì„±",
    "proactivity_description": "ìˆ˜ë™ì  â† â†’ ëŠ¥ë™ì ",

    "creativity": "ì°½ì˜ì„±",
    "creativity_description": "ë³´ìˆ˜ì  â† â†’ ì°½ì˜ì ",

    "empathy": "ê³µê°",
    "empathy_description": "ë…¼ë¦¬ì  â† â†’ ê³µê°ì ",

    "directness": "ì§ì„¤ì„±",
    "directness_description": "ì™„ê³¡í•¨ â† â†’ ì§ì„¤ì ",

    "reset": "ê¸°ë³¸ê°’ìœ¼ë¡œ ì¬ì„¤ì •",
    "save": "ì €ì¥",
    "saved": "ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤"
  },

  "notifications": {
    "title": "ì•Œë¦¼",
    "proactive_enabled": "ëŠ¥ë™ì  ì•Œë¦¼ í™œì„±í™”",
    "sound_enabled": "ì†Œë¦¬ í™œì„±í™”",
    "desktop_notifications": "ë°ìŠ¤í¬í†± ì•Œë¦¼",
    "notification_center": "ì•Œë¦¼ ì„¼í„°"
  },

  "history": {
    "title": "ëŒ€í™” ê¸°ë¡",
    "search_placeholder": "ëŒ€í™” ê²€ìƒ‰...",
    "filter_all": "ì „ì²´",
    "filter_today": "ì˜¤ëŠ˜",
    "filter_week": "ì´ë²ˆ ì£¼",
    "filter_month": "ì´ë²ˆ ë‹¬",
    "no_results": "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤",
    "messages_count": "{{count}}ê°œ ë©”ì‹œì§€",
    "delete": "ì‚­ì œ",
    "delete_confirm": "ì´ ëŒ€í™”ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
  },

  "errors": {
    "generic": "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
    "network": "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜",
    "ai_unavailable": "AI ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
    "voice_not_supported": "ì´ ê¸°ê¸°ì—ì„œ ìŒì„± ì…ë ¥ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤",
    "file_too_large": "íŒŒì¼ì´ ë„ˆë¬´ í½ë‹ˆë‹¤ (ìµœëŒ€ {{size}}MB)",
    "retry": "ë‹¤ì‹œ ì‹œë„",
    "dismiss": "ë‹«ê¸°"
  },

  "keyboard_shortcuts": {
    "title": "í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤",
    "new_conversation": "ìƒˆ ëŒ€í™”",
    "search": "ê²€ìƒ‰",
    "settings": "ì„¤ì •",
    "toggle_voice": "ìŒì„± ì…ë ¥ í† ê¸€",
    "send_message": "ë©”ì‹œì§€ ì „ì†¡"
  }
}
```

**English (en.json)**:

```json
{
  "app": {
    "name": "Eden Project",
    "tagline": "Your AI Companion",
    "version": "Version {{version}}"
  },

  "chat": {
    "input_placeholder": "Type a message...",
    "typing": "Typing...",
    "voice_recording": "Recording voice...",
    "send": "Send",
    "attach_file": "Attach file",
    "emoji": "Emoji",
    "search": "Search",
    "settings": "Settings",
    "new_conversation": "New conversation",
    "read": "Read",
    "empty_state_title": "Start a new conversation",
    "empty_state_subtitle": "How can I help you today?"
  },

  "settings": {
    "title": "Settings",
    "general": "General",
    "persona": "Persona",
    "privacy": "Privacy",
    "advanced": "Advanced",
    "about": "About",

    "language": "Language",
    "language_english": "English",
    "language_korean": "í•œêµ­ì–´",

    "theme": "Theme",
    "theme_light": "Light",
    "theme_dark": "Dark",
    "theme_system": "System",

    "voice": "Voice",
    "voice_enabled": "Enable voice input",
    "voice_output_enabled": "Enable voice output",
    "voice_speed": "Voice speed",

    "screen_capture": "Screen Capture",
    "screen_capture_enabled": "Enable screen capture",
    "screen_capture_warning": "AI will be able to see your screen",
    "screen_capture_frequency": "Capture frequency (seconds)",

    "mode": "Mode",
    "mode_user_led": "User-Led",
    "mode_ai_led": "AI-Led",
    "mode_description_user": "AI responds only when asked",
    "mode_description_ai": "AI proactively suggests and helps"
  },

  "persona": {
    "title": "Persona Settings",
    "description": "Customize your AI's personality",
    "current_persona": "Current Persona",

    "warmth": "Warmth",
    "warmth_description": "Cold â† â†’ Warm",

    "formality": "Formality",
    "formality_description": "Casual â† â†’ Formal",

    "humor": "Humor",
    "humor_description": "Serious â† â†’ Playful",

    "verbosity": "Verbosity",
    "verbosity_description": "Concise â† â†’ Detailed",

    "proactivity": "Proactivity",
    "proactivity_description": "Reactive â† â†’ Proactive",

    "creativity": "Creativity",
    "creativity_description": "Conservative â† â†’ Creative",

    "empathy": "Empathy",
    "empathy_description": "Logical â† â†’ Empathetic",

    "directness": "Directness",
    "directness_description": "Indirect â† â†’ Direct",

    "reset": "Reset to defaults",
    "save": "Save",
    "saved": "Saved successfully"
  },

  "notifications": {
    "title": "Notifications",
    "proactive_enabled": "Enable proactive notifications",
    "sound_enabled": "Enable sound",
    "desktop_notifications": "Desktop notifications",
    "notification_center": "Notification Center"
  },

  "history": {
    "title": "Conversation History",
    "search_placeholder": "Search conversations...",
    "filter_all": "All time",
    "filter_today": "Today",
    "filter_week": "This week",
    "filter_month": "This month",
    "no_results": "No results found",
    "messages_count": "{{count}} messages",
    "delete": "Delete",
    "delete_confirm": "Are you sure you want to delete this conversation?"
  },

  "errors": {
    "generic": "An error occurred",
    "network": "Network error",
    "ai_unavailable": "AI model unavailable",
    "voice_not_supported": "Voice input is not supported on this device",
    "file_too_large": "File is too large (max {{size}}MB)",
    "retry": "Retry",
    "dismiss": "Dismiss"
  },

  "keyboard_shortcuts": {
    "title": "Keyboard Shortcuts",
    "new_conversation": "New conversation",
    "search": "Search",
    "settings": "Settings",
    "toggle_voice": "Toggle voice input",
    "send_message": "Send message"
  }
}
```

### 3.3 Usage in Components

```tsx
// renderer/pages/Chat.tsx

import { useTranslation } from "react-i18next";

export function Chat() {
  const { t, i18n } = useTranslation();

  const changeLanguage = (lng: string) => {
    i18n.changeLanguage(lng);
  };

  return (
    <div>
      <h1>{t("app.name")}</h1>
      <p>{t("app.tagline")}</p>

      <input placeholder={t("chat.input_placeholder")} />

      <button onClick={() => changeLanguage("ko")}>
        {t("settings.language_korean")}
      </button>
      <button onClick={() => changeLanguage("en")}>
        {t("settings.language_english")}
      </button>
    </div>
  );
}
```

---

(This file continues with remaining sections 4-10, but I'll save it now and continue appending in the next response to avoid exceeding token limits)

## 4. Voice Input/Output UI

### 4.1 Voice Recording Button (Complete)

```tsx
// renderer/components/voice/VoiceRecordButton.tsx

import { Mic, MicOff, Loader2 } from "lucide-react";
import { cn } from "@/lib/utils";
import { useState, useEffect } from "react";

interface VoiceRecordButtonProps {
  isRecording: boolean;
  isProcessing: boolean;
  onToggle: () => void;
  disabled?: boolean;
}

export function VoiceRecordButton({
  isRecording,
  isProcessing,
  onToggle,
  disabled = false,
}: VoiceRecordButtonProps) {
  const [audioLevel, setAudioLevel] = useState(0);

  // Simulate audio level (in real app, get from microphone)
  useEffect(() => {
    if (!isRecording) {
      setAudioLevel(0);
      return;
    }

    const interval = setInterval(() => {
      setAudioLevel(Math.random() * 100);
    }, 100);

    return () => clearInterval(interval);
  }, [isRecording]);

  return (
    <button
      onClick={onToggle}
      disabled={disabled || isProcessing}
      className={cn(
        "relative p-4 rounded-full transition-all duration-200",
        "focus:outline-none focus:ring-4 focus:ring-offset-2",
        isRecording && "bg-red-500 text-white scale-110 shadow-lg",
        !isRecording &&
          !isProcessing &&
          "bg-gray-200 text-gray-700 hover:bg-gray-300",
        isProcessing && "bg-gray-300 cursor-wait",
        disabled && "opacity-50 cursor-not-allowed"
      )}
      aria-label={isRecording ? "Stop recording" : "Start recording"}
    >
      {isProcessing ? (
        <Loader2 className="w-6 h-6 animate-spin" />
      ) : isRecording ? (
        <>
          <MicOff className="w-6 h-6" />
          {/* Audio level indicator */}
          <div
            className="absolute inset-0 rounded-full border-4 border-white animate-ping"
            style={{
              animationDuration: "1s",
              opacity: audioLevel / 200,
            }}
          />
        </>
      ) : (
        <Mic className="w-6 h-6" />
      )}
    </button>
  );
}
```

### 4.2 Waveform Visualization

```tsx
// renderer/components/voice/WaveformVisualizer.tsx

import { useEffect, useRef } from "react";

interface WaveformVisualizerProps {
  audioData: number[]; // 0-255 values
  isActive: boolean;
}

export function WaveformVisualizer({
  audioData,
  isActive,
}: WaveformVisualizerProps) {
  const canvasRef = useRef<HTMLCanvasElement>(null);

  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    // Clear canvas
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    if (!isActive || audioData.length === 0) return;

    // Draw waveform bars
    const barWidth = canvas.width / audioData.length;
    const barGap = 2;

    audioData.forEach((value, index) => {
      const barHeight = (value / 255) * canvas.height * 0.8;
      const x = index * barWidth;
      const y = (canvas.height - barHeight) / 2;

      // Gradient fill
      const gradient = ctx.createLinearGradient(0, y, 0, y + barHeight);
      gradient.addColorStop(0, "#FAE100");
      gradient.addColorStop(1, "#E1CA00");

      ctx.fillStyle = gradient;
      ctx.fillRect(x, y, barWidth - barGap, barHeight);

      // Add glow effect
      ctx.shadowBlur = 10;
      ctx.shadowColor = "#FAE100";
    });
  }, [audioData, isActive]);

  return (
    <div className="relative w-full h-16 bg-gray-100 dark:bg-gray-800 rounded-lg overflow-hidden">
      <canvas
        ref={canvasRef}
        width={600}
        height={64}
        className="w-full h-full"
      />
      {!isActive && (
        <div className="absolute inset-0 flex items-center justify-center text-gray-400">
          <Mic className="w-8 h-8" />
        </div>
      )}
    </div>
  );
}
```

### 4.3 TTS Playback Control

```tsx
// renderer/components/voice/TTSPlayer.tsx

import { Play, Pause, Volume2, VolumeX } from "lucide-react";
import { useState, useEffect, useRef } from "react";
import { Slider } from "@/components/ui/slider";

interface TTSPlayerProps {
  text: string;
  autoPlay?: boolean;
  onComplete?: () => void;
}

export function TTSPlayer({
  text,
  autoPlay = false,
  onComplete,
}: TTSPlayerProps) {
  const [isPlaying, setIsPlaying] = useState(false);
  const [isMuted, setIsMuted] = useState(false);
  const [volume, setVolume] = useState(0.8);
  const [progress, setProgress] = useState(0);
  const utteranceRef = useRef<SpeechSynthesisUtterance | null>(null);

  useEffect(() => {
    if (autoPlay && text) {
      play();
    }
  }, [text, autoPlay]);

  const play = async () => {
    if (!text) return;

    // Use Web Speech API or call IPC for better quality
    const audioBuffer = await window.electronAPI.aiSpeak({
      text,
      voice: "female", // or from settings
    });

    // Play audio
    const audio = new Audio();
    audio.src = URL.createObjectURL(
      new Blob([audioBuffer], { type: "audio/wav" })
    );
    audio.volume = isMuted ? 0 : volume;

    audio.addEventListener("timeupdate", () => {
      setProgress((audio.currentTime / audio.duration) * 100);
    });

    audio.addEventListener("ended", () => {
      setIsPlaying(false);
      setProgress(0);
      onComplete?.();
    });

    audio.play();
    setIsPlaying(true);
  };

  const pause = () => {
    // Implement pause
    setIsPlaying(false);
  };

  return (
    <div className="flex items-center gap-3 px-4 py-2 bg-gray-50 dark:bg-gray-800 rounded-lg">
      {/* Play/Pause */}
      <button
        onClick={isPlaying ? pause : play}
        className="p-2 hover:bg-gray-200 dark:hover:bg-gray-700 rounded-full transition"
      >
        {isPlaying ? (
          <Pause className="w-4 h-4" />
        ) : (
          <Play className="w-4 h-4" />
        )}
      </button>

      {/* Progress Bar */}
      <div className="flex-1">
        <div className="h-1 bg-gray-300 dark:bg-gray-600 rounded-full overflow-hidden">
          <div
            className="h-full bg-yellow-400 transition-all"
            style={{ width: `${progress}%` }}
          />
        </div>
      </div>

      {/* Volume Control */}
      <button
        onClick={() => setIsMuted(!isMuted)}
        className="p-2 hover:bg-gray-200 dark:hover:bg-gray-700 rounded-full transition"
      >
        {isMuted ? (
          <VolumeX className="w-4 h-4" />
        ) : (
          <Volume2 className="w-4 h-4" />
        )}
      </button>

      <div className="w-24">
        <Slider
          value={[isMuted ? 0 : volume * 100]}
          onValueChange={([v]) => {
            setVolume(v / 100);
            setIsMuted(v === 0);
          }}
          max={100}
          step={1}
        />
      </div>
    </div>
  );
}
```

---

## 5. Dual Mode: User-Led vs AI-Led

### 5.1 Mode Switcher Component (Complete)

```tsx
// renderer/components/ModeSwitcher.tsx

import { User, Sparkles } from "lucide-react";
import { useSettingsStore } from "@/stores/settingsStore";
import { useTranslation } from "react-i18next";
import { cn } from "@/lib/utils";

export function ModeSwitcher() {
  const { t } = useTranslation();
  const { mode, setMode } = useSettingsStore();

  return (
    <div className="inline-flex gap-1 p-1 bg-gray-100 dark:bg-gray-800 rounded-lg">
      <button
        onClick={() => setMode("user-led")}
        className={cn(
          "flex items-center gap-2 px-4 py-2 rounded-md text-sm font-medium transition-all",
          mode === "user-led"
            ? "bg-white dark:bg-gray-700 text-gray-900 dark:text-white shadow-sm"
            : "text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-white"
        )}
      >
        <User className="w-4 h-4" />
        <span>{t("settings.mode_user_led")}</span>
      </button>

      <button
        onClick={() => setMode("ai-led")}
        className={cn(
          "flex items-center gap-2 px-4 py-2 rounded-md text-sm font-medium transition-all",
          mode === "ai-led"
            ? "bg-yellow-400 text-gray-900 shadow-sm"
            : "text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-white"
        )}
      >
        <Sparkles className="w-4 h-4" />
        <span>{t("settings.mode_ai_led")}</span>
      </button>
    </div>
  );
}
```

### 5.2 Mode Behavior Implementation

```typescript
// main/services/proactive/proactive-manager.ts

export class ProactiveManager {
  private mode: "user-led" | "ai-led" = "user-led";
  private enabled = false;

  setMode(mode: "user-led" | "ai-led") {
    this.mode = mode;
    this.enabled = mode === "ai-led";

    if (this.enabled) {
      this.startMonitoring();
    } else {
      this.stopMonitoring();
    }
  }

  private startMonitoring() {
    // Monitor git status every 5 minutes
    setInterval(() => this.checkGitStatus(), 5 * 60 * 1000);

    // Monitor calendar every 10 minutes
    setInterval(() => this.checkUpcomingEvents(), 10 * 60 * 1000);

    // Monitor workspace every 2 minutes
    setInterval(() => this.checkWorkspaceChanges(), 2 * 60 * 1000);
  }

  private stopMonitoring() {
    // Clear all intervals
  }

  private async checkGitStatus() {
    const status = await gitService.getStatus();

    if (status.modified.length > 5) {
      this.sendNotification({
        type: "git-uncommitted",
        title: "Uncommitted Changes",
        message: `You have ${status.modified.length} modified files. Would you like to create a commit?`,
        actions: [
          { label: "Create commit", action: "git-commit" },
          { label: "Not now", action: "dismiss" },
        ],
      });
    }
  }

  private async checkUpcomingEvents() {
    const events = await calendarService.getUpcomingEvents(30); // 30 min

    if (events.length > 0) {
      const event = events[0];
      this.sendNotification({
        type: "calendar-reminder",
        title: "Upcoming Event",
        message: `"${event.title}" starts in ${formatDuration(event.start)}`,
        actions: [
          { label: "Prepare", action: "calendar-prepare" },
          { label: "Snooze", action: "snooze" },
        ],
      });
    }
  }
}
```

---

## 6. Proactive Notifications

### 6.1 Notification Component (Complete)

```tsx
// renderer/components/notifications/ProactiveNotification.tsx

import { X, CheckCircle, Sparkles, AlertCircle, Info } from "lucide-react";
import { cn } from "@/lib/utils";

type NotificationType = "success" | "info" | "warning" | "error" | "proactive";

interface ProactiveNotificationProps {
  id: string;
  type: NotificationType;
  title: string;
  message: string;
  actions?: Array<{
    label: string;
    onClick: () => void;
    variant?: "primary" | "secondary" | "danger";
  }>;
  onDismiss: () => void;
  autoClose?: number; // ms
}

export function ProactiveNotification({
  id,
  type,
  title,
  message,
  actions,
  onDismiss,
  autoClose,
}: ProactiveNotificationProps) {
  const [isExiting, setIsExiting] = useState(false);

  useEffect(() => {
    if (autoClose) {
      const timer = setTimeout(() => {
        handleDismiss();
      }, autoClose);
      return () => clearTimeout(timer);
    }
  }, [autoClose]);

  const handleDismiss = () => {
    setIsExiting(true);
    setTimeout(() => {
      onDismiss();
    }, 200); // Animation duration
  };

  const icons = {
    success: <CheckCircle className="w-5 h-5 text-green-500" />,
    info: <Info className="w-5 h-5 text-blue-500" />,
    warning: <AlertCircle className="w-5 h-5 text-yellow-500" />,
    error: <AlertCircle className="w-5 h-5 text-red-500" />,
    proactive: <Sparkles className="w-5 h-5 text-yellow-500" />,
  };

  return (
    <div
      className={cn(
        "fixed bottom-4 right-4 w-96 bg-white dark:bg-gray-800 rounded-xl shadow-2xl p-4",
        "border border-gray-200 dark:border-gray-700",
        "transition-all duration-200",
        isExiting
          ? "animate-slide-out-right opacity-0"
          : "animate-slide-in-right"
      )}
    >
      <div className="flex items-start gap-3">
        {/* Icon */}
        <div className="flex-shrink-0 mt-0.5">{icons[type]}</div>

        {/* Content */}
        <div className="flex-1 min-w-0">
          <div className="flex items-start justify-between mb-1">
            <h3 className="font-semibold text-gray-900 dark:text-white">
              {title}
            </h3>
            <button
              onClick={handleDismiss}
              className="text-gray-400 hover:text-gray-600 dark:hover:text-gray-300 transition"
            >
              <X className="w-4 h-4" />
            </button>
          </div>

          <p className="text-sm text-gray-600 dark:text-gray-300 mb-3">
            {message}
          </p>

          {/* Actions */}
          {actions && actions.length > 0 && (
            <div className="flex gap-2">
              {actions.map((action, index) => (
                <button
                  key={index}
                  onClick={() => {
                    action.onClick();
                    handleDismiss();
                  }}
                  className={cn(
                    "px-4 py-2 rounded-lg text-sm font-medium transition-colors",
                    action.variant === "primary" &&
                      "bg-yellow-400 hover:bg-yellow-500 text-gray-900",
                    action.variant === "danger" &&
                      "bg-red-500 hover:bg-red-600 text-white",
                    (!action.variant || action.variant === "secondary") &&
                      "bg-gray-200 dark:bg-gray-700 hover:bg-gray-300 dark:hover:bg-gray-600 text-gray-900 dark:text-white"
                  )}
                >
                  {action.label}
                </button>
              ))}
            </div>
          )}
        </div>
      </div>

      {/* Progress bar for auto-close */}
      {autoClose && (
        <div className="absolute bottom-0 left-0 right-0 h-1 bg-gray-200 dark:bg-gray-700 rounded-b-xl overflow-hidden">
          <div
            className="h-full bg-yellow-400 animate-shrink-width"
            style={{ animationDuration: `${autoClose}ms` }}
          />
        </div>
      )}
    </div>
  );
}
```

### 6.2 Notification Scenarios (10 Examples)

```typescript
// Scenario 1: Git Uncommitted Changes
{
  type: 'proactive',
  title: 'Uncommitted Changes Detected',
  message: 'You have 3 modified files in your git repository. Would you like me to create a commit?',
  actions: [
    { label: 'Create Commit', onClick: handleGitCommit, variant: 'primary' },
    { label: 'Review Changes', onClick: handleGitDiff, variant: 'secondary' },
    { label: 'Not Now', onClick: handleDismiss, variant: 'secondary' },
  ]
}

// Scenario 2: Upcoming Meeting
{
  type: 'info',
  title: 'Meeting in 15 Minutes',
  message: 'Team standup starts at 2:00 PM. Would you like me to prepare a summary of your recent work?',
  actions: [
    { label: 'Prepare Summary', onClick: handlePrepareSummary, variant: 'primary' },
    { label: 'Snooze 5min', onClick: handleSnooze, variant: 'secondary' },
  ]
}

// Scenario 3: Optimal Focus Time
{
  type: 'proactive',
  title: 'Optimal Coding Time Available',
  message: 'You have a 2.5 hour free block from 11:00-13:30. Perfect for deep work on your React project!',
  actions: [
    { label: 'Start Focus Mode', onClick: handleFocusMode, variant: 'primary' },
    { label: 'Remind Me Later', onClick: handleRemindLater, variant: 'secondary' },
  ]
}

// Scenario 4: Long Coding Session
{
  type: 'warning',
  title: 'Take a Break',
  message: "You've been coding for 2 hours straight. Research shows breaks improve productivity and prevent burnout.",
  actions: [
    { label: 'Take 5min Break', onClick: handleBreak, variant: 'primary' },
    { label: 'Remind in 30min', onClick: handleSnooze30, variant: 'secondary' },
  ]
}

// Scenario 5: Build Failure
{
  type: 'error',
  title: 'Build Failed',
  message: 'Your last build failed with 3 TypeScript errors. Would you like me to analyze them?',
  actions: [
    { label: 'Show Errors', onClick: handleShowErrors, variant: 'danger' },
    { label: 'Dismiss', onClick: handleDismiss, variant: 'secondary' },
  ]
}

// Scenario 6: Dependency Update
{
  type: 'info',
  title: 'Dependencies Outdated',
  message: '5 npm packages have updates available. Would you like to review them?',
  actions: [
    { label: 'Show Updates', onClick: handleShowUpdates, variant: 'primary' },
    { label: 'Update All', onClick: handleUpdateAll, variant: 'secondary' },
    { label: 'Ignore', onClick: handleDismiss, variant: 'secondary' },
  ]
}

// Scenario 7: Code Quality Suggestion
{
  type: 'proactive',
  title: 'Code Quality Improvement',
  message: 'I noticed repeated code in UserService.ts and AuthService.ts. Would you like me to suggest a refactor?',
  actions: [
    { label: 'Show Suggestion', onClick: handleShowSuggestion, variant: 'primary' },
    { label: 'Not Now', onClick: handleDismiss, variant: 'secondary' },
  ]
}

// Scenario 8: Screen Time
{
  type: 'warning',
  title: 'Screen Time Alert',
  message: "You've been working for 6 hours today. Consider wrapping up for a healthy work-life balance.",
  actions: [
    { label: 'Create End-of-Day Summary', onClick: handleEODSummary, variant: 'primary' },
    { label: 'Keep Working', onClick: handleDismiss, variant: 'secondary' },
  ]
}

// Scenario 9: Learning Opportunity
{
  type: 'info',
  title: 'Learning Opportunity',
  message: "You've used Array.map() 15 times today. Did you know about Array.flatMap() for nested arrays?",
  actions: [
    { label: 'Learn More', onClick: handleLearnMore, variant: 'primary' },
    { label: 'Got It', onClick: handleDismiss, variant: 'secondary' },
  ]
}

// Scenario 10: Achievement Unlocked
{
  type: 'success',
  title: 'ğŸ‰ Milestone Achieved!',
  message: "You've completed 50 commits this week! Great job on staying productive.",
  actions: [
    { label: 'View Stats', onClick: handleViewStats, variant: 'primary' },
  ],
  autoClose: 5000
}
```

### 6.3 Notification Manager

```typescript
// stores/notificationStore.ts

import { create } from "zustand";

interface Notification {
  id: string;
  type: "success" | "info" | "warning" | "error" | "proactive";
  title: string;
  message: string;
  actions?: any[];
  timestamp: Date;
}

interface NotificationStore {
  notifications: Notification[];
  add: (notification: Omit<Notification, "id" | "timestamp">) => void;
  remove: (id: string) => void;
  clear: () => void;
}

export const useNotificationStore = create<NotificationStore>((set) => ({
  notifications: [],

  add: (notification) =>
    set((state) => ({
      notifications: [
        ...state.notifications,
        {
          ...notification,
          id: crypto.randomUUID(),
          timestamp: new Date(),
        },
      ],
    })),

  remove: (id) =>
    set((state) => ({
      notifications: state.notifications.filter((n) => n.id !== id),
    })),

  clear: () => set({ notifications: [] }),
}));
```

---

## 7. Settings & Persona Configuration

### 7.1 Settings Screen (Complete)

```tsx
// renderer/pages/Settings.tsx

import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import { GeneralSettings } from "@/components/settings/GeneralSettings";
import { PersonaSettings } from "@/components/settings/PersonaSettings";
import { PrivacySettings } from "@/components/settings/PrivacySettings";
import { AdvancedSettings } from "@/components/settings/AdvancedSettings";
import { AboutSettings } from "@/components/settings/AboutSettings";
import { useTranslation } from "react-i18next";
import { Settings as SettingsIcon } from "lucide-react";

export function Settings() {
  const { t } = useTranslation();

  return (
    <div className="max-w-5xl mx-auto p-8">
      {/* Header */}
      <div className="flex items-center gap-3 mb-8">
        <SettingsIcon className="w-8 h-8 text-yellow-500" />
        <h1 className="text-3xl font-bold">{t("settings.title")}</h1>
      </div>

      {/* Tabs */}
      <Tabs defaultValue="general" className="w-full">
        <TabsList className="grid grid-cols-5 w-full mb-8">
          <TabsTrigger value="general">{t("settings.general")}</TabsTrigger>
          <TabsTrigger value="persona">{t("settings.persona")}</TabsTrigger>
          <TabsTrigger value="privacy">{t("settings.privacy")}</TabsTrigger>
          <TabsTrigger value="advanced">{t("settings.advanced")}</TabsTrigger>
          <TabsTrigger value="about">{t("settings.about")}</TabsTrigger>
        </TabsList>

        <TabsContent value="general" className="space-y-6">
          <GeneralSettings />
        </TabsContent>

        <TabsContent value="persona" className="space-y-6">
          <PersonaSettings />
        </TabsContent>

        <TabsContent value="privacy" className="space-y-6">
          <PrivacySettings />
        </TabsContent>

        <TabsContent value="advanced" className="space-y-6">
          <AdvancedSettings />
        </TabsContent>

        <TabsContent value="about" className="space-y-6">
          <AboutSettings />
        </TabsContent>
      </Tabs>
    </div>
  );
}
```

### 7.2 Persona Settings (Complete with All Parameters)

```tsx
// renderer/components/settings/PersonaSettings.tsx

import { Slider } from "@/components/ui/slider";
import { Button } from "@/components/ui/button";
import { usePersonaStore } from "@/stores/personaStore";
import { useTranslation } from "react-i18next";
import { RotateCcw, Save, Sparkles } from "lucide-react";

export function PersonaSettings() {
  const { t } = useTranslation();
  const { persona, updatePersona, resetPersona, savePersona, isSaving } =
    usePersonaStore();

  const parameters = [
    {
      key: "warmth",
      icon: "ğŸ¤—",
      labels: ["Cold", "Warm"],
    },
    {
      key: "formality",
      icon: "ğŸ‘”",
      labels: ["Casual", "Formal"],
    },
    {
      key: "humor",
      icon: "ğŸ˜„",
      labels: ["Serious", "Playful"],
    },
    {
      key: "verbosity",
      icon: "ğŸ’¬",
      labels: ["Concise", "Detailed"],
    },
    {
      key: "proactivity",
      icon: "ğŸš€",
      labels: ["Reactive", "Proactive"],
    },
    {
      key: "creativity",
      icon: "ğŸ¨",
      labels: ["Conservative", "Creative"],
    },
    {
      key: "empathy",
      icon: "â¤ï¸",
      labels: ["Logical", "Empathetic"],
    },
    {
      key: "directness",
      icon: "ğŸ¯",
      labels: ["Indirect", "Direct"],
    },
  ];

  return (
    <div className="space-y-8">
      {/* Header */}
      <div>
        <div className="flex items-center gap-2 mb-2">
          <Sparkles className="w-6 h-6 text-yellow-500" />
          <h2 className="text-2xl font-semibold">{t("persona.title")}</h2>
        </div>
        <p className="text-gray-600 dark:text-gray-400">
          {t("persona.description")}
        </p>
      </div>

      {/* Current Persona Preview */}
      <div className="p-6 bg-gradient-to-br from-yellow-50 to-yellow-100 dark:from-gray-800 dark:to-gray-700 rounded-xl border border-yellow-200 dark:border-gray-600">
        <h3 className="text-lg font-semibold mb-2 flex items-center gap-2">
          <span>ğŸŒ¿</span>
          {t("persona.current_persona")}
        </h3>
        <p className="text-sm text-gray-700 dark:text-gray-300">
          {getPersonaDescription(persona)}
        </p>
      </div>

      {/* Parameter Sliders */}
      <div className="grid gap-8">
        {parameters.map((param) => (
          <div key={param.key} className="space-y-3">
            <div className="flex items-center justify-between">
              <label className="flex items-center gap-2 text-sm font-medium">
                <span className="text-xl">{param.icon}</span>
                <span>{t(`persona.${param.key}`)}</span>
              </label>
              <span className="text-sm font-mono text-gray-500">
                {(persona[param.key] * 100).toFixed(0)}%
              </span>
            </div>

            <Slider
              value={[persona[param.key] * 100]}
              onValueChange={([value]) =>
                updatePersona({ [param.key]: value / 100 })
              }
              min={0}
              max={100}
              step={5}
              className="w-full"
            />

            <div className="flex justify-between text-xs text-gray-500">
              <span>{param.labels[0]}</span>
              <span>{param.labels[1]}</span>
            </div>
          </div>
        ))}
      </div>

      {/* Actions */}
      <div className="flex gap-4 pt-4 border-t dark:border-gray-700">
        <Button
          onClick={resetPersona}
          variant="outline"
          className="flex items-center gap-2"
        >
          <RotateCcw className="w-4 h-4" />
          {t("persona.reset")}
        </Button>

        <Button
          onClick={savePersona}
          disabled={isSaving}
          className="flex items-center gap-2 bg-yellow-400 hover:bg-yellow-500 text-gray-900"
        >
          <Save className="w-4 h-4" />
          {isSaving ? "Saving..." : t("persona.save")}
        </Button>
      </div>
    </div>
  );
}

function getPersonaDescription(persona: PersonaParameters): string {
  const traits = [];

  if (persona.warmth > 0.7) traits.push("warm and friendly");
  if (persona.formality > 0.7) traits.push("professional");
  else if (persona.formality < 0.3) traits.push("casual");
  if (persona.humor > 0.7) traits.push("playful");
  if (persona.proactivity > 0.7) traits.push("proactive");
  if (persona.empathy > 0.7) traits.push("empathetic");

  return `A ${traits.join(", ")} AI assistant that adapts to your style.`;
}
```

---

(Continuing with sections 8-10...)

## 8. Conversation History

### 8.1 History Screen (Complete)

```tsx
// renderer/pages/History.tsx

import { useState, useEffect } from "react";
import { Search, Calendar, Filter, Trash2, Download } from "lucide-react";
import { ConversationCard } from "@/components/history/ConversationCard";
import { useTranslation } from "react-i18next";
import { Input } from "@/components/ui/input";
import { Select } from "@/components/ui/select";

type FilterPeriod = "all" | "today" | "week" | "month";

export function History() {
  const { t } = useTranslation();
  const [conversations, setConversations] = useState([]);
  const [searchQuery, setSearchQuery] = useState("");
  const [filter, setFilter] = useState<FilterPeriod>("all");
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    loadConversations();
  }, [filter]);

  const loadConversations = async () => {
    setLoading(true);
    const data = await window.electronAPI.getConversations({ filter });
    setConversations(data);
    setLoading(false);
  };

  const filteredConversations = conversations.filter(
    (conv) =>
      searchQuery === "" ||
      conv.title?.toLowerCase().includes(searchQuery.toLowerCase()) ||
      conv.messages.some((m) =>
        m.content.toLowerCase().includes(searchQuery.toLowerCase())
      )
  );

  const handleDelete = async (id: string) => {
    if (confirm(t("history.delete_confirm"))) {
      await window.electronAPI.deleteConversation(id);
      setConversations(conversations.filter((c) => c.id !== id));
    }
  };

  const handleExport = async (id: string) => {
    await window.electronAPI.exportConversation(id);
  };

  return (
    <div className="max-w-6xl mx-auto p-8">
      {/* Header */}
      <div className="flex items-center justify-between mb-8">
        <h1 className="text-3xl font-bold">{t("history.title")}</h1>

        <div className="flex gap-2">
          <button
            onClick={() => setConversations([])}
            className="px-4 py-2 text-sm text-gray-600 hover:text-gray-900 dark:text-gray-400 dark:hover:text-white"
          >
            Clear All
          </button>
        </div>
      </div>

      {/* Search & Filters */}
      <div className="flex gap-4 mb-6">
        {/* Search */}
        <div className="flex-1 relative">
          <Search className="absolute left-3 top-1/2 -translate-y-1/2 w-5 h-5 text-gray-400" />
          <Input
            type="text"
            placeholder={t("history.search_placeholder")}
            value={searchQuery}
            onChange={(e) => setSearchQuery(e.target.value)}
            className="pl-10"
          />
        </div>

        {/* Filter by period */}
        <Select
          value={filter}
          onChange={(e) => setFilter(e.target.value as FilterPeriod)}
          className="w-48"
        >
          <option value="all">{t("history.filter_all")}</option>
          <option value="today">{t("history.filter_today")}</option>
          <option value="week">{t("history.filter_week")}</option>
          <option value="month">{t("history.filter_month")}</option>
        </Select>
      </div>

      {/* Results count */}
      {!loading && (
        <div className="text-sm text-gray-500 mb-4">
          {filteredConversations.length}{" "}
          {filteredConversations.length === 1
            ? "conversation"
            : "conversations"}
        </div>
      )}

      {/* Loading */}
      {loading && (
        <div className="flex items-center justify-center py-12">
          <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-yellow-400" />
        </div>
      )}

      {/* Empty state */}
      {!loading && filteredConversations.length === 0 && (
        <div className="text-center py-12">
          <Calendar className="w-16 h-16 text-gray-300 mx-auto mb-4" />
          <h3 className="text-lg font-semibold text-gray-700 dark:text-gray-300 mb-2">
            {searchQuery ? t("history.no_results") : "No conversations yet"}
          </h3>
          <p className="text-gray-500">
            {searchQuery
              ? "Try a different search term"
              : "Start chatting to see your history here"}
          </p>
        </div>
      )}

      {/* Conversation List */}
      {!loading && filteredConversations.length > 0 && (
        <div className="space-y-4">
          {filteredConversations.map((conv) => (
            <ConversationCard
              key={conv.id}
              conversation={conv}
              onDelete={() => handleDelete(conv.id)}
              onExport={() => handleExport(conv.id)}
            />
          ))}
        </div>
      )}
    </div>
  );
}
```

### 8.2 Conversation Card Component

```tsx
// renderer/components/history/ConversationCard.tsx

import {
  MessageCircle,
  Calendar,
  Trash2,
  Download,
  ChevronRight,
} from "lucide-react";
import { formatDistanceToNow, format } from "date-fns";
import { useNavigate } from "react-router-dom";

interface ConversationCardProps {
  conversation: {
    id: string;
    title: string | null;
    createdAt: Date;
    messageCount: number;
    model: string;
    messages: Array<{ content: string }>;
  };
  onDelete: () => void;
  onExport: () => void;
}

export function ConversationCard({
  conversation,
  onDelete,
  onExport,
}: ConversationCardProps) {
  const navigate = useNavigate();

  const getPreview = () => {
    const firstUserMessage = conversation.messages.find(
      (m) => m.role === "user"
    );
    return firstUserMessage?.content.slice(0, 150) || "No messages";
  };

  return (
    <div
      className="group p-4 bg-white dark:bg-gray-800 border border-gray-200 dark:border-gray-700 rounded-lg hover:shadow-md transition-all cursor-pointer"
      onClick={() => navigate(`/chat/${conversation.id}`)}
    >
      <div className="flex items-start justify-between mb-2">
        {/* Title & Icon */}
        <div className="flex items-center gap-3 flex-1 min-w-0">
          <MessageCircle className="w-5 h-5 text-yellow-500 flex-shrink-0" />
          <h3 className="font-semibold text-gray-900 dark:text-white truncate">
            {conversation.title || "Untitled conversation"}
          </h3>
        </div>

        {/* Actions (shown on hover) */}
        <div className="flex gap-2 opacity-0 group-hover:opacity-100 transition-opacity">
          <button
            onClick={(e) => {
              e.stopPropagation();
              onExport();
            }}
            className="p-1.5 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md transition"
            aria-label="Export"
          >
            <Download className="w-4 h-4 text-gray-500" />
          </button>

          <button
            onClick={(e) => {
              e.stopPropagation();
              onDelete();
            }}
            className="p-1.5 hover:bg-red-50 dark:hover:bg-red-900/20 rounded-md transition"
            aria-label="Delete"
          >
            <Trash2 className="w-4 h-4 text-red-500" />
          </button>

          <ChevronRight className="w-5 h-5 text-gray-400" />
        </div>
      </div>

      {/* Preview */}
      <p className="text-gray-600 dark:text-gray-400 text-sm mb-3 line-clamp-2">
        {getPreview()}
      </p>

      {/* Metadata */}
      <div className="flex items-center gap-4 text-xs text-gray-500">
        <span className="flex items-center gap-1">
          <MessageCircle className="w-3 h-3" />
          {conversation.messageCount} messages
        </span>
        <span>â€¢</span>
        <span className="flex items-center gap-1">
          <Calendar className="w-3 h-3" />
          {formatDistanceToNow(new Date(conversation.createdAt), {
            addSuffix: true,
          })}
        </span>
        <span>â€¢</span>
        <span className="text-gray-400">{conversation.model}</span>
      </div>
    </div>
  );
}
```

### 8.3 Search Algorithm

```typescript
// utils/search.ts

export function searchConversations(
  conversations: Conversation[],
  query: string
): Conversation[] {
  if (!query) return conversations;

  const lowercaseQuery = query.toLowerCase();

  return conversations.filter((conv) => {
    // Search in title
    if (conv.title?.toLowerCase().includes(lowercaseQuery)) {
      return true;
    }

    // Search in messages
    if (
      conv.messages.some((m) =>
        m.content.toLowerCase().includes(lowercaseQuery)
      )
    ) {
      return true;
    }

    // Search by date
    const dateStr = format(new Date(conv.createdAt), "PPP").toLowerCase();
    if (dateStr.includes(lowercaseQuery)) {
      return true;
    }

    return false;
  });
}

// Advanced: Fuzzy search with ranking
export function fuzzySearchConversations(
  conversations: Conversation[],
  query: string
): Array<{ conversation: Conversation; score: number }> {
  const results = conversations.map((conv) => ({
    conversation: conv,
    score: calculateRelevanceScore(conv, query),
  }));

  return results.filter((r) => r.score > 0).sort((a, b) => b.score - a.score);
}

function calculateRelevanceScore(conv: Conversation, query: string): number {
  let score = 0;
  const lowercaseQuery = query.toLowerCase();

  // Title match (highest weight)
  if (conv.title?.toLowerCase().includes(lowercaseQuery)) {
    score += 10;
  }

  // Message match
  const messageMatches = conv.messages.filter((m) =>
    m.content.toLowerCase().includes(lowercaseQuery)
  ).length;
  score += messageMatches * 2;

  // Recency bonus
  const daysSinceCreated =
    (Date.now() - new Date(conv.createdAt).getTime()) / (1000 * 60 * 60 * 24);
  if (daysSinceCreated < 7) score += 3;
  else if (daysSinceCreated < 30) score += 1;

  return score;
}
```

---

## 9. Keyboard Shortcuts & Accessibility

### 9.1 Complete Keyboard Shortcuts

```typescript
// hooks/useKeyboardShortcuts.ts

import { useEffect } from "react";
import { useNavigate } from "react-router-dom";

export function useKeyboardShortcuts() {
  const navigate = useNavigate();

  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      const isMac = navigator.platform.toUpperCase().indexOf("MAC") >= 0;
      const modifier = isMac ? e.metaKey : e.ctrlKey;

      // Cmd/Ctrl + K: Focus search
      if (modifier && e.key === "k") {
        e.preventDefault();
        document.getElementById("search-input")?.focus();
      }

      // Cmd/Ctrl + N: New conversation
      if (modifier && e.key === "n") {
        e.preventDefault();
        navigate("/chat/new");
      }

      // Cmd/Ctrl + ,: Open settings
      if (modifier && e.key === ",") {
        e.preventDefault();
        navigate("/settings");
      }

      // Cmd/Ctrl + H: Show history
      if (modifier && e.key === "h") {
        e.preventDefault();
        navigate("/history");
      }

      // Cmd/Ctrl + Shift + V: Toggle voice input
      if (modifier && e.shiftKey && e.key === "V") {
        e.preventDefault();
        // Trigger voice input
        document.dispatchEvent(new CustomEvent("toggle-voice"));
      }

      // Cmd/Ctrl + /: Show keyboard shortcuts
      if (modifier && e.key === "/") {
        e.preventDefault();
        // Show shortcuts modal
        document.dispatchEvent(new CustomEvent("show-shortcuts"));
      }

      // Escape: Close modal/dismiss notification
      if (e.key === "Escape") {
        document.dispatchEvent(new CustomEvent("close-modal"));
      }

      // Cmd/Ctrl + D: Toggle dark mode
      if (modifier && e.key === "d") {
        e.preventDefault();
        document.dispatchEvent(new CustomEvent("toggle-theme"));
      }

      // Cmd/Ctrl + 1-5: Switch tabs (in settings)
      if (modifier && e.key >= "1" && e.key <= "5") {
        e.preventDefault();
        const tabIndex = parseInt(e.key) - 1;
        document.dispatchEvent(
          new CustomEvent("switch-tab", { detail: { tabIndex } })
        );
      }
    };

    window.addEventListener("keydown", handleKeyDown);
    return () => window.removeEventListener("keydown", handleKeyDown);
  }, [navigate]);
}
```

### 9.2 Keyboard Shortcuts Reference

| Shortcut               | Action                   | Context            |
| ---------------------- | ------------------------ | ------------------ |
| `Cmd+K` / `Ctrl+K`     | Focus search             | Global             |
| `Cmd+N` / `Ctrl+N`     | New conversation         | Global             |
| `Cmd+,` / `Ctrl+,`     | Open settings            | Global             |
| `Cmd+H` / `Ctrl+H`     | Show history             | Global             |
| `Cmd+Shift+V`          | Toggle voice input       | Chat               |
| `Cmd+D` / `Ctrl+D`     | Toggle dark mode         | Global             |
| `Cmd+/` / `Ctrl+/`     | Show shortcuts           | Global             |
| `Cmd+1-5` / `Ctrl+1-5` | Switch setting tabs      | Settings           |
| `Enter`                | Send message             | Chat input         |
| `Shift+Enter`          | New line                 | Chat input         |
| `Escape`               | Close modal/notification | Global             |
| `â†‘` / `â†“`              | Navigate history         | Chat input (empty) |
| `Cmd+F` / `Ctrl+F`     | Search in conversation   | Chat               |

### 9.3 Accessibility Implementation

```tsx
// Accessibility best practices

// 1. Semantic HTML
<main role="main" aria-label="Chat interface">
  <header role="banner">
    <h1>Eden Project</h1>
  </header>

  <nav role="navigation" aria-label="Main navigation">
    {/* Navigation items */}
  </nav>

  <article role="article" aria-label="Conversation">
    {/* Chat messages */}
  </article>
</main>

// 2. ARIA Labels
<button
  onClick={handleClick}
  aria-label="Send message"
  aria-describedby="send-button-description"
>
  <Send />
</button>

<span id="send-button-description" className="sr-only">
  Press Enter or click to send your message to the AI
</span>

// 3. Keyboard navigation
<div
  role="button"
  tabIndex={0}
  onKeyPress={(e) => e.key === 'Enter' && handleClick()}
  onClick={handleClick}
  aria-label="Action button"
>
  Click me
</div>

// 4. Focus management
const inputRef = useRef<HTMLInputElement>(null);

useEffect(() => {
  inputRef.current?.focus();
}, []);

// 5. Screen reader announcements
<div role="status" aria-live="polite" className="sr-only">
  {statusMessage}
</div>

<div role="alert" aria-live="assertive" className="sr-only">
  {errorMessage}
</div>

// 6. Skip links
<a href="#main-content" className="sr-only focus:not-sr-only">
  Skip to main content
</a>

// 7. Color contrast
// Ensure all text meets WCAG AA standards (4.5:1 ratio)
// Use tools like https://webaim.org/resources/contrastchecker/

// 8. Focus indicators
button:focus-visible {
  outline: 2px solid #FAE100;
  outline-offset: 2px;
}

// 9. Screen reader only class
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border-width: 0;
}

.sr-only:focus {
  position: static;
  width: auto;
  height: auto;
  padding: 0;
  margin: 0;
  overflow: visible;
  clip: auto;
  white-space: normal;
}
```

### 9.4 Keyboard Shortcuts Modal

```tsx
// renderer/components/ShortcutsModal.tsx

import { Dialog } from "@/components/ui/dialog";
import { useEffect, useState } from "react";

export function ShortcutsModal() {
  const [isOpen, setIsOpen] = useState(false);
  const isMac = navigator.platform.toUpperCase().indexOf("MAC") >= 0;
  const modifierKey = isMac ? "âŒ˜" : "Ctrl";

  useEffect(() => {
    const handleShow = () => setIsOpen(true);
    document.addEventListener("show-shortcuts", handleShow);
    return () => document.removeEventListener("show-shortcuts", handleShow);
  }, []);

  const shortcuts = [
    { keys: [`${modifierKey}`, "K"], action: "Focus search" },
    { keys: [`${modifierKey}`, "N"], action: "New conversation" },
    { keys: [`${modifierKey}`, ","], action: "Open settings" },
    { keys: [`${modifierKey}`, "H"], action: "Show history" },
    { keys: [`${modifierKey}`, "Shift", "V"], action: "Toggle voice input" },
    { keys: [`${modifierKey}`, "D"], action: "Toggle dark mode" },
    { keys: [`${modifierKey}`, "/"], action: "Show this help" },
    { keys: ["Enter"], action: "Send message" },
    { keys: ["Shift", "Enter"], action: "New line" },
    { keys: ["Esc"], action: "Close modal" },
  ];

  return (
    <Dialog open={isOpen} onOpenChange={setIsOpen}>
      <div className="max-w-2xl mx-auto p-6">
        <h2 className="text-2xl font-bold mb-6">Keyboard Shortcuts</h2>

        <div className="space-y-2">
          {shortcuts.map((shortcut, index) => (
            <div
              key={index}
              className="flex items-center justify-between py-2 border-b border-gray-200 dark:border-gray-700"
            >
              <span className="text-gray-700 dark:text-gray-300">
                {shortcut.action}
              </span>
              <div className="flex gap-1">
                {shortcut.keys.map((key, i) => (
                  <kbd
                    key={i}
                    className="px-2 py-1 text-sm bg-gray-100 dark:bg-gray-800 border border-gray-300 dark:border-gray-600 rounded"
                  >
                    {key}
                  </kbd>
                ))}
              </div>
            </div>
          ))}
        </div>
      </div>
    </Dialog>
  );
}
```

---

## 10. System Tray & Window Management

### 10.1 System Tray Implementation

```typescript
// main/tray.ts

import { Tray, Menu, nativeImage, BrowserWindow, app } from "electron";
import path from "path";

export class TrayManager {
  private tray: Tray | null = null;
  private mainWindow: BrowserWindow;

  constructor(mainWindow: BrowserWindow) {
    this.mainWindow = mainWindow;
  }

  create() {
    const iconPath = path.join(__dirname, "../resources/icons/tray-icon.png");
    const icon = nativeImage.createFromPath(iconPath);

    // Create tray with icon
    this.tray = new Tray(icon.resize({ width: 16, height: 16 }));

    // Build context menu
    const contextMenu = Menu.buildFromTemplate([
      {
        label: "Show Eden Project",
        click: () => this.mainWindow.show(),
      },
      {
        label: "New Conversation",
        accelerator: "CmdOrCtrl+N",
        click: () => {
          this.mainWindow.show();
          this.mainWindow.webContents.send("new-conversation");
        },
      },
      { type: "separator" },
      {
        label: "Mode",
        submenu: [
          {
            label: "User-Led",
            type: "radio",
            click: () => this.setMode("user-led"),
          },
          {
            label: "AI-Led",
            type: "radio",
            click: () => this.setMode("ai-led"),
          },
        ],
      },
      { type: "separator" },
      {
        label: "Settings",
        accelerator: "CmdOrCtrl+,",
        click: () => {
          this.mainWindow.show();
          this.mainWindow.webContents.send("navigate-to", "/settings");
        },
      },
      {
        label: "History",
        accelerator: "CmdOrCtrl+H",
        click: () => {
          this.mainWindow.show();
          this.mainWindow.webContents.send("navigate-to", "/history");
        },
      },
      { type: "separator" },
      {
        label: "Check for Updates",
        click: () => this.checkForUpdates(),
      },
      {
        label: "About",
        click: () => this.showAbout(),
      },
      { type: "separator" },
      {
        label: "Quit",
        accelerator: "CmdOrCtrl+Q",
        click: () => app.quit(),
      },
    ]);

    this.tray.setContextMenu(contextMenu);
    this.tray.setToolTip("Eden Project - Your AI Companion");

    // Click to show/hide window (Windows/Linux)
    this.tray.on("click", () => {
      if (this.mainWindow.isVisible()) {
        this.mainWindow.hide();
      } else {
        this.mainWindow.show();
      }
    });

    // Double-click to show window (macOS)
    this.tray.on("double-click", () => {
      this.mainWindow.show();
    });
  }

  updateIcon(status: "idle" | "processing" | "recording") {
    if (!this.tray) return;

    const iconMap = {
      idle: "tray-icon.png",
      processing: "tray-icon-processing.png",
      recording: "tray-icon-recording.png",
    };

    const iconPath = path.join(
      __dirname,
      `../resources/icons/${iconMap[status]}`
    );
    const icon = nativeImage.createFromPath(iconPath);

    this.tray.setImage(icon.resize({ width: 16, height: 16 }));
  }

  updateTooltip(message: string) {
    if (!this.tray) return;
    this.tray.setToolTip(message);
  }

  private setMode(mode: "user-led" | "ai-led") {
    this.mainWindow.webContents.send("set-mode", mode);
  }

  private checkForUpdates() {
    // Trigger auto-updater
    this.mainWindow.webContents.send("check-updates");
  }

  private showAbout() {
    this.mainWindow.show();
    this.mainWindow.webContents.send("show-about");
  }

  destroy() {
    if (this.tray) {
      this.tray.destroy();
      this.tray = null;
    }
  }
}
```

### 10.2 Window Management

```typescript
// main/window-manager.ts

import { BrowserWindow, screen, app } from "electron";
import path from "path";
import Store from "electron-store";

interface WindowBounds {
  x: number;
  y: number;
  width: number;
  height: number;
}

export class WindowManager {
  private mainWindow: BrowserWindow | null = null;
  private store: Store;

  constructor() {
    this.store = new Store();
  }

  create(): BrowserWindow {
    // Get saved window bounds or use defaults
    const savedBounds = this.store.get("windowBounds") as
      | WindowBounds
      | undefined;
    const { width, height } = screen.getPrimaryDisplay().workAreaSize;

    const defaultBounds = {
      width: 1200,
      height: 800,
      x: (width - 1200) / 2,
      y: (height - 800) / 2,
    };

    const bounds = savedBounds || defaultBounds;

    this.mainWindow = new BrowserWindow({
      ...bounds,
      minWidth: 800,
      minHeight: 600,
      show: false, // Don't show until ready-to-show
      backgroundColor: "#FAFAF9",
      titleBarStyle: process.platform === "darwin" ? "hiddenInset" : "default",
      frame: true,
      webPreferences: {
        contextIsolation: true,
        nodeIntegration: false,
        preload: path.join(__dirname, "preload.js"),
        devTools: !app.isPackaged,
      },
    });

    // Load URL
    if (app.isPackaged) {
      this.mainWindow.loadFile(path.join(__dirname, "../renderer/index.html"));
    } else {
      this.mainWindow.loadURL("http://localhost:5173"); // Vite dev server
    }

    // Show when ready (prevents flash of white)
    this.mainWindow.once("ready-to-show", () => {
      this.mainWindow?.show();
      this.mainWindow?.focus();
    });

    // Save window bounds on resize/move
    this.mainWindow.on("resize", () => this.saveBounds());
    this.mainWindow.on("move", () => this.saveBounds());

    // Handle close
    this.mainWindow.on("close", (e) => {
      if (process.platform === "darwin") {
        // On macOS, hide instead of close
        e.preventDefault();
        this.mainWindow?.hide();
      } else {
        // On Windows/Linux, minimize to tray
        const minimizeToTray = this.store.get("minimizeToTray", true);
        if (minimizeToTray) {
          e.preventDefault();
          this.mainWindow?.hide();
        }
      }
    });

    // Cleanup on closed
    this.mainWindow.on("closed", () => {
      this.mainWindow = null;
    });

    return this.mainWindow;
  }

  private saveBounds() {
    if (!this.mainWindow) return;

    const bounds = this.mainWindow.getBounds();
    this.store.set("windowBounds", bounds);
  }

  restore() {
    if (this.mainWindow) {
      if (this.mainWindow.isMinimized()) {
        this.mainWindow.restore();
      }
      this.mainWindow.show();
      this.mainWindow.focus();
    }
  }

  toggleFullScreen() {
    if (this.mainWindow) {
      this.mainWindow.setFullScreen(!this.mainWindow.isFullScreen());
    }
  }

  minimize() {
    if (this.mainWindow) {
      this.mainWindow.minimize();
    }
  }

  maximize() {
    if (this.mainWindow) {
      if (this.mainWindow.isMaximized()) {
        this.mainWindow.unmaximize();
      } else {
        this.mainWindow.maximize();
      }
    }
  }

  close() {
    if (this.mainWindow) {
      this.mainWindow.close();
    }
  }

  getWindow(): BrowserWindow | null {
    return this.mainWindow;
  }
}
```

### 10.3 macOS Dock Integration

```typescript
// main/dock.ts (macOS only)

import { app, Menu } from "electron";

export class DockManager {
  setup() {
    if (process.platform !== "darwin") return;

    // Set dock menu
    const dockMenu = Menu.buildFromTemplate([
      {
        label: "New Conversation",
        click: () => {
          // Send event to main window
          const windows = BrowserWindow.getAllWindows();
          windows[0]?.webContents.send("new-conversation");
        },
      },
      {
        label: "Show History",
        click: () => {
          const windows = BrowserWindow.getAllWindows();
          windows[0]?.webContents.send("navigate-to", "/history");
        },
      },
    ]);

    app.dock.setMenu(dockMenu);
  }

  setBadge(count: number) {
    if (process.platform !== "darwin") return;

    if (count > 0) {
      app.dock.setBadge(count.toString());
    } else {
      app.dock.setBadge("");
    }
  }

  bounce(type: "critical" | "informational" = "informational") {
    if (process.platform !== "darwin") return;

    app.dock.bounce(type);
  }
}
```

### 10.4 Window Controls (Traffic Lights)

```tsx
// renderer/components/WindowControls.tsx (for frameless window)

import { Minimize, Maximize, X } from "lucide-react";

export function WindowControls() {
  const handleMinimize = () => {
    window.electronAPI.windowMinimize();
  };

  const handleMaximize = () => {
    window.electronAPI.windowMaximize();
  };

  const handleClose = () => {
    window.electronAPI.windowClose();
  };

  return (
    <div className="flex items-center gap-2">
      <button
        onClick={handleMinimize}
        className="p-2 hover:bg-gray-200 dark:hover:bg-gray-700 rounded-md transition"
        aria-label="Minimize"
      >
        <Minimize className="w-4 h-4" />
      </button>

      <button
        onClick={handleMaximize}
        className="p-2 hover:bg-gray-200 dark:hover:bg-gray-700 rounded-md transition"
        aria-label="Maximize"
      >
        <Maximize className="w-4 h-4" />
      </button>

      <button
        onClick={handleClose}
        className="p-2 hover:bg-red-500 hover:text-white rounded-md transition"
        aria-label="Close"
      >
        <X className="w-4 h-4" />
      </button>
    </div>
  );
}
```

---

**End of Part 4 (EXPANDED)**

_Total Lines: ~2100_
_Status: Complete - Production Ready_

---

## Summary

Part 4 now includes **complete, production-ready implementations** for:

1. âœ… KakaoTalk-Style Chat Interface (with code highlighting, grouping, animations)
2. âœ… Design System & Theme (complete color palette, typography, dark mode)
3. âœ… Internationalization (Korean + English, complete translations)
4. âœ… Voice Input/Output UI (recording, waveform, TTS playback)
5. âœ… Dual Mode System (User-Led vs AI-Led with full logic)
6. âœ… Proactive Notifications (10 scenarios, complete component)
7. âœ… Settings & Persona Configuration (8 parameters with sliders)
8. âœ… Conversation History (search, filter, export, delete)
9. âœ… Keyboard Shortcuts & Accessibility (complete shortcuts, ARIA)
10. âœ… System Tray & Window Management (macOS + Windows support)

**Next step**: Replace old Part 4 in main spec file, then create API documentation.

# Part 5: Implementation & Data Models

## Table of Contents - Part 5

1. [SQLite Database Schema](#1-sqlite-database-schema)
2. [Data Models (TypeScript)](#2-data-models-typescript)
3. [Implementation Phases](#3-implementation-phases)
4. [Deployment & Distribution](#4-deployment--distribution)
5. [Testing Strategy](#5-testing-strategy)
6. [Performance Benchmarks](#6-performance-benchmarks)
7. [Security Checklist](#7-security-checklist)
8. [Known Limitations & Trade-offs](#8-known-limitations--trade-offs)
9. [Success Metrics](#9-success-metrics)
10. [Final Launch Checklist](#10-final-launch-checklist)

---

## 1. SQLite Database Schema

### 1.1 Database Architecture

**Why SQLite?**

- âœ… 100% local (no server)
- âœ… Zero-configuration
- âœ… Fast (ACID compliant)
- âœ… Embedded in app
- âœ… Small footprint

**Location**: `~/Library/Application Support/garden-of-eden/eden.db` (macOS)

### 1.2 Schema Design

```sql
-- schema.sql

-- Conversations
CREATE TABLE conversations (
  id TEXT PRIMARY KEY,
  title TEXT,
  model TEXT NOT NULL DEFAULT 'llama-3.1-8b',
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  message_count INTEGER NOT NULL DEFAULT 0,
  metadata JSON
);

CREATE INDEX idx_conversations_created ON conversations(created_at DESC);

-- Messages
CREATE TABLE messages (
  id TEXT PRIMARY KEY,
  conversation_id TEXT NOT NULL,
  role TEXT NOT NULL CHECK(role IN ('user', 'assistant', 'system')),
  content TEXT NOT NULL,
  tokens INTEGER,
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  metadata JSON,
  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

CREATE INDEX idx_messages_conversation ON messages(conversation_id, created_at);

-- Persona Parameters
CREATE TABLE persona_parameters (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  warmth REAL NOT NULL DEFAULT 0.7 CHECK(warmth BETWEEN 0 AND 1),
  formality REAL NOT NULL DEFAULT 0.5 CHECK(formality BETWEEN 0 AND 1),
  humor REAL NOT NULL DEFAULT 0.6 CHECK(humor BETWEEN 0 AND 1),
  verbosity REAL NOT NULL DEFAULT 0.5 CHECK(verbosity BETWEEN 0 AND 1),
  proactivity REAL NOT NULL DEFAULT 0.5 CHECK(proactivity BETWEEN 0 AND 1),
  creativity REAL NOT NULL DEFAULT 0.7 CHECK(creativity BETWEEN 0 AND 1),
  empathy REAL NOT NULL DEFAULT 0.8 CHECK(empathy BETWEEN 0 AND 1),
  directness REAL NOT NULL DEFAULT 0.6 CHECK(directness BETWEEN 0 AND 1),
  updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Insert default persona
INSERT INTO persona_parameters (warmth, formality, humor, verbosity, proactivity, creativity, empathy, directness)
VALUES (0.7, 0.5, 0.6, 0.5, 0.5, 0.7, 0.8, 0.6);

-- Episodic Memory (RAG)
CREATE TABLE episodic_memory (
  id TEXT PRIMARY KEY,
  conversation_id TEXT NOT NULL,
  user_message TEXT NOT NULL,
  assistant_response TEXT NOT NULL,
  embedding BLOB, -- Vector embedding (serialized)
  satisfaction_score REAL CHECK(satisfaction_score BETWEEN 0 AND 1),
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

CREATE INDEX idx_memory_satisfaction ON episodic_memory(satisfaction_score DESC);

-- User Settings
CREATE TABLE user_settings (
  key TEXT PRIMARY KEY,
  value TEXT NOT NULL,
  type TEXT NOT NULL CHECK(type IN ('string', 'number', 'boolean', 'json')),
  updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- Insert default settings
INSERT INTO user_settings (key, value, type) VALUES
  ('language', 'en', 'string'),
  ('theme', 'system', 'string'),
  ('voice_enabled', 'true', 'boolean'),
  ('screen_capture_enabled', 'false', 'boolean'),
  ('mode', 'user-led', 'string'),
  ('proactive_notifications', 'false', 'boolean');

-- Workspace Context
CREATE TABLE workspaces (
  id TEXT PRIMARY KEY,
  root_path TEXT NOT NULL UNIQUE,
  name TEXT NOT NULL,
  type TEXT NOT NULL CHECK(type IN ('nodejs', 'python', 'rust', 'go', 'java', 'generic')),
  git_repo TEXT,
  last_opened DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  metadata JSON
);

CREATE INDEX idx_workspaces_last_opened ON workspaces(last_opened DESC);

-- Proactive Notifications History
CREATE TABLE notifications (
  id TEXT PRIMARY KEY,
  type TEXT NOT NULL,
  title TEXT NOT NULL,
  message TEXT NOT NULL,
  action_taken TEXT, -- 'accepted', 'dismissed', 'ignored'
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  resolved_at DATETIME,
  metadata JSON
);

CREATE INDEX idx_notifications_created ON notifications(created_at DESC);
```

### 1.3 Migrations System

```typescript
// main/database/migrations.ts

import Database from "better-sqlite3";
import fs from "fs";
import path from "path";

export class MigrationManager {
  constructor(private db: Database.Database) {}

  async runMigrations() {
    // Create migrations table if not exists
    this.db.exec(`
      CREATE TABLE IF NOT EXISTS migrations (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        name TEXT NOT NULL UNIQUE,
        executed_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
      );
    `);

    const migrationFiles = fs
      .readdirSync(path.join(__dirname, "migrations"))
      .filter((f) => f.endsWith(".sql"))
      .sort();

    for (const file of migrationFiles) {
      const executed = this.db
        .prepare("SELECT 1 FROM migrations WHERE name = ?")
        .get(file);

      if (!executed) {
        const sql = fs.readFileSync(
          path.join(__dirname, "migrations", file),
          "utf-8"
        );
        this.db.exec(sql);
        this.db.prepare("INSERT INTO migrations (name) VALUES (?)").run(file);
        console.log(`âœ… Executed migration: ${file}`);
      }
    }
  }
}
```

---

## 2. Data Models (TypeScript)

### 2.1 Core Models

```typescript
// shared/types/models.ts

export interface Conversation {
  id: string;
  title: string | null;
  model: string;
  createdAt: Date;
  updatedAt: Date;
  messageCount: number;
  metadata?: Record<string, any>;
}

export interface Message {
  id: string;
  conversationId: string;
  role: "user" | "assistant" | "system";
  content: string;
  tokens?: number;
  createdAt: Date;
  metadata?: Record<string, any>;
}

export interface PersonaParameters {
  warmth: number; // 0-1: Cold â†’ Warm
  formality: number; // 0-1: Casual â†’ Formal
  humor: number; // 0-1: Serious â†’ Playful
  verbosity: number; // 0-1: Concise â†’ Detailed
  proactivity: number; // 0-1: Reactive â†’ Proactive
  creativity: number; // 0-1: Conservative â†’ Creative
  empathy: number; // 0-1: Logical â†’ Empathetic
  directness: number; // 0-1: Indirect â†’ Direct
}

export interface EpisodicMemory {
  id: string;
  conversationId: string;
  userMessage: string;
  assistantResponse: string;
  embedding?: Float32Array;
  satisfactionScore?: number;
  createdAt: Date;
}

export interface Workspace {
  id: string;
  rootPath: string;
  name: string;
  type: "nodejs" | "python" | "rust" | "go" | "java" | "generic";
  gitRepo?: string;
  lastOpened: Date;
  metadata?: Record<string, any>;
}

export interface ProactiveNotification {
  id: string;
  type: string;
  title: string;
  message: string;
  actionTaken?: "accepted" | "dismissed" | "ignored";
  createdAt: Date;
  resolvedAt?: Date;
  metadata?: Record<string, any>;
}
```

### 2.2 Repository Pattern

```typescript
// main/database/repositories/conversation.repository.ts

import Database from "better-sqlite3";
import { Conversation, Message } from "@/shared/types/models";

export class ConversationRepository {
  constructor(private db: Database.Database) {}

  create(
    conversation: Omit<Conversation, "id" | "createdAt" | "updatedAt">
  ): Conversation {
    const id = crypto.randomUUID();
    const now = new Date().toISOString();

    this.db
      .prepare(
        `
      INSERT INTO conversations (id, title, model, created_at, updated_at, message_count, metadata)
      VALUES (?, ?, ?, ?, ?, ?, ?)
    `
      )
      .run(
        id,
        conversation.title || null,
        conversation.model,
        now,
        now,
        0,
        JSON.stringify(conversation.metadata || {})
      );

    return this.findById(id)!;
  }

  findById(id: string): Conversation | null {
    const row = this.db
      .prepare("SELECT * FROM conversations WHERE id = ?")
      .get(id);
    return row ? this.mapRow(row) : null;
  }

  findAll(limit = 50, offset = 0): Conversation[] {
    const rows = this.db
      .prepare(
        `
      SELECT * FROM conversations
      ORDER BY updated_at DESC
      LIMIT ? OFFSET ?
    `
      )
      .all(limit, offset);

    return rows.map((row) => this.mapRow(row));
  }

  addMessage(
    conversationId: string,
    message: Omit<Message, "id" | "createdAt">
  ): Message {
    const id = crypto.randomUUID();
    const now = new Date().toISOString();

    this.db
      .prepare(
        `
      INSERT INTO messages (id, conversation_id, role, content, tokens, created_at, metadata)
      VALUES (?, ?, ?, ?, ?, ?, ?)
    `
      )
      .run(
        id,
        conversationId,
        message.role,
        message.content,
        message.tokens || null,
        now,
        JSON.stringify(message.metadata || {})
      );

    // Update conversation message count and updated_at
    this.db
      .prepare(
        `
      UPDATE conversations
      SET message_count = message_count + 1, updated_at = ?
      WHERE id = ?
    `
      )
      .run(now, conversationId);

    return {
      id,
      conversationId,
      role: message.role,
      content: message.content,
      tokens: message.tokens,
      createdAt: new Date(now),
      metadata: message.metadata,
    };
  }

  private mapRow(row: any): Conversation {
    return {
      id: row.id,
      title: row.title,
      model: row.model,
      createdAt: new Date(row.created_at),
      updatedAt: new Date(row.updated_at),
      messageCount: row.message_count,
      metadata: row.metadata ? JSON.parse(row.metadata) : undefined,
    };
  }
}
```

---

## 3. Implementation Phases

### Phase 1: Foundation (Week 1-2)

**Goal**: Basic Electron app with database

**Tasks**:

- âœ… Setup Electron + React + TypeScript project
- âœ… Configure Vite for renderer
- âœ… Setup SQLite database
- âœ… Create database schema and migrations
- âœ… Implement repository pattern
- âœ… Basic IPC communication
- âœ… Window management
- âœ… System tray

**Deliverable**: Empty Electron app that opens, stores data locally

---

### Phase 2: AI Integration (Week 3-4)

**Goal**: Local AI models working

**Tasks**:

- âœ… Download and setup llama.cpp
- âœ… Integrate Llama 3.1 8B model
- âœ… Integrate Whisper Large V3 for STT
- âœ… Setup system TTS
- âœ… Create AI service layer
- âœ… Implement streaming responses
- âœ… Test end-to-end conversation flow

**Deliverable**: Chat with local AI works

---

### Phase 3: UI/UX (Week 5-6)

**Goal**: Beautiful, functional UI

**Tasks**:

- âœ… Implement KakaoTalk-style chat interface
- âœ… Chat bubbles, typing indicator
- âœ… Input box with voice button
- âœ… Design system (colors, typography)
- âœ… Dark mode support
- âœ… i18n setup (Korean + English)
- âœ… Settings screen
- âœ… Conversation history

**Deliverable**: Polished UI that feels native

---

### Phase 4: System Integration (Week 7-8)

**Goal**: AI can access system

**Tasks**:

- âœ… File system integration
- âœ… Git integration
- âœ… Workspace detection
- âœ… Screen capture service
- âœ… Calendar integration (ICS)
- âœ… Webhook system
- âœ… Plugin architecture

**Deliverable**: AI can read files, commit code, see screen

---

### Phase 5: Learning System (Week 9-10)

**Goal**: Persona adapts over time

**Tasks**:

- âœ… Persona parameter system
- âœ… RAG episodic memory
- âœ… Satisfaction feedback loop
- âœ… Parameter optimization algorithm
- âœ… Memory retrieval
- âœ… Persona UI (sliders)

**Deliverable**: AI personality improves with usage

---

### Phase 6: Polish & Testing (Week 11-12)

**Goal**: Production-ready

**Tasks**:

- âœ… Comprehensive error handling
- âœ… Loading states
- âœ… Keyboard shortcuts
- âœ… Accessibility (screen reader)
- âœ… Performance optimization
- âœ… Unit tests (80% coverage)
- âœ… Integration tests
- âœ… User testing (5-10 beta testers)

**Deliverable**: Stable, tested app

---

### Phase 7: Distribution (Week 13)

**Goal**: Packaged for distribution

**Tasks**:

- âœ… electron-builder configuration
- âœ… Code signing (macOS + Windows)
- âœ… Auto-updater setup
- âœ… Crash reporting (Sentry)
- âœ… Analytics (optional, privacy-focused)
- âœ… First-run onboarding
- âœ… Model downloader UI

**Deliverable**: Installable .dmg (macOS) and .exe (Windows)

---

### Phase 8: Launch (Week 14)

**Goal**: Public release

**Tasks**:

- âœ… Create landing page
- âœ… Write documentation
- âœ… Record demo video
- âœ… Prepare social media assets
- âœ… Submit to Product Hunt
- âœ… Post on HackerNews, Reddit
- âœ… Monitor feedback and iterate

**Deliverable**: Public launch! ğŸš€

---

## 4. Deployment & Distribution

### 4.1 electron-builder Configuration

```json
// electron-builder.json

{
  "appId": "com.garden-of-eden.app",
  "productName": "Eden Project",
  "copyright": "Copyright Â© 2025",
  "directories": {
    "output": "dist"
  },
  "files": [
    "out/**/*",
    "resources/**/*",
    "!resources/models/*" // Models downloaded separately
  ],
  "mac": {
    "target": ["dmg", "zip"],
    "category": "public.app-category.productivity",
    "icon": "resources/icons/icon.icns",
    "hardenedRuntime": true,
    "gatekeeperAssess": false,
    "entitlements": "build/entitlements.mac.plist",
    "entitlementsInherit": "build/entitlements.mac.plist"
  },
  "win": {
    "target": ["nsis", "portable"],
    "icon": "resources/icons/icon.ico"
  },
  "linux": {
    "target": ["AppImage", "deb"],
    "category": "Utility",
    "icon": "resources/icons/"
  },
  "publish": {
    "provider": "github",
    "owner": "garden-of-eden",
    "repo": "desktop-app"
  }
}
```

### 4.2 Auto-Updater

```typescript
// main/updater.ts

import { autoUpdater } from "electron-updater";

export class AutoUpdaterService {
  init() {
    autoUpdater.checkForUpdatesAndNotify();

    autoUpdater.on("update-available", () => {
      dialog.showMessageBox({
        type: "info",
        title: "Update Available",
        message: "A new version is available. Downloading...",
      });
    });

    autoUpdater.on("update-downloaded", () => {
      dialog
        .showMessageBox({
          type: "info",
          title: "Update Ready",
          message: "Update downloaded. Restart to install?",
          buttons: ["Restart", "Later"],
        })
        .then((result) => {
          if (result.response === 0) {
            autoUpdater.quitAndInstall();
          }
        });
    });
  }
}
```

### 4.3 Model Downloader

**Models are NOT bundled** (too large). User downloads on first run.

```typescript
// renderer/pages/FirstRun.tsx

export function ModelDownloader() {
  const [progress, setProgress] = useState(0);

  const downloadModels = async () => {
    await window.electronAPI.downloadModel("llama-3.1-8b", (p) =>
      setProgress(p)
    );
    await window.electronAPI.downloadModel("whisper-large-v3", (p) =>
      setProgress(p)
    );
  };

  return (
    <div>
      <h1>Welcome to Eden Project</h1>
      <p>Downloading AI models (12GB)...</p>
      <ProgressBar value={progress} />
    </div>
  );
}
```

---

## 5. Testing Strategy

### 5.1 Unit Tests

```typescript
// __tests__/database/conversation.repository.test.ts

import { ConversationRepository } from "@/main/database/repositories";
import Database from "better-sqlite3";

describe("ConversationRepository", () => {
  let db: Database.Database;
  let repo: ConversationRepository;

  beforeEach(() => {
    db = new Database(":memory:");
    // Run migrations
    repo = new ConversationRepository(db);
  });

  test("creates conversation", () => {
    const conv = repo.create({
      title: "Test",
      model: "llama-3.1-8b",
      messageCount: 0,
    });

    expect(conv.id).toBeDefined();
    expect(conv.title).toBe("Test");
  });
});
```

### 5.2 Integration Tests

Test full conversation flow from input to AI response.

### 5.3 E2E Tests

Use Playwright to test UI flows.

---

## 6. Performance Benchmarks

### 6.1 Target Metrics

| Metric            | Target  | Acceptable |
| ----------------- | ------- | ---------- |
| App Launch        | < 2s    | < 5s       |
| LLM First Token   | < 500ms | < 2s       |
| LLM Full Response | < 3s    | < 8s       |
| STT Transcription | < 1s    | < 3s       |
| TTS Generation    | < 500ms | < 2s       |
| Screen Capture    | < 200ms | < 500ms    |
| Database Query    | < 10ms  | < 50ms     |
| Memory Usage      | < 1.5GB | < 2.5GB    |

### 6.2 Optimization Strategies

**LLM**:

- Use Q4 quantization (5.5GB vs 16GB)
- GPU acceleration (Metal/CUDA)
- Context caching

**Database**:

- Indexes on all queries
- Connection pooling
- Batch inserts

**UI**:

- Virtual scrolling for history
- Lazy loading
- React.memo for expensive components

---

## 7. Security Checklist

- âœ… Context isolation enabled
- âœ… Node integration disabled in renderer
- âœ… IPC channel whitelist
- âœ… File access control (user permission)
- âœ… No eval() or dangerous patterns
- âœ… HTTPS for all external requests
- âœ… Encrypted local storage (optional)
- âœ… Secure auto-updater (signed releases)
- âœ… CSP headers
- âœ… Regular dependency audits

---

## 8. Known Limitations & Trade-offs

### 8.1 Model Size

**Limitation**: 12GB models require significant disk space

**Trade-off**: Accept large size for 100% privacy

**Mitigation**: Optional cloud fallback (future)

### 8.2 Hardware Requirements

**Minimum**:

- RAM: 16GB
- Storage: 20GB free
- CPU: 4 cores
- GPU: Optional (but recommended)

**Trade-off**: Excludes lower-end devices

### 8.3 Offline-Only (v1)

**Limitation**: No cloud sync, no mobile app

**Future**: Optional cloud backup

---

## 9. Success Metrics

### 9.1 User Engagement

- **DAU**: 100+ in Month 1
- **Avg Session Length**: > 10 minutes
- **Messages per Day**: > 20
- **7-Day Retention**: > 40%
- **30-Day Retention**: > 20%

### 9.2 Quality Metrics

- **AI Response Satisfaction**: > 4.0/5.0
- **Bug Reports**: < 5 per week
- **Crash Rate**: < 0.5%
- **NPS Score**: > 50

### 9.3 Technical Metrics

- **Avg Response Time**: < 5s (P95)
- **Error Rate**: < 2%
- **Memory Usage**: < 1.5GB (P95)
- **Uptime**: > 99.5%

---

## 10. Final Launch Checklist

### 10.1 Pre-Launch (Week Before)

- [ ] All Phase 1-7 tasks completed
- [ ] Beta testing done (5-10 users)
- [ ] Critical bugs fixed
- [ ] Performance benchmarks met
- [ ] Landing page live
- [ ] Documentation complete
- [ ] Demo video recorded
- [ ] Social media assets ready

### 10.2 Launch Day

- [ ] Final build created
- [ ] Code signed (macOS + Windows)
- [ ] DMG/EXE uploaded to GitHub Releases
- [ ] Landing page updated with download links
- [ ] Post on Product Hunt (morning PST)
- [ ] Post on HackerNews
- [ ] Post on Reddit (r/SideProject, r/MacApps)
- [ ] Tweet announcement
- [ ] Monitor feedback channels

### 10.3 Post-Launch (Week After)

- [ ] Respond to all feedback
- [ ] Hotfix critical bugs
- [ ] Collect feature requests
- [ ] Plan v1.1 roadmap
- [ ] Thank early adopters

---

## Conclusion

**Eden Project** is an ambitious but achievable project:

âœ… **100% Local AI** - No privacy concerns, no subscriptions
âœ… **Desktop-First** - Powerful system integrations
âœ… **KakaoTalk-Inspired** - Familiar, warm, conversational
âœ… **Customizable Persona** - Adapts to your style
âœ… **Open-Source** - Community-driven evolution

**Total Development Time**: 14 weeks (3.5 months)

**Tech Stack**:

- Electron + React + TypeScript
- Llama 3.1 8B (via llama.cpp)
- Whisper Large V3 (STT)
- SQLite (local database)
- shadcn/ui (components)

**Target Users**:

- Solo developers
- Remote workers
- Students
- Privacy-conscious power users

**Launch Goal**: 100 active users in first month

---

**Let's build something extraordinary.** ğŸš€

**End of Part 5**

_Total Lines Part 5: ~800_
_Total Lines V3 Spec: ~5500_

---

**End of Eden Project Master Specification**

_Version 3.0.0 Complete_
_Last Updated: 2025-01-11_

---

---

# Part 6: API Reference & Developer Documentation

## Table of Contents - Part 6

1. [IPC Channels API](#1-ipc-channels-api)
2. [Service APIs](#2-service-apis)
3. [Database Schema Reference](#3-database-schema-reference)
4. [TypeScript Types Reference](#4-typescript-types-reference)
5. [Plugin Development Guide](#5-plugin-development-guide)
6. [Webhook Integration Guide](#6-webhook-integration-guide)

---

## 1. IPC Channels API

### 1.1 AI Operations

#### `ai:chat`

Send a chat message to the AI.

**Request**:

```typescript
{
  message: string;
  context?: {
    screenCapture?: Buffer;
    workspaceInfo?: WorkspaceContext;
    recentFiles?: string[];
  };
}
```

**Response**:

```typescript
{
  text: string;
  conversationId: string;
  tokens?: number;
}
```

**Example**:

```typescript
const response = await window.electronAPI.aiChat({
  message: "Explain React hooks",
  context: {
    workspaceInfo: await getWorkspaceContext(),
  },
});

console.log(response.text);
```

---

#### `ai:chat-stream`

Stream AI responses token-by-token.

**Request**:

```typescript
{
  message: string;
  context?: ScreenContext;
}
```

**Response**: Event stream

```typescript
onToken: (token: string) => void
onComplete: () => void
onError: (error: Error) => void
```

**Example**:

```typescript
const cleanup = window.electronAPI.aiChatStream(
  { message: "Write a function to sort an array" },
  (token) => {
    console.log(token); // Incremental tokens
  }
);

// Later: cleanup() to stop listening
```

---

#### `ai:voice-input`

Transcribe audio to text using Whisper.

**Request**:

```typescript
{
  audioBuffer: ArrayBuffer;  // WAV/MP3
  language?: 'en' | 'ko' | 'auto';
}
```

**Response**:

```typescript
{
  transcription: string;
  confidence: number; // 0-1
  language: string;
}
```

---

#### `ai:speak`

Generate speech from text using TTS.

**Request**:

```typescript
{
  text: string;
  voice?: 'male' | 'female';
  speed?: number;  // 0.5-2.0
}
```

**Response**:

```typescript
{
  audioBuffer: ArrayBuffer; // WAV
  duration: number; // seconds
}
```

---

### 1.2 File Operations

#### `file:read`

Read file contents.

**Request**:

```typescript
{
  path: string;  // Absolute path
  encoding?: 'utf-8' | 'binary';
}
```

**Response**:

```typescript
{
  content: string | Buffer;
  encoding: string;
  size: number; // bytes
}
```

---

#### `file:write`

Write file contents.

**Request**:

```typescript
{
  path: string;
  content: string;
  encoding?: 'utf-8';
}
```

**Response**:

```typescript
{
  success: boolean;
  bytesWritten: number;
}
```

---

#### `file:watch`

Watch file for changes.

**Request**:

```typescript
{
  path: string;
}
```

**Response**: Event stream

```typescript
{
  event: "change" | "add" | "unlink";
  path: string;
  timestamp: Date;
}
```

---

### 1.3 Git Operations

#### `git:status`

Get repository status.

**Request**:

```typescript
{
  repoPath: string;
}
```

**Response**:

```typescript
{
  branch: string;
  ahead: number;
  behind: number;
  modified: string[];
  created: string[];
  deleted: string[];
  staged: string[];
}
```

---

#### `git:commit`

Create a commit.

**Request**:

```typescript
{
  repoPath: string;
  message: string;
  files?: string[];  // If empty, commits all
}
```

**Response**:

```typescript
{
  hash: string;
  success: boolean;
}
```

---

#### `git:diff`

Get diff for file or all files.

**Request**:

```typescript
{
  repoPath: string;
  file?: string;  // Optional: specific file
}
```

**Response**:

```typescript
{
  diff: string; // Unified diff format
}
```

---

### 1.4 System Operations

#### `system:screenshot`

Capture screenshot.

**Request**:

```typescript
{
  display?: number;  // Display index (default: 0)
}
```

**Response**:

```typescript
{
  image: Buffer; // PNG
  width: number;
  height: number;
  display: number;
}
```

---

#### `system:notify`

Show system notification.

**Request**:

```typescript
{
  title: string;
  body: string;
  icon?: string;
  urgency?: 'low' | 'normal' | 'critical';
}
```

**Response**:

```typescript
{
  clicked: boolean;
  action?: string;
}
```

---

### 1.5 Settings Operations

#### `settings:get`

Get setting value.

**Request**:

```typescript
{
  key: string;
}
```

**Response**:

```typescript
{
  value: any;
}
```

---

#### `settings:set`

Set setting value.

**Request**:

```typescript
{
  key: string;
  value: any;
}
```

**Response**:

```typescript
{
  success: boolean;
}
```

---

## 2. Service APIs

### 2.1 LlamaService

```typescript
class LlamaService {
  constructor(config: LlamaConfig);

  // Generate text
  async generate(prompt: string, options?: GenerateOptions): Promise<string>;

  // Generate with streaming
  async generateStream(
    prompt: string,
    onToken: (token: string) => void,
    options?: GenerateOptions
  ): Promise<void>;

  // Get embeddings
  async embed(text: string): Promise<Float32Array>;

  // Chat with history
  async chat(
    messages: ChatMessage[],
    options?: GenerateOptions
  ): Promise<string>;

  // Load model
  async loadModel(modelPath: string): Promise<void>;

  // Unload model
  async unloadModel(): Promise<void>;

  // Get model info
  getModelInfo(): ModelInfo;
}

interface GenerateOptions {
  maxTokens?: number; // Default: 2048
  temperature?: number; // 0-2, default: 0.7
  topP?: number; // 0-1, default: 0.9
  topK?: number; // Default: 40
  repeatPenalty?: number; // Default: 1.1
  stopSequences?: string[];
}

interface ChatMessage {
  role: "user" | "assistant" | "system";
  content: string;
}

interface ModelInfo {
  name: string;
  size: number; // bytes
  parameters: string; // e.g., "8B"
  quantization: string; // e.g., "Q4_K_M"
  contextLength: number;
}
```

**Usage Example**:

```typescript
const llama = new LlamaService({
  modelPath: "./models/llama-3.1-8b.gguf",
  nGpuLayers: 35,
});

await llama.loadModel();

const response = await llama.generate("Explain React hooks in simple terms", {
  maxTokens: 500,
  temperature: 0.7,
});

console.log(response);
```

---

### 2.2 WhisperService

```typescript
class WhisperService {
  constructor(config: WhisperConfig);

  // Transcribe audio file
  async transcribeFile(filePath: string): Promise<TranscriptionResult>;

  // Transcribe audio buffer
  async transcribeBuffer(
    audioBuffer: ArrayBuffer,
    options?: TranscribeOptions
  ): Promise<TranscriptionResult>;

  // Real-time transcription
  async transcribeStream(
    audioStream: ReadableStream,
    onSegment: (segment: string) => void
  ): Promise<void>;
}

interface WhisperConfig {
  modelPath: string;
  language?: "en" | "ko" | "auto";
  device?: "cpu" | "gpu";
}

interface TranscribeOptions {
  language?: string;
  task?: "transcribe" | "translate";
  temperature?: number;
}

interface TranscriptionResult {
  text: string;
  segments: Array<{
    text: string;
    start: number; // seconds
    end: number;
    confidence: number;
  }>;
  language: string;
  duration: number;
}
```

---

### 2.3 FileService

```typescript
class FileService {
  // Read file
  async read(filePath: string): Promise<{ content: string; encoding: string }>;

  // Write file
  async write(filePath: string, content: string): Promise<void>;

  // Read directory
  async readDirectory(dirPath: string): Promise<string[]>;

  // Get project structure
  async getProjectStructure(rootPath: string): Promise<FileTree>;

  // Watch file
  watchFile(filePath: string, callback: (event: string) => void): string;

  // Unwatch file
  unwatchFile(watcherId: string): void;

  // Check if file exists
  async exists(filePath: string): Promise<boolean>;

  // Get file stats
  async stat(filePath: string): Promise<FileStats>;
}

interface FileTree {
  name: string;
  type: "file" | "directory";
  children?: FileTree[];
  size?: number;
}

interface FileStats {
  size: number;
  created: Date;
  modified: Date;
  isDirectory: boolean;
  isFile: boolean;
}
```

---

### 2.4 GitService

```typescript
class GitService {
  constructor(repoPath: string);

  // Get status
  async getStatus(): Promise<GitStatus>;

  // Create commit
  async commit(message: string, files?: string[]): Promise<string>;

  // Get diff
  async getDiff(file?: string): Promise<string>;

  // Get log
  async getLog(count?: number): Promise<GitCommit[]>;

  // Create branch
  async createBranch(branchName: string): Promise<void>;

  // Switch branch
  async switchBranch(branchName: string): Promise<void>;

  // Push
  async push(remote?: string, branch?: string): Promise<void>;

  // Pull
  async pull(remote?: string, branch?: string): Promise<void>;
}

interface GitStatus {
  branch: string;
  ahead: number;
  behind: number;
  modified: string[];
  created: string[];
  deleted: string[];
  staged: string[];
}

interface GitCommit {
  hash: string;
  message: string;
  author: string;
  date: string;
  files: string[];
}
```

---

## 3. Database Schema Reference

### 3.1 Complete Schema

```sql
-- conversations table
CREATE TABLE conversations (
  id TEXT PRIMARY KEY,
  title TEXT,
  model TEXT NOT NULL DEFAULT 'llama-3.1-8b',
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  message_count INTEGER NOT NULL DEFAULT 0,
  metadata JSON
);

CREATE INDEX idx_conversations_created ON conversations(created_at DESC);

-- messages table
CREATE TABLE messages (
  id TEXT PRIMARY KEY,
  conversation_id TEXT NOT NULL,
  role TEXT NOT NULL CHECK(role IN ('user', 'assistant', 'system')),
  content TEXT NOT NULL,
  tokens INTEGER,
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  metadata JSON,
  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

CREATE INDEX idx_messages_conversation ON messages(conversation_id, created_at);
CREATE INDEX idx_messages_role ON messages(role);

-- persona_parameters table
CREATE TABLE persona_parameters (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  warmth REAL NOT NULL DEFAULT 0.7 CHECK(warmth BETWEEN 0 AND 1),
  formality REAL NOT NULL DEFAULT 0.5 CHECK(formality BETWEEN 0 AND 1),
  humor REAL NOT NULL DEFAULT 0.6 CHECK(humor BETWEEN 0 AND 1),
  verbosity REAL NOT NULL DEFAULT 0.5 CHECK(verbosity BETWEEN 0 AND 1),
  proactivity REAL NOT NULL DEFAULT 0.5 CHECK(proactivity BETWEEN 0 AND 1),
  creativity REAL NOT NULL DEFAULT 0.7 CHECK(creativity BETWEEN 0 AND 1),
  empathy REAL NOT NULL DEFAULT 0.8 CHECK(empathy BETWEEN 0 AND 1),
  directness REAL NOT NULL DEFAULT 0.6 CHECK(directness BETWEEN 0 AND 1),
  updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- episodic_memory table (RAG)
CREATE TABLE episodic_memory (
  id TEXT PRIMARY KEY,
  conversation_id TEXT NOT NULL,
  user_message TEXT NOT NULL,
  assistant_response TEXT NOT NULL,
  embedding BLOB,
  satisfaction_score REAL CHECK(satisfaction_score BETWEEN 0 AND 1),
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

CREATE INDEX idx_memory_satisfaction ON episodic_memory(satisfaction_score DESC);
CREATE INDEX idx_memory_created ON episodic_memory(created_at DESC);

-- user_settings table
CREATE TABLE user_settings (
  key TEXT PRIMARY KEY,
  value TEXT NOT NULL,
  type TEXT NOT NULL CHECK(type IN ('string', 'number', 'boolean', 'json')),
  updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
);

-- workspaces table
CREATE TABLE workspaces (
  id TEXT PRIMARY KEY,
  root_path TEXT NOT NULL UNIQUE,
  name TEXT NOT NULL,
  type TEXT NOT NULL CHECK(type IN ('nodejs', 'python', 'rust', 'go', 'java', 'generic')),
  git_repo TEXT,
  last_opened DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  metadata JSON
);

CREATE INDEX idx_workspaces_last_opened ON workspaces(last_opened DESC);

-- notifications table
CREATE TABLE notifications (
  id TEXT PRIMARY KEY,
  type TEXT NOT NULL,
  title TEXT NOT NULL,
  message TEXT NOT NULL,
  action_taken TEXT,
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  resolved_at DATETIME,
  metadata JSON
);

CREATE INDEX idx_notifications_created ON notifications(created_at DESC);
CREATE INDEX idx_notifications_type ON notifications(type);
```

### 3.2 Table Descriptions

#### `conversations`

Stores all chat conversations.

| Column          | Type     | Description                          |
| --------------- | -------- | ------------------------------------ |
| `id`            | TEXT     | UUID primary key                     |
| `title`         | TEXT     | User-defined or auto-generated title |
| `model`         | TEXT     | AI model used (e.g., "llama-3.1-8b") |
| `created_at`    | DATETIME | Creation timestamp                   |
| `updated_at`    | DATETIME | Last update timestamp                |
| `message_count` | INTEGER  | Number of messages in conversation   |
| `metadata`      | JSON     | Additional metadata                  |

---

#### `messages`

Stores individual messages within conversations.

| Column            | Type     | Description                      |
| ----------------- | -------- | -------------------------------- |
| `id`              | TEXT     | UUID primary key                 |
| `conversation_id` | TEXT     | Foreign key to conversations     |
| `role`            | TEXT     | 'user', 'assistant', or 'system' |
| `content`         | TEXT     | Message text                     |
| `tokens`          | INTEGER  | Token count (optional)           |
| `created_at`      | DATETIME | Creation timestamp               |
| `metadata`        | JSON     | Additional metadata              |

---

#### `persona_parameters`

Stores AI personality settings.

| Column        | Type | Range | Default | Description               |
| ------------- | ---- | ----- | ------- | ------------------------- |
| `warmth`      | REAL | 0-1   | 0.7     | Cold â† â†’ Warm             |
| `formality`   | REAL | 0-1   | 0.5     | Casual â† â†’ Formal         |
| `humor`       | REAL | 0-1   | 0.6     | Serious â† â†’ Playful       |
| `verbosity`   | REAL | 0-1   | 0.5     | Concise â† â†’ Detailed      |
| `proactivity` | REAL | 0-1   | 0.5     | Reactive â† â†’ Proactive    |
| `creativity`  | REAL | 0-1   | 0.7     | Conservative â† â†’ Creative |
| `empathy`     | REAL | 0-1   | 0.8     | Logical â† â†’ Empathetic    |
| `directness`  | REAL | 0-1   | 0.6     | Indirect â† â†’ Direct       |

---

## 4. TypeScript Types Reference

### 4.1 Core Types

```typescript
// Conversation types
export interface Conversation {
  id: string;
  title: string | null;
  model: string;
  createdAt: Date;
  updatedAt: Date;
  messageCount: number;
  metadata?: Record<string, any>;
}

export interface Message {
  id: string;
  conversationId: string;
  role: "user" | "assistant" | "system";
  content: string;
  tokens?: number;
  createdAt: Date;
  metadata?: Record<string, any>;
}

// Persona types
export interface PersonaParameters {
  warmth: number; // 0-1
  formality: number; // 0-1
  humor: number; // 0-1
  verbosity: number; // 0-1
  proactivity: number; // 0-1
  creativity: number; // 0-1
  empathy: number; // 0-1
  directness: number; // 0-1
}

// Memory types
export interface EpisodicMemory {
  id: string;
  conversationId: string;
  userMessage: string;
  assistantResponse: string;
  embedding?: Float32Array;
  satisfactionScore?: number; // 0-1
  createdAt: Date;
}

// Workspace types
export interface Workspace {
  id: string;
  rootPath: string;
  name: string;
  type: "nodejs" | "python" | "rust" | "go" | "java" | "generic";
  gitRepo?: string;
  lastOpened: Date;
  metadata?: Record<string, any>;
}

export interface WorkspaceContext {
  hasWorkspace: boolean;
  workspaceName?: string;
  workspaceType?: string;
  openFiles?: string[];
  hasGit?: boolean;
}

// Notification types
export interface ProactiveNotification {
  id: string;
  type: "success" | "info" | "warning" | "error" | "proactive";
  title: string;
  message: string;
  actionTaken?: "accepted" | "dismissed" | "ignored";
  createdAt: Date;
  resolvedAt?: Date;
  metadata?: Record<string, any>;
}

// Git types
export interface GitStatus {
  branch: string;
  ahead: number;
  behind: number;
  modified: string[];
  created: string[];
  deleted: string[];
  staged: string[];
}

export interface GitCommit {
  hash: string;
  message: string;
  author: string;
  date: string;
  files: string[];
}

// Settings types
export type Theme = "light" | "dark" | "system";
export type Language = "en" | "ko";
export type Mode = "user-led" | "ai-led";

export interface UserSettings {
  language: Language;
  theme: Theme;
  voiceEnabled: boolean;
  voiceOutputEnabled: boolean;
  screenCaptureEnabled: boolean;
  mode: Mode;
  proactiveNotifications: boolean;
}
```

### 4.2 IPC Types

```typescript
export interface IPCChannel {
  "ai:chat": {
    request: { message: string; context?: ScreenContext };
    response: { text: string; conversationId: string };
  };
  "ai:voice-input": {
    request: { audioBuffer: ArrayBuffer };
    response: { transcription: string };
  };
  "file:read": {
    request: { path: string };
    response: { content: string; encoding: string };
  };
  "file:write": {
    request: { path: string; content: string };
    response: { success: boolean };
  };
  "git:status": {
    request: { repoPath: string };
    response: GitStatus;
  };
  "git:commit": {
    request: { repoPath: string; message: string; files: string[] };
    response: { hash: string };
  };
  "system:screenshot": {
    request: { display?: number };
    response: { image: Buffer; width: number; height: number };
  };
  "system:notify": {
    request: { title: string; body: string };
    response: { clicked: boolean };
  };
}
```

---

## 5. Plugin Development Guide

### 5.1 Plugin Structure

Create a plugin by implementing the `EdenPlugin` interface:

```typescript
// my-plugin/index.ts

import { EdenPlugin, PluginContext } from "@/main/plugins/plugin.interface";

export class MyPlugin implements EdenPlugin {
  name = "my-plugin";
  version = "1.0.0";
  description = "My custom Eden plugin";

  async onLoad(context: PluginContext) {
    console.log("Plugin loaded!");

    // Access core services
    const workspaceInfo = await context.file.getProjectStructure(
      "/path/to/project"
    );
    console.log("Workspace:", workspaceInfo);
  }

  async onUnload() {
    console.log("Plugin unloaded!");
  }

  commands = [
    {
      name: "my-command",
      description: "My custom command",
      execute: async (args: string[], context: PluginContext) => {
        return `Command executed with args: ${args.join(", ")}`;
      },
    },
  ];

  ipcHandlers = {
    "my-plugin:custom-action": async (request: any) => {
      // Handle custom IPC
      return { success: true };
    },
  };
}

export default MyPlugin;
```

### 5.2 Plugin Installation

1. Create plugin directory:

```bash
mkdir ~/Library/Application\ Support/garden-of-eden/plugins/my-plugin
```

2. Add `index.js` (compiled TypeScript):

```bash
cp dist/index.js ~/Library/Application\ Support/garden-of-eden/plugins/my-plugin/
```

3. Restart Eden â†’ Plugin auto-loads

### 5.3 Available Context APIs

```typescript
interface PluginContext {
  ai: AIServiceAPI; // Access to Llama, Whisper
  file: FileService; // File operations
  git: GitService; // Git operations
  calendar: CalendarService; // Calendar access
  webhook: WebhookService; // Webhook triggers
  db: Database; // SQLite database
  storage: PluginStorage; // Plugin-specific storage
  logger: Logger; // Logging
}
```

---

## 6. Webhook Integration Guide

### 6.1 Setup

Configure webhooks in settings:

```json
{
  "webhooks": {
    "slack": {
      "url": "https://hooks.slack.com/services/YOUR/WEBHOOK/URL",
      "enabled": true
    },
    "discord": {
      "url": "https://discord.com/api/webhooks/YOUR/WEBHOOK",
      "enabled": true
    }
  }
}
```

### 6.2 Triggering Webhooks

From plugin or service:

```typescript
// Trigger Slack webhook
await webhookService.notifySlack("Hello from Eden!", "#general");

// Trigger Discord webhook
await webhookService.notifyDiscord("New commit created!");

// Custom webhook
await webhookService.trigger("custom-webhook", {
  event: "conversation_completed",
  data: { conversationId: "123" },
});
```

### 6.3 Supported Services

- âœ… Slack
- âœ… Discord
- âœ… Notion
- âœ… Zapier (generic webhook)
- âœ… IFTTT (generic webhook)
- âœ… Custom HTTP endpoints

---

**End of Part 6**

_Lines: ~800_
_Next: Part 7 - User & Developer Guide_

---

---

# Part 7: User & Developer Guide

_Complete guide for users and developers working with Eden Project_

---

## 1. Getting Started

### 1.1 System Requirements

**Minimum Requirements:**

- **OS**: Windows 10 (64-bit) or macOS 11.0+
- **RAM**: 16 GB (8 GB usable for app)
- **Storage**: 20 GB free space
- **CPU**: Intel i5 / AMD Ryzen 5 or equivalent (AVX2 support required)
- **GPU**: Optional (NVIDIA RTX series for GPU acceleration)

**Recommended:**

- **OS**: Windows 11 or macOS 13.0+
- **RAM**: 32 GB
- **Storage**: 50 GB SSD
- **CPU**: Intel i7 / AMD Ryzen 7 or Apple M1/M2
- **GPU**: NVIDIA RTX 3060 or better (for faster inference)

---

### 1.2 Installation

#### Windows Installation

1. **Download**: Get the latest `.exe` installer from the releases page
2. **Run Installer**: Double-click `GardenOfEden-Setup-v3.0.0.exe`
3. **Choose Install Location**: Default is `C:\Program Files\GardenOfEden`
4. **Complete Installation**: Click "Finish" when done

```powershell
# Silent install (admin required)
GardenOfEden-Setup-v3.0.0.exe /S /D=C:\Program Files\GardenOfEden
```

#### macOS Installation

1. **Download**: Get the latest `.dmg` from releases
2. **Open DMG**: Double-click `GardenOfEden-v3.0.0.dmg`
3. **Drag to Applications**: Drag the app icon to Applications folder
4. **First Launch**: Right-click app and select "Open" (bypass Gatekeeper)

```bash
# Command line install
hdiutil attach GardenOfEden-v3.0.0.dmg
cp -R "/Volumes/Eden Project/Eden Project.app" /Applications/
hdiutil detach "/Volumes/Eden Project"
```

#### Linux Installation (AppImage)

1. **Download**: Get `GardenOfEden-v3.0.0.AppImage`
2. **Make Executable**:

```bash
chmod +x GardenOfEden-v3.0.0.AppImage
```

3. **Run**:

```bash
./GardenOfEden-v3.0.0.AppImage
```

---

### 1.3 First Run & Model Download

When you first launch Eden Project, you'll see the **Model Download Wizard**.

#### Step 1: Welcome Screen

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Welcome to Eden Project           â”‚
â”‚                                          â”‚
â”‚  Your personal AI assistant              â”‚
â”‚  100% local, 100% private                â”‚
â”‚                                          â”‚
â”‚  We need to download AI models          â”‚
â”‚  (~8 GB total)                          â”‚
â”‚                                          â”‚
â”‚         [Continue] [Quit]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Step 2: Model Selection

```
Select models to download:

â˜‘ Llama 3.1 8B (Primary AI)          ~4.7 GB
â˜‘ Whisper Large V3 (Speech-to-text)  ~1.5 GB
â˜‘ LLaVA 7B (Vision, optional)        ~4.1 GB

Total: ~10.3 GB
Estimated time: 15-30 minutes

Download location:
~/Library/Application Support/GardenOfEden/models/

         [Back] [Start Download]
```

#### Step 3: Download Progress

```
Downloading models...

Llama 3.1 8B
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (4.7 GB)

Whisper Large V3
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (1.5 GB)

LLaVA 7B
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 45% (1.8 / 4.1 GB)

Overall progress: 71%
Time remaining: ~8 minutes

              [Cancel] [Minimize]
```

#### Step 4: Model Verification

After download, models are verified for integrity:

```
Verifying models...

â˜‘ Llama 3.1 8B (SHA256 verified)
â˜‘ Whisper Large V3 (SHA256 verified)
â˜‘ LLaVA 7B (SHA256 verified)

All models ready!

              [Continue to App]
```

---

### 1.4 Initial Configuration

#### Welcome Tutorial

First-time users see a 5-step tutorial:

**Step 1: Chat Interface**

```
This is your chat interface!

- Type messages in the input box
- Press Enter to send
- AI responses appear on the left
- Your messages on the right

            [Next]
```

**Step 2: Voice Input**

```
Click the microphone icon to speak

ğŸ¤ Click and hold to record
   Release to send

Or click once to start, click again to stop

            [Next]
```

**Step 3: Persona Configuration**

```
Configure AI personality in Settings

Adjust 8 parameters:
- Warmth, Formality, Humor
- Verbosity, Proactivity, Creativity
- Empathy, Directness

            [Next]
```

**Step 4: Dual Mode**

```
Switch between two modes:

ğŸ‘¤ User-Led: You control the conversation
ğŸ¤– AI-Led: AI proactively suggests actions

Toggle in the top-right corner

            [Next]
```

**Step 5: Privacy**

```
Everything stays on your computer

âœ“ No internet required (after setup)
âœ“ No data collection
âœ“ Full privacy

            [Start Using]
```

---

## 2. User Guide

### 2.1 Chat Interface Basics

#### Sending Messages

1. **Text**: Type in the input box at bottom, press Enter
2. **Voice**: Click ğŸ¤ microphone icon, speak, click again to send
3. **Multiline**: Press Shift+Enter for new line without sending

#### Message Features

- **Markdown Support**: Use `**bold**`, `*italic*`, `code`, etc.
- **Code Blocks**: Syntax highlighting for 50+ languages
- **Copy Code**: Hover over code block, click copy icon
- **Edit Messages**: Click pencil icon to edit sent messages
- **Delete Messages**: Right-click message â†’ Delete

#### Example Chat Session

````
You: Hello! Can you help me write a Python function?

AI: Of course! I'd be happy to help you write a Python
    function. What should the function do?

You: Calculate the factorial of a number

AI: Here's a Python function to calculate factorial:

    ```python
    def factorial(n: int) -> int:
        """Calculate factorial of n."""
        if n < 0:
            raise ValueError("n must be non-negative")
        if n == 0 or n == 1:
            return 1
        return n * factorial(n - 1)

    # Example usage
    print(factorial(5))  # Output: 120
    ```

    This uses recursion. Would you like an iterative
    version instead?
````

---

### 2.2 Voice Features

#### Voice Input (Speech-to-Text)

**Method 1: Click-and-Hold**

1. Click and hold ğŸ¤ microphone button
2. Speak your message
3. Release button to process
4. Text appears in input box

**Method 2: Click-to-Toggle**

1. Click ğŸ¤ once to start recording
2. Speak your message
3. Click ğŸ¤ again to stop
4. Text appears in input box

**Visual Feedback:**

```
Recording...
ğŸ¤ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 12s / 60s max
ğŸ”Š â–‚â–ƒâ–…â–†â–‡â–†â–…â–ƒâ–‚ (waveform animation)

[Stop Recording]
```

**Supported Languages:**

- ğŸ‡°ğŸ‡· Korean (í•œêµ­ì–´)
- ğŸ‡ºğŸ‡¸ English
- ğŸ‡¯ğŸ‡µ Japanese (æ—¥æœ¬èª)
- ğŸ‡¨ğŸ‡³ Chinese (ä¸­æ–‡)
- ğŸ‡ªğŸ‡¸ Spanish (EspaÃ±ol)
- ğŸ‡«ğŸ‡· French (FranÃ§ais)

#### Voice Output (Text-to-Speech)

AI responses can be read aloud automatically or manually.

**Enable Auto-TTS:**
Settings â†’ Voice â†’ Enable auto-playback âœ“

**Manual Playback:**
Click ğŸ”Š speaker icon on any AI message

**TTS Player UI:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ”Š Playing AI response...      â”‚
â”‚ â–¶ [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘] 35% (4s / 12s)â”‚
â”‚ [Pause] [Stop] [Speed: 1.0x]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**TTS Settings:**

- **Speed**: 0.5x - 2.0x
- **Voice**: System default or custom
- **Auto-play**: On/Off
- **Skip long messages**: Threshold (e.g., 500 chars)

---

### 2.3 Persona Configuration

Access: Settings â†’ Persona

The AI's personality is controlled by 8 adjustable parameters.

#### 8 Persona Parameters

**1. Warmth (ì˜¨ê¸°)**

```
Cold â—„â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â–º Warm
     0      0.7      1.0

Cold:  Neutral, matter-of-fact
Warm:  Friendly, caring, emotionally present
```

**2. Formality (ê²©ì‹)**

```
Casual â—„â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â–º Formal
       0     0.3      1.0

Casual: Conversational, uses contractions
Formal: Professional, proper grammar
```

**3. Humor (ìœ ë¨¸)**

```
Serious â—„â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Playful
        0   0.2       1.0

Serious: Straightforward, no jokes
Playful: Witty, uses humor appropriately
```

**4. Verbosity (ìƒì„¸í•¨)**

```
Concise â—„â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â–º Detailed
        0    0.5       1.0

Concise: Brief, to-the-point answers
Detailed: Thorough explanations
```

**5. Proactivity (ì£¼ë„ì„±)**

```
Reactive â—„â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â–º Proactive
         0    0.6      1.0

Reactive:  Only answers direct questions
Proactive: Suggests actions, asks questions
```

**6. Creativity (ì°½ì˜ì„±)**

```
Practical â—„â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â–º Creative
          0   0.4      1.0

Practical: Safe, proven solutions
Creative:  Novel, unconventional ideas
```

**7. Empathy (ê³µê°)**

```
Objective â—„â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â–º Empathetic
          0   0.6      1.0

Objective:  Focus on facts, logic
Empathetic: Acknowledge feelings, supportive
```

**8. Directness (ì§ì„¤ì„±)**

```
Indirect â—„â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â–º Direct
         0     0.7     1.0

Indirect: Gentle, suggestive
Direct:   Clear, straightforward, honest
```

#### Example Personas

**Preset 1: Professional Assistant**

```yaml
warmth: 0.5
formality: 0.8
humor: 0.2
verbosity: 0.6
proactivity: 0.7
creativity: 0.4
empathy: 0.5
directness: 0.8
```

**Preset 2: Friendly Companion**

```yaml
warmth: 0.9
formality: 0.2
humor: 0.7
verbosity: 0.5
proactivity: 0.8
creativity: 0.6
empathy: 0.9
directness: 0.5
```

**Preset 3: Technical Expert**

```yaml
warmth: 0.3
formality: 0.6
humor: 0.1
verbosity: 0.8
proactivity: 0.5
creativity: 0.7
empathy: 0.3
directness: 0.9
```

---

### 2.4 Dual Mode: User-Led vs AI-Led

#### User-Led Mode ğŸ‘¤

**Behavior:**

- AI waits for your input
- Responds only when asked
- Does not interrupt
- Does not suggest unprompted actions

**Best For:**

- Focused work sessions
- When you know what you need
- Minimal distractions
- Traditional chat experience

**Example:**

```
You: What's the weather?
AI:  I'm a local AI without internet access,
     so I can't check live weather. Would you
     like me to help with something else?

[AI waits for next input]
```

#### AI-Led Mode ğŸ¤–

**Behavior:**

- AI actively monitors context
- Suggests actions proactively
- Sends notifications
- Asks clarifying questions
- Initiates helpful conversations

**Best For:**

- Exploratory work
- Learning new topics
- Getting suggestions
- Productivity assistance

**Example:**

```
[System detects: package.json modified]

AI: ğŸ”” I noticed you updated package.json
    with a new dependency. Would you like
    me to run `npm install`?

    [Yes] [No] [Dismiss]
```

**Toggle Mode:**
Click mode switcher in top-right:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mode: User-Led â”‚ â† Click to toggle
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Changes to:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mode: AI-Led   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2.5 System Integrations

#### File System Integration

**Reading Files:**

```
You: Read the README.md file

AI:  [Reads file automatically]
     Here's the content of README.md:

     # My Project
     This is a sample project...
```

**Writing Files:**

````
You: Create a new Python file called hello.py
     with a hello world program

AI:  I'll create hello.py for you:

     ```python
     # hello.py
     print("Hello, World!")
     ```

     âœ“ File created at ~/Desktop/hello.py
````

**File Operations:**

- âœ… Read files
- âœ… Write files
- âœ… List directories
- âœ… Search file contents
- âœ… Move/rename files
- âœ… Delete files (with confirmation)

#### Git Integration

**Status Check:**

```
You: What's my git status?

AI:  Current branch: main

     Modified files:
     â€¢ src/app.ts (3 changes)
     â€¢ README.md (1 change)

     Untracked files:
     â€¢ test/new-test.ts

     You're 2 commits ahead of origin/main.
```

**Commit:**

```
You: Commit these changes with message
     "Add new feature"

AI:  I'll commit the modified files:

     $ git add src/app.ts README.md
     $ git commit -m "Add new feature"

     âœ“ Committed as 8a3f2b1

     Would you like me to push to remote?
```

**Git Operations:**

- âœ… Status check
- âœ… Diff viewing
- âœ… Commit (with confirmation)
- âœ… Branch management
- âœ… Log viewing
- âš ï¸ Push (requires explicit confirmation)
- âŒ Force push (blocked for safety)

#### Clipboard Integration

**Copy from Chat:**
Right-click any message â†’ Copy

**Paste into Chat:**
AI can read clipboard when needed:

````
You: Fix the code in my clipboard

AI:  [Reads clipboard automatically]
     I see this JavaScript code:

     ```javascript
     function add(a, b) {
       return a + b
     }
     ```

     The code looks good! Did you want me
     to add error handling or type checking?
````

#### Screen Context (Vision)

**Screenshot Analysis:**

````
You: [Paste screenshot] What's wrong here?

AI:  [Analyzes screenshot with LLaVA]
     I can see a JavaScript error in your
     browser console:

     "TypeError: Cannot read property 'map'
      of undefined"

     This suggests `items` is undefined when
     you try to call .map() on it. Add a check:

     ```javascript
     const items = data?.items || [];
     items.map(...)
     ```
````

---

### 2.6 Conversation History

Access: Click ğŸ“š History icon or press Cmd/Ctrl+H

#### History View

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Conversation History          [Search]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“… Today                                â”‚
â”‚   â€¢ How to use Git (15 messages)   2h  â”‚
â”‚   â€¢ Python debugging help (8 msg)  4h  â”‚
â”‚                                         â”‚
â”‚ ğŸ“… Yesterday                            â”‚
â”‚   â€¢ React component design (23 msg)     â”‚
â”‚   â€¢ SQL query optimization (12 msg)     â”‚
â”‚                                         â”‚
â”‚ ğŸ“… This Week                            â”‚
â”‚   â€¢ TypeScript best practices (45 msg)  â”‚
â”‚   â€¢ API design discussion (31 msg)      â”‚
â”‚                                         â”‚
â”‚ [Load More]                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Search

```
Search: "python flask"

Results (3):

1. Flask API Tutorial (2024-01-10)
   "...building a REST API with Flask..."
   32 messages

2. Flask vs Django (2024-01-08)
   "...comparing Flask and Django for..."
   18 messages

3. Flask debugging (2024-01-05)
   "...debug mode in Flask application..."
   12 messages
```

#### Export Conversation

Right-click any conversation â†’ Export

**Export Formats:**

- **JSON**: Full conversation data
- **Markdown**: Readable text format
- **TXT**: Plain text
- **PDF**: Formatted document (requires plugin)

**Example Markdown Export:**

```markdown
# Conversation: Python Debugging Help

Date: 2024-01-12 14:30
Model: Llama 3.1 8B
Messages: 8

---

**User** (14:30:15)
How do I debug a Python script?

**AI** (14:30:18)
There are several ways to debug Python:

1. **Print statements**: Simple but effective
2. **pdb debugger**: Built-in Python debugger
3. **IDE debuggers**: VS Code, PyCharm
   ...
```

---

### 2.7 Settings & Preferences

Access: Click âš™ï¸ Settings icon or press Cmd/Ctrl+,

#### General Settings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Settings                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ General                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Language: [English â–¼]               â”‚ â”‚
â”‚ â”‚                                     â”‚ â”‚
â”‚ â”‚ Theme: â— Light â—‹ Dark â—‹ Auto       â”‚ â”‚
â”‚ â”‚                                     â”‚ â”‚
â”‚ â”‚ Start at login: [âœ“]                â”‚ â”‚
â”‚ â”‚                                     â”‚ â”‚
â”‚ â”‚ Minimize to tray: [âœ“]              â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                         â”‚
â”‚ [Save] [Cancel]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Model Settings

```
Model Configuration

Primary LLM: [Llama 3.1 8B â–¼]

Temperature: â—„â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â–º 0.7
             0.0   0.7   1.0

Max Tokens:  [2048        ]

Context Window: [8192      ]

GPU Acceleration: [âœ“] Enabled
GPU Device: NVIDIA RTX 3060 (8 GB)

[Apply] [Reset to Defaults]
```

#### Privacy Settings

```
Privacy & Data

Conversation History:
[âœ“] Save conversations locally
[âœ“] Enable conversation search
[ ] Auto-delete after 30 days

Telemetry:
[ ] Send anonymous usage stats
[ ] Share crash reports

Data Location:
~/Library/Application Support/GardenOfEden/

[Open Data Folder] [Clear All Data]
```

#### Keyboard Shortcuts

```
Keyboard Shortcuts

Chat:
Send message          Enter
New line              Shift+Enter
Voice input           Cmd/Ctrl+M
Clear input           Escape

Navigation:
New conversation      Cmd/Ctrl+N
Search history        Cmd/Ctrl+H
Settings              Cmd/Ctrl+,
Toggle mode           Cmd/Ctrl+D

Window:
Hide window           Cmd/Ctrl+W
Minimize to tray      Cmd/Ctrl+Shift+M
Quit                  Cmd/Ctrl+Q

[Customize] [Reset to Defaults]
```

---

## 3. Developer Guide

### 3.1 Building from Source

#### Prerequisites

**Required:**

- Node.js 18+ (LTS recommended)
- npm 9+ or yarn 1.22+
- Git
- Python 3.10+ (for llama.cpp bindings)
- CMake 3.20+ (for building native modules)

**Platform-Specific:**

_Windows:_

- Visual Studio 2019+ (Build Tools)
- Windows SDK

_macOS:_

- Xcode Command Line Tools
- Homebrew (recommended)

_Linux:_

- GCC 9+ or Clang 10+
- Build essentials

#### Clone Repository

```bash
git clone https://github.com/yourusername/garden-of-eden-v3.git
cd garden-of-eden-v3
```

#### Install Dependencies

```bash
# Install Node.js dependencies
npm install

# Install Python dependencies (for llama.cpp)
pip install -r requirements.txt

# Build native modules
npm run build:native
```

#### Download Models

```bash
# Download all models
npm run download:models

# Or download individually
npm run download:llama
npm run download:whisper
npm run download:llava
```

#### Development Mode

```bash
# Start in development mode (hot reload)
npm run dev

# Run main and renderer separately
npm run dev:main    # Main process
npm run dev:renderer # Renderer process (React)
```

#### Build for Production

```bash
# Build for current platform
npm run build

# Build for specific platform
npm run build:win    # Windows
npm run build:mac    # macOS
npm run build:linux  # Linux

# Build for all platforms (requires CI/CD)
npm run build:all
```

#### Run Tests

```bash
# Run all tests
npm test

# Run unit tests
npm run test:unit

# Run integration tests
npm run test:integration

# Run E2E tests
npm run test:e2e

# Coverage report
npm run test:coverage
```

---

### 3.2 Project Structure

```
garden-of-eden-v3/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/                 # Electron main process
â”‚   â”‚   â”œâ”€â”€ index.ts          # Main entry point
â”‚   â”‚   â”œâ”€â”€ ipc/              # IPC handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ ai.ts         # AI chat handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ file.ts       # File system handlers
â”‚   â”‚   â”‚   â””â”€â”€ git.ts        # Git handlers
â”‚   â”‚   â”œâ”€â”€ services/         # Core services
â”‚   â”‚   â”‚   â”œâ”€â”€ llama.ts      # Llama service
â”‚   â”‚   â”‚   â”œâ”€â”€ whisper.ts    # Whisper service
â”‚   â”‚   â”‚   â”œâ”€â”€ llava.ts      # LLaVA service
â”‚   â”‚   â”‚   â””â”€â”€ db.ts         # Database service
â”‚   â”‚   â”œâ”€â”€ plugins/          # Plugin system
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.ts    # Plugin manager
â”‚   â”‚   â”‚   â””â”€â”€ loader.ts     # Plugin loader
â”‚   â”‚   â””â”€â”€ utils/            # Utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ renderer/             # Electron renderer (React)
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ Chat/         # Chat interface
â”‚   â”‚   â”‚   â”œâ”€â”€ Settings/     # Settings UI
â”‚   â”‚   â”‚   â””â”€â”€ History/      # History viewer
â”‚   â”‚   â”œâ”€â”€ stores/           # Zustand stores
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.ts       # Chat state
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.ts   # Settings state
â”‚   â”‚   â”‚   â””â”€â”€ persona.ts    # Persona state
â”‚   â”‚   â”œâ”€â”€ hooks/            # React hooks
â”‚   â”‚   â”œâ”€â”€ utils/            # Utilities
â”‚   â”‚   â””â”€â”€ App.tsx           # Root component
â”‚   â”‚
â”‚   â”œâ”€â”€ preload/              # Preload scripts
â”‚   â”‚   â””â”€â”€ index.ts          # Bridge between main/renderer
â”‚   â”‚
â”‚   â””â”€â”€ shared/               # Shared types/utils
â”‚       â”œâ”€â”€ types/            # TypeScript types
â”‚       â””â”€â”€ constants/        # Constants
â”‚
â”œâ”€â”€ models/                   # AI models (gitignored)
â”‚   â”œâ”€â”€ llama-3.1-8b.gguf
â”‚   â”œâ”€â”€ whisper-large-v3.bin
â”‚   â””â”€â”€ llava-7b.gguf
â”‚
â”œâ”€â”€ plugins/                  # User plugins
â”‚   â””â”€â”€ example-plugin/
â”‚
â”œâ”€â”€ tests/                    # Test files
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”‚
â”œâ”€â”€ scripts/                  # Build/utility scripts
â”‚   â”œâ”€â”€ download-models.js
â”‚   â””â”€â”€ build.js
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â””â”€â”€ api/
â”‚
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ electron-builder.yml      # Build configuration
â””â”€â”€ README.md
```

---

### 3.3 Core Architecture

#### Process Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Renderer Process (React)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Chat   â”‚  â”‚ Settings â”‚  â”‚ Historyâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚         â†• (IPC via contextBridge)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Main Process (Node.js)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚       IPC Handler Manager         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†•         â†•         â†•           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Llama  â”‚ â”‚ Whisper â”‚ â”‚  LLaVA  â”‚  â”‚
â”‚  â”‚ Service â”‚ â”‚ Service â”‚ â”‚ Service â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â†•         â†•         â†•           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚      SQLite Database (DB)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Data Flow

**Chat Message Flow:**

```
1. User types â†’ ChatInput component
2. ChatInput â†’ useChatStore.sendMessage()
3. Store â†’ window.electronAPI.sendAIChat()
4. IPC â†’ Main process (ai.ts handler)
5. Handler â†’ LlamaService.generateResponse()
6. LlamaService â†’ llama.cpp (streaming)
7. Stream chunks â†’ Renderer (IPC events)
8. Renderer â†’ ChatBubble updates (streaming UI)
9. Complete â†’ Save to DB
```

---

### 3.4 Adding Features

#### Example: Adding a New IPC Channel

**1. Define types** (`src/shared/types/ipc.ts`):

```typescript
export interface IPCChannel {
  // ... existing channels

  "system:screenshot": {
    request: { saveToFile?: boolean };
    response: { base64: string; path?: string };
  };
}
```

**2. Create handler** (`src/main/ipc/system.ts`):

```typescript
import { ipcMain } from "electron";
import { screenshot } from "screenshot-desktop";

export function registerSystemHandlers() {
  ipcMain.handle("system:screenshot", async (event, req) => {
    const img = await screenshot();
    const base64 = img.toString("base64");

    if (req.saveToFile) {
      const path = await saveScreenshot(img);
      return { base64, path };
    }

    return { base64 };
  });
}
```

**3. Register in main** (`src/main/index.ts`):

```typescript
import { registerSystemHandlers } from "./ipc/system";

app.whenReady().then(() => {
  registerAIHandlers();
  registerFileHandlers();
  registerGitHandlers();
  registerSystemHandlers(); // Add this
});
```

**4. Expose in preload** (`src/preload/index.ts`):

```typescript
contextBridge.exposeInMainWorld("electronAPI", {
  // ... existing APIs

  takeScreenshot: (saveToFile?: boolean) =>
    ipcRenderer.invoke("system:screenshot", { saveToFile }),
});
```

**5. Use in renderer** (`src/renderer/components/ScreenshotButton.tsx`):

```typescript
export function ScreenshotButton() {
  const [loading, setLoading] = useState(false);

  const handleClick = async () => {
    setLoading(true);
    try {
      const { base64, path } = await window.electronAPI.takeScreenshot(true);
      console.log("Screenshot saved:", path);
      // Show screenshot in chat...
    } finally {
      setLoading(false);
    }
  };

  return (
    <button onClick={handleClick} disabled={loading}>
      {loading ? "Capturing..." : "ğŸ“¸ Screenshot"}
    </button>
  );
}
```

---

### 3.5 Plugin Development

Plugins extend Eden Project functionality without modifying core code.

#### Plugin Structure

```
my-plugin/
â”œâ”€â”€ manifest.json       # Plugin metadata
â”œâ”€â”€ index.js           # Main entry point
â”œâ”€â”€ icon.png           # Plugin icon
â””â”€â”€ README.md          # Documentation
```

#### manifest.json

```json
{
  "name": "my-plugin",
  "version": "1.0.0",
  "description": "My awesome plugin",
  "author": "Your Name",
  "main": "index.js",
  "permissions": ["fs:read", "fs:write", "network:fetch"],
  "hooks": {
    "onMessageSent": true,
    "onMessageReceived": true,
    "onAppReady": true
  }
}
```

#### index.js

```javascript
class MyPlugin {
  constructor(api) {
    this.api = api;
  }

  async onActivate() {
    console.log("MyPlugin activated!");

    // Register command
    this.api.commands.register("my-command", async (args) => {
      await this.api.chat.sendMessage("Hello from plugin!");
    });

    // Add menu item
    this.api.menu.addItem({
      label: "My Plugin Action",
      action: () => this.doSomething(),
    });
  }

  async onMessageSent(message) {
    // Hook: triggered when user sends message
    console.log("User sent:", message.content);
  }

  async onMessageReceived(message) {
    // Hook: triggered when AI responds
    console.log("AI responded:", message.content);
  }

  async doSomething() {
    const result = await this.api.fs.readFile("/path/to/file");
    await this.api.chat.sendMessage(`File contents: ${result}`);
  }

  async onDeactivate() {
    console.log("MyPlugin deactivated!");
  }
}

module.exports = MyPlugin;
```

#### Plugin API Reference

**api.chat**

```javascript
api.chat.sendMessage(content); // Send message to chat
api.chat.getCurrentConversation(); // Get active conversation
api.chat.getHistory(limit); // Get conversation history
```

**api.fs**

```javascript
api.fs.readFile(path); // Read file
api.fs.writeFile(path, content); // Write file
api.fs.listDir(path); // List directory
api.fs.fileExists(path); // Check if file exists
```

**api.commands**

```javascript
api.commands.register(name, handler); // Register slash command
api.commands.unregister(name); // Unregister command
```

**api.menu**

```javascript
api.menu.addItem({ label, action }); // Add menu item
api.menu.removeItem(id); // Remove menu item
```

**api.settings**

```javascript
api.settings.get(key); // Get setting value
api.settings.set(key, value); // Set setting value
```

---

### 3.6 Testing

#### Unit Tests

```typescript
// tests/unit/services/llama.test.ts
import { LlamaService } from "@/main/services/llama";

describe("LlamaService", () => {
  let service: LlamaService;

  beforeEach(() => {
    service = new LlamaService({
      modelPath: "./models/test-model.gguf",
    });
  });

  afterEach(async () => {
    await service.dispose();
  });

  test("should generate response", async () => {
    const response = await service.generateResponse({
      messages: [{ role: "user", content: "Hello" }],
    });

    expect(response.content).toBeTruthy();
    expect(response.content.length).toBeGreaterThan(0);
  });

  test("should respect max tokens", async () => {
    const response = await service.generateResponse({
      messages: [{ role: "user", content: "Count to 100" }],
      maxTokens: 20,
    });

    expect(response.tokens).toBeLessThanOrEqual(20);
  });
});
```

#### Integration Tests

```typescript
// tests/integration/chat-flow.test.ts
import { app } from "electron";
import { Database } from "@/main/services/db";
import { LlamaService } from "@/main/services/llama";

describe("Chat Flow Integration", () => {
  let db: Database;
  let llama: LlamaService;

  beforeAll(async () => {
    await app.whenReady();
    db = new Database(":memory:");
    llama = new LlamaService({ modelPath: "./models/test.gguf" });
  });

  afterAll(async () => {
    await db.close();
    await llama.dispose();
  });

  test("complete chat flow", async () => {
    // Create conversation
    const conv = await db.createConversation({
      title: "Test Chat",
      model: "llama-3.1-8b",
    });

    // Send message
    const userMsg = await db.createMessage({
      conversationId: conv.id,
      role: "user",
      content: "What is 2+2?",
    });

    // Generate AI response
    const aiResponse = await llama.generateResponse({
      messages: [{ role: "user", content: userMsg.content }],
    });

    // Save AI message
    const aiMsg = await db.createMessage({
      conversationId: conv.id,
      role: "assistant",
      content: aiResponse.content,
    });

    // Verify conversation
    const messages = await db.getMessages(conv.id);
    expect(messages).toHaveLength(2);
    expect(messages[0].role).toBe("user");
    expect(messages[1].role).toBe("assistant");
  });
});
```

#### E2E Tests

```typescript
// tests/e2e/chat-ui.test.ts
import { ElectronApplication, Page, _electron } from "playwright";
import { test, expect } from "@playwright/test";

let app: ElectronApplication;
let page: Page;

test.beforeAll(async () => {
  app = await _electron.launch({ args: ["."] });
  page = await app.firstWindow();
});

test.afterAll(async () => {
  await app.close();
});

test("should send and receive message", async () => {
  // Type message
  await page.fill('[data-testid="chat-input"]', "Hello AI!");

  // Send message
  await page.press('[data-testid="chat-input"]', "Enter");

  // Wait for user message to appear
  await page.waitForSelector('[data-testid="user-message"]');
  const userMsg = await page.textContent('[data-testid="user-message"]');
  expect(userMsg).toContain("Hello AI!");

  // Wait for AI response
  await page.waitForSelector('[data-testid="ai-message"]', { timeout: 30000 });
  const aiMsg = await page.textContent('[data-testid="ai-message"]');
  expect(aiMsg).toBeTruthy();
  expect(aiMsg.length).toBeGreaterThan(0);
});

test("should toggle dual mode", async () => {
  // Click mode toggle
  await page.click('[data-testid="mode-toggle"]');

  // Verify mode changed
  const modeText = await page.textContent('[data-testid="current-mode"]');
  expect(modeText).toContain("AI-Led");

  // Toggle back
  await page.click('[data-testid="mode-toggle"]');
  const newModeText = await page.textContent('[data-testid="current-mode"]');
  expect(newModeText).toContain("User-Led");
});
```

---

### 3.7 Contributing

#### Contribution Guidelines

1. **Fork & Clone**

   ```bash
   git clone https://github.com/yourusername/garden-of-eden-v3.git
   cd garden-of-eden-v3
   git remote add upstream https://github.com/original/garden-of-eden-v3.git
   ```

2. **Create Feature Branch**

   ```bash
   git checkout -b feature/my-new-feature
   ```

3. **Make Changes**

   - Write code
   - Add tests
   - Update documentation

4. **Run Tests & Linting**

   ```bash
   npm run lint
   npm run test
   npm run type-check
   ```

5. **Commit with Conventional Commits**

   ```bash
   git commit -m "feat: add screenshot capture feature"
   git commit -m "fix: resolve memory leak in LlamaService"
   git commit -m "docs: update plugin development guide"
   ```

6. **Push & Create PR**
   ```bash
   git push origin feature/my-new-feature
   ```
   Then create Pull Request on GitHub

#### Code Style

**TypeScript:**

```typescript
// âœ… Good
export async function generateResponse(
  messages: Message[],
  options?: GenerateOptions
): Promise<Response> {
  const { maxTokens = 2048, temperature = 0.7 } = options ?? {};

  // Implementation...
}

// âŒ Bad
export async function generateResponse(messages, options) {
  let maxTokens = options?.maxTokens || 2048;
  // No types, inconsistent formatting
}
```

**React Components:**

```tsx
// âœ… Good
interface ChatBubbleProps {
  message: string;
  sender: "user" | "ai";
  timestamp: Date;
}

export function ChatBubble({ message, sender, timestamp }: ChatBubbleProps) {
  return (
    <div className={cn("chat-bubble", sender)}>
      <p>{message}</p>
      <time>{formatTime(timestamp)}</time>
    </div>
  );
}

// âŒ Bad
export default function ChatBubble(props) {
  return <div>{props.message}</div>;
}
```

#### PR Template

```markdown
## Description

Brief description of changes

## Type of Change

- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change
- [ ] Documentation update

## Testing

- [ ] Unit tests added/updated
- [ ] Integration tests added/updated
- [ ] E2E tests added/updated
- [ ] Manual testing completed

## Checklist

- [ ] Code follows style guidelines
- [ ] Self-review completed
- [ ] Comments added for complex code
- [ ] Documentation updated
- [ ] No new warnings
- [ ] Tests pass locally

## Screenshots (if applicable)
```

---

## 4. Troubleshooting

### 4.1 Common Issues

#### Issue: App won't start

**Symptoms:**

- App crashes on launch
- White screen
- "Application Error" dialog

**Solutions:**

1. **Check logs:**

   ```bash
   # macOS
   ~/Library/Logs/GardenOfEden/main.log

   # Windows
   %APPDATA%\GardenOfEden\logs\main.log

   # Linux
   ~/.config/GardenOfEden/logs/main.log
   ```

2. **Clear cache:**

   ```bash
   # macOS
   rm -rf ~/Library/Application\ Support/GardenOfEden/cache

   # Windows
   rmdir /s "%APPDATA%\GardenOfEden\cache"

   # Linux
   rm -rf ~/.config/GardenOfEden/cache
   ```

3. **Reinstall models:**

   ```bash
   # Delete models
   rm -rf ~/Library/Application\ Support/GardenOfEden/models

   # Relaunch app to trigger download wizard
   ```

#### Issue: Slow AI responses

**Symptoms:**

- AI takes 30+ seconds to respond
- Responses timeout
- High CPU usage

**Solutions:**

1. **Enable GPU acceleration:**
   Settings â†’ Model â†’ GPU Acceleration âœ“

2. **Reduce context window:**
   Settings â†’ Model â†’ Context Window: 4096 (instead of 8192)

3. **Lower temperature:**
   Settings â†’ Model â†’ Temperature: 0.5 (instead of 0.7)

4. **Check system resources:**
   ```bash
   # Monitor CPU/RAM usage
   top -o cpu
   ```

#### Issue: Voice input not working

**Symptoms:**

- Microphone button grayed out
- No waveform animation
- "Microphone not available" error

**Solutions:**

1. **Grant microphone permission:**

   - macOS: System Preferences â†’ Security & Privacy â†’ Microphone â†’ Eden Project âœ“
   - Windows: Settings â†’ Privacy â†’ Microphone â†’ Allow apps âœ“

2. **Check microphone:**
   Settings â†’ Voice â†’ Input Device: [Select microphone]

3. **Restart audio service:**

   ```bash
   # macOS
   sudo killall coreaudiod

   # Windows
   Restart-Service -Name "Audiosrv"
   ```

#### Issue: Git integration not working

**Symptoms:**

- "Git not found" error
- Commands fail silently
- No repository detected

**Solutions:**

1. **Install Git:**

   ```bash
   # macOS (Homebrew)
   brew install git

   # Windows (Chocolatey)
   choco install git

   # Linux
   sudo apt install git  # Debian/Ubuntu
   sudo yum install git  # RHEL/CentOS
   ```

2. **Add Git to PATH:**

   ```bash
   # Verify Git is accessible
   git --version

   # If not, add to PATH:
   # Windows: Add C:\Program Files\Git\bin to PATH
   # macOS/Linux: Usually automatic after install
   ```

3. **Initialize repository:**
   ```bash
   cd /path/to/your/project
   git init
   ```

---

### 4.2 Performance Optimization

#### Reduce Memory Usage

1. **Limit conversation history:**
   Settings â†’ Privacy â†’ Auto-delete after 30 days âœ“

2. **Disable unnecessary features:**

   - Settings â†’ Voice â†’ Auto-TTS âŒ (if not needed)
   - Settings â†’ Vision â†’ LLaVA Model âŒ (if not using vision)

3. **Close unused conversations:**
   Right-click conversation â†’ Close

#### Improve Response Speed

1. **Use smaller model:**
   Settings â†’ Model â†’ Primary LLM: Llama 3.1 3B (instead of 8B)

   Note: Smaller model = faster but less capable

2. **Reduce max tokens:**
   Settings â†’ Model â†’ Max Tokens: 1024 (instead of 2048)

3. **Enable metal/CUDA:**

   ```bash
   # macOS (Metal)
   Settings â†’ Model â†’ GPU: Metal âœ“

   # Windows/Linux (CUDA)
   Settings â†’ Model â†’ GPU: CUDA âœ“
   ```

---

### 4.3 Data Management

#### Backup Data

```bash
# Full backup
cp -r ~/Library/Application\ Support/GardenOfEden ~/Desktop/GardenOfEden-Backup

# Just conversations
cp ~/Library/Application\ Support/GardenOfEden/conversations.db ~/Desktop/
```

#### Restore Data

```bash
# Restore full backup
cp -r ~/Desktop/GardenOfEden-Backup ~/Library/Application\ Support/GardenOfEden

# Restore just conversations
cp ~/Desktop/conversations.db ~/Library/Application\ Support/GardenOfEden/
```

#### Export All Conversations

```bash
# CLI export (if available)
garden-of-eden export --format json --output ~/Desktop/conversations.json

# Or use GUI: History â†’ Select All â†’ Export â†’ JSON
```

---

## 5. FAQ

### General

**Q: Is Eden Project really 100% local?**
A: Yes! After initial model download, everything runs on your computer. No internet required.

**Q: What's the difference between User-Led and AI-Led mode?**
A: User-Led is reactive (AI waits for you), AI-Led is proactive (AI suggests actions).

**Q: Can I use my own AI models?**
A: Yes! Place GGUF format models in the models directory and select them in Settings.

**Q: Does Eden Project work offline?**
A: Yes, completely offline after setup.

### Privacy & Security

**Q: Is my data encrypted?**
A: Conversations are stored in plaintext SQLite locally. Enable disk encryption for security.

**Q: Can the AI access my files without permission?**
A: Only when you explicitly ask (e.g., "read this file"). AI cannot browse freely.

**Q: Is voice data sent to servers?**
A: No, all speech-to-text happens locally using Whisper.

### Performance

**Q: Why is the first response slow?**
A: Model loading takes time. Subsequent responses are faster (model stays in memory).

**Q: How much RAM does it use?**
A: ~4-6 GB for 8B model, ~2-3 GB for 3B model.

**Q: Can I run it on a laptop?**
A: Yes, but performance varies. Recommended: 16GB RAM, modern CPU.

### Features

**Q: Can I use multiple AI models simultaneously?**
A: Not currently, but you can switch models in Settings.

**Q: Does it support languages other than English/Korean?**
A: UI supports English/Korean. AI supports 50+ languages.

**Q: Can I customize the UI theme?**
A: Yes, Light/Dark/Auto modes. Custom themes via plugins.

---

**End of Part 7**

_Lines: ~1500_
_Total Specification: ~11,700 lines_

---

---

# Epilogue

**Eden Project** represents a complete vision for a desktop-first, privacy-focused, locally-powered AI assistant.

This specification covers:

- âœ… Part 1: Vision & Philosophy
- âœ… Part 2: AI Intelligence & Local Models
- âœ… Part 3: Architecture & System Integration
- âœ… Part 4: UI/UX & Features (Expanded)
- âœ… Part 5: Implementation & Data Models
- âœ… Part 6: API Reference & Developer Documentation
- âœ… Part 7: User & Developer Guide

**Total: ~11,700 lines of comprehensive documentation**

All information needed to understand, build, use, and extend Eden Project is now contained in this single master specification document.

Ready to build the future of personal AI assistants.

---

_Document Version: 3.0_
_Last Updated: 2025-01-12_
_Status: Complete_
